#\!/usr/bin/env python
"""
å¿«é€Ÿæ€§èƒ½æµ‹è¯• - åˆ†æä¸ºä»€ä¹ˆLLMè°ƒç”¨æ…¢
"""

import asyncio
import time
import os
from src.utils.llm_client_proxy import GeminiClientWithProxy

async def test_llm_performance():
    """æµ‹è¯•LLMæ€§èƒ½"""
    
    print("=" * 60)
    print("LLMæ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    config = {
        "model_name": "gemini-1.5-flash",
        "temperature": 0.1,
        "max_tokens": 100
    }
    
    client = GeminiClientWithProxy(config)
    
    # 1. æµ‹è¯•å•ä¸ªè°ƒç”¨
    print("\n1. å•ä¸ªLLMè°ƒç”¨:")
    start = time.time()
    result = await client.generate("Return JSON: {\"test\": true}")
    single_time = time.time() - start
    print(f"   è€—æ—¶: {single_time:.2f}ç§’")
    
    # 2. æµ‹è¯•10ä¸ªå¹¶è¡Œè°ƒç”¨
    print("\n2. 10ä¸ªå¹¶è¡Œè°ƒç”¨:")
    queries = [f"Is table{i} valid? Return JSON" for i in range(10)]
    start = time.time()
    tasks = [client.generate(q) for q in queries]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    parallel_10_time = time.time() - start
    success = sum(1 for r in results if not isinstance(r, Exception))
    print(f"   è€—æ—¶: {parallel_10_time:.2f}ç§’")
    print(f"   æˆåŠŸ: {success}/10")
    print(f"   å¹³å‡: {parallel_10_time/10:.2f}ç§’/è°ƒç”¨")
    
    # 3. æµ‹è¯•20ä¸ªå¹¶è¡Œè°ƒç”¨
    print("\n3. 20ä¸ªå¹¶è¡Œè°ƒç”¨:")
    queries = [f"Is table{i} valid? Return JSON" for i in range(20)]
    start = time.time()
    tasks = [client.generate(q) for q in queries]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    parallel_20_time = time.time() - start
    success = sum(1 for r in results if not isinstance(r, Exception))
    print(f"   è€—æ—¶: {parallel_20_time:.2f}ç§’")
    print(f"   æˆåŠŸ: {success}/20")
    print(f"   å¹³å‡: {parallel_20_time/20:.2f}ç§’/è°ƒç”¨")
    
    # 4. åˆ†æç»“æœ
    print("\nğŸ“Š åˆ†æ:")
    if parallel_10_time < single_time * 2:
        print("   âœ… å¹¶è¡Œæœ‰æ•ˆï¼APIæ”¯æŒé«˜å¹¶å‘")
    else:
        print("   âš ï¸ å¯èƒ½æœ‰APIé™æµæˆ–ç½‘ç»œç“¶é¢ˆ")
    
    speedup_10 = (single_time * 10) / parallel_10_time
    speedup_20 = (single_time * 20) / parallel_20_time
    
    print(f"   10å¹¶å‘åŠ é€Ÿæ¯”: {speedup_10:.1f}x")
    print(f"   20å¹¶å‘åŠ é€Ÿæ¯”: {speedup_20:.1f}x")
    
    # 5. å»ºè®®
    print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    if parallel_20_time > 30:
        print("   1. å‡å°‘å€™é€‰æ•°é‡æ˜¯å…³é”®ï¼ˆ20â†’10æˆ–æ›´å°‘ï¼‰")
        print("   2. ä½¿ç”¨æ›´çŸ­çš„prompt")
        print("   3. è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹(å¦‚gemini-1.5-flash)")
        print("   4. å®ç°ç»“æœç¼“å­˜")
    else:
        print("   æ€§èƒ½è‰¯å¥½ï¼Œæ— éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")

if __name__ == "__main__":
    asyncio.run(test_llm_performance())
