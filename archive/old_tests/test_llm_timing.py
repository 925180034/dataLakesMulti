#\!/usr/bin/env python
"""
æµ‹è¯•LLMè°ƒç”¨æ—¶é—´ - éªŒè¯å¹¶è¡Œæ‰§è¡Œ
"""

import asyncio
import time
import os
from src.utils.llm_client_proxy import GeminiClientWithProxy

async def test_serial_vs_parallel():
    """æ¯”è¾ƒä¸²è¡Œå’Œå¹¶è¡ŒLLMè°ƒç”¨"""
    
    config = {
        "model_name": "gemini-1.5-flash",
        "temperature": 0.1,
        "max_tokens": 100
    }
    
    client = GeminiClientWithProxy(config)
    
    # å‡†å¤‡5ä¸ªæµ‹è¯•æŸ¥è¯¢
    queries = [
        f"Is table{i} joinable with table{i+1}? Return JSON: {{\"is_match\": true/false}}"
        for i in range(5)
    ]
    
    print("=" * 60)
    print("LLMè°ƒç”¨æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    # 1. ä¸²è¡Œè°ƒç”¨
    print("\n1. ä¸²è¡Œè°ƒç”¨ (5ä¸ªæŸ¥è¯¢)...")
    start = time.time()
    serial_results = []
    for query in queries:
        try:
            result = await client.generate(query)
            serial_results.append(result)
        except Exception as e:
            serial_results.append(f"Error: {e}")
    serial_time = time.time() - start
    print(f"   ä¸²è¡Œè€—æ—¶: {serial_time:.2f}s")
    print(f"   å¹³å‡æ¯ä¸ª: {serial_time/5:.2f}s")
    
    # 2. å¹¶è¡Œè°ƒç”¨
    print("\n2. å¹¶è¡Œè°ƒç”¨ (5ä¸ªæŸ¥è¯¢)...")
    start = time.time()
    tasks = [client.generate(query) for query in queries]
    parallel_results = await asyncio.gather(*tasks, return_exceptions=True)
    parallel_time = time.time() - start
    print(f"   å¹¶è¡Œè€—æ—¶: {parallel_time:.2f}s")
    print(f"   å¹³å‡æ¯ä¸ª: {parallel_time/5:.2f}s")
    
    # 3. è®¡ç®—æå‡
    speedup = serial_time / parallel_time if parallel_time > 0 else 0
    print(f"\nğŸ“Š æ€§èƒ½æå‡: {speedup:.1f}x")
    print(f"   èŠ‚çœæ—¶é—´: {serial_time - parallel_time:.2f}s")
    
    # 4. æ‰¹é‡æµ‹è¯•ï¼ˆ20ä¸ªå€™é€‰ï¼Œåˆ†æ‰¹å¤„ç†ï¼‰
    print("\n3. æ‰¹é‡å¤„ç†æµ‹è¯• (20ä¸ªå€™é€‰ï¼Œæ‰¹å¤§å°=5)...")
    candidates = [f"table{i}" for i in range(20)]
    start = time.time()
    
    batch_size = 5
    all_results = []
    for i in range(0, len(candidates), batch_size):
        batch = candidates[i:i+batch_size]
        batch_queries = [
            f"Is {table} valid? Return JSON: {{\"valid\": true/false}}"
            for table in batch
        ]
        batch_tasks = [client.generate(q) for q in batch_queries]
        batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
        all_results.extend(batch_results)
    
    batch_time = time.time() - start
    print(f"   æ‰¹é‡å¤„ç†è€—æ—¶: {batch_time:.2f}s")
    print(f"   å¤„ç†é€Ÿåº¦: {20/batch_time:.2f} queries/s")
    
    # 5. ä¸è¶…æ—¶ä¿æŠ¤
    print("\n4. è¶…æ—¶ä¿æŠ¤æµ‹è¯•...")
    timeout_query = "Complex query that might timeout..."
    
    try:
        start = time.time()
        result = await asyncio.wait_for(
            client.generate(timeout_query),
            timeout=5.0
        )
        print(f"   âœ… æˆåŠŸå“åº”: {(time.time()-start):.2f}s")
    except asyncio.TimeoutError:
        print(f"   â±ï¸ è¶…æ—¶ä¿æŠ¤ç”Ÿæ•ˆ (5ç§’)")
    except Exception as e:
        print(f"   âŒ å…¶ä»–é”™è¯¯: {e}")

if __name__ == "__main__":
    print("æµ‹è¯•ä»£ç†è®¾ç½®...")
    print(f"HTTP_PROXY: {os.getenv('http_proxy', 'Not set')}")
    print(f"HTTPS_PROXY: {os.getenv('https_proxy', 'Not set')}")
    
    asyncio.run(test_serial_vs_parallel())
EOF < /dev/null
