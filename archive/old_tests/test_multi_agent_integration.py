#!/usr/bin/env python3
"""
é›†æˆæµ‹è¯•ï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ + ä¸‰å±‚åŠ é€Ÿæ¶æ„
éªŒè¯çœŸæ­£çš„å¤šAgentååŒå·¥ä½œæµ
"""

import asyncio
import json
import time
from pathlib import Path
from typing import List, Dict, Any

# å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
from src.core.enhanced_multi_agent_system import EnhancedMultiAgentOrchestrator
from src.core.models import TableInfo, ColumnInfo

# è¯„ä»·æŒ‡æ ‡
from src.core.ultra_optimized_workflow import EvaluationMetrics
import numpy as np


async def test_multi_agent_with_acceleration():
    """æµ‹è¯•å¤šAgentç³»ç»Ÿä¸ä¸‰å±‚åŠ é€Ÿçš„é›†æˆ"""
    
    print("="*80)
    print("ğŸš€ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ + ä¸‰å±‚åŠ é€Ÿæ¶æ„ é›†æˆæµ‹è¯•")
    print("="*80)
    
    # 1. åŠ è½½æ•°æ®
    dataset_path = Path("examples/separated_datasets/join_subset")
    
    # åŠ è½½è¡¨
    with open(dataset_path / "tables.json") as f:
        tables_data = json.load(f)[:50]  # ä½¿ç”¨50ä¸ªè¡¨æµ‹è¯•
    
    # åŠ è½½æŸ¥è¯¢
    queries_path = dataset_path / "queries_filtered.json"
    if not queries_path.exists():
        queries_path = dataset_path / "queries.json"
    with open(queries_path) as f:
        queries_data = json.load(f)[:5]  # æµ‹è¯•5ä¸ªæŸ¥è¯¢
    
    # åŠ è½½ground truth
    gt_path = dataset_path / "ground_truth_transformed.json"
    if not gt_path.exists():
        gt_path = dataset_path / "ground_truth.json"
    with open(gt_path) as f:
        ground_truth = json.load(f)
    
    print(f"\nğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
    print(f"  - è¡¨æ•°é‡: {len(tables_data)}")
    print(f"  - æŸ¥è¯¢æ•°é‡: {len(queries_data)}")
    print(f"  - Ground Truthæ¡ç›®: {len(ground_truth)}")
    
    # 2. è½¬æ¢æ•°æ®æ ¼å¼
    tables = []
    for td in tables_data:
        table = TableInfo(
            table_name=td['table_name'],
            columns=[
                ColumnInfo(
                    table_name=td['table_name'],
                    column_name=col.get('column_name', col.get('name', '')),
                    data_type=col.get('data_type', 'unknown'),
                    sample_values=col.get('sample_values', [])[:3]
                )
                for col in td.get('columns', [])[:15]
            ]
        )
        tables.append(table)
    
    # 3. åˆ›å»ºå¤šAgentç³»ç»Ÿåè°ƒå™¨
    print("\nğŸ¤– åˆå§‹åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ...")
    orchestrator = EnhancedMultiAgentOrchestrator()
    
    # åˆå§‹åŒ–ç³»ç»Ÿï¼ˆåŒ…å«ä¸‰å±‚åŠ é€Ÿå·¥å…·ï¼‰
    start_init = time.time()
    await orchestrator.initialize(tables)
    init_time = time.time() - start_init
    print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {init_time:.2f}ç§’")
    
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    status = orchestrator.get_detailed_status()
    print(f"\nğŸ“‹ ç³»ç»ŸçŠ¶æ€:")
    print(f"  - Agentsæ•°é‡: {status['system']['num_agents']}")
    print(f"  - Agentåˆ—è¡¨: {status['system']['agents']}")
    print(f"  - ä¸‰å±‚åŠ é€ŸçŠ¶æ€:")
    print(f"    â€¢ Layer 1 (Metadata Filter): {'âœ… å¯ç”¨' if status['acceleration']['layer1_enabled'] else 'âŒ ç¦ç”¨'}")
    print(f"    â€¢ Layer 2 (Vector Search): {'âœ… å¯ç”¨' if status['acceleration']['layer2_enabled'] else 'âŒ ç¦ç”¨'}")
    print(f"    â€¢ Layer 3 (LLM Matcher): {'âœ… å¯ç”¨' if status['acceleration']['layer3_enabled'] else 'âŒ ç¦ç”¨'}")
    
    # 4. æµ‹è¯•æŸ¥è¯¢å¤„ç†
    print(f"\nğŸ”¬ å¼€å§‹æµ‹è¯•æŸ¥è¯¢å¤„ç†...")
    print("-"*60)
    
    # è¯„ä»·æŒ‡æ ‡æ”¶é›†
    all_metrics = []
    hit_at_k = {1: 0, 3: 0, 5: 0, 10: 0}
    
    for i, query in enumerate(queries_data, 1):
        query_table_name = query.get('query_table', '')
        query_column = query.get('query_column', '')
        
        # æŸ¥æ‰¾æŸ¥è¯¢è¡¨
        query_table = next((t for t in tables if t.table_name == query_table_name), None)
        if not query_table:
            print(f"\nâŒ æŸ¥è¯¢{i}: æ‰¾ä¸åˆ°è¡¨ {query_table_name}")
            continue
        
        print(f"\nğŸ“ æŸ¥è¯¢{i}/{len(queries_data)}: {query_table_name}")
        
        # æ„å»ºæŸ¥è¯¢
        query_text = f"Find tables that can be joined with {query_table_name}"
        
        # æ‰§è¡Œå¤šAgentååŒå¤„ç†
        start_time = time.time()
        try:
            results = await orchestrator.process_query_with_collaboration(
                query_text,
                query_table,
                strategy="auto"
            )
            query_time = time.time() - start_time
            
            # æå–é¢„æµ‹ç»“æœ
            predictions = []
            for result in results:
                if isinstance(result, dict):
                    table_name = result.get('table', result.get('table_name'))
                    if table_name:
                        predictions.append(table_name)
                else:
                    # Handle other result formats
                    predictions.append(str(result))
            
            # è·å–ground truth
            gt_key = f"{query_table_name}:{query_column}" if query_column else query_table_name
            true_matches = ground_truth.get(gt_key, [])
            
            # è®¡ç®—Hit@K
            for k in [1, 3, 5, 10]:
                if any(p in true_matches for p in predictions[:k]):
                    hit_at_k[k] += 1
            
            # è®¡ç®—è¯„ä»·æŒ‡æ ‡
            precision = len(set(predictions[:10]) & set(true_matches)) / min(10, len(predictions)) if predictions else 0
            recall = len(set(predictions[:10]) & set(true_matches)) / len(true_matches) if true_matches else 0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆçš„ä½ç½®ï¼ˆMRRï¼‰
            mrr = 0
            for idx, pred in enumerate(predictions[:10], 1):
                if pred in true_matches:
                    mrr = 1.0 / idx
                    break
            
            metric = EvaluationMetrics(
                precision=precision,
                recall=recall,
                f1_score=f1,
                mrr=mrr,
                query_time=query_time
            )
            all_metrics.append(metric)
            
            # æ˜¾ç¤ºç»“æœ
            print(f"  â±ï¸ æŸ¥è¯¢æ—¶é—´: {query_time:.2f}ç§’")
            print(f"  ğŸ“Š è¿”å›ç»“æœæ•°: {len(results)}")
            print(f"  ğŸ¯ Ground Truth: {true_matches[:3]}{'...' if len(true_matches) > 3 else ''}")
            print(f"  ğŸ”® é¢„æµ‹Top-5: {predictions[:5]}")
            print(f"  ğŸ“ˆ æŒ‡æ ‡: P={precision:.2f}, R={recall:.2f}, F1={f1:.2f}, MRR={mrr:.2f}")
            
            # æ£€æŸ¥æ­£ç¡®ç­”æ¡ˆä½ç½®
            for gt in true_matches[:3]:
                if gt in predictions:
                    idx = predictions.index(gt)
                    print(f"    âœ… '{gt}' åœ¨ç¬¬{idx+1}ä½")
                else:
                    print(f"    âŒ '{gt}' ä¸åœ¨ç»“æœä¸­")
            
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
            continue
    
    # 5. æ±‡æ€»è¯„ä»·æŒ‡æ ‡
    print("\n" + "="*60)
    print("ğŸ“Š è¯„ä»·æŒ‡æ ‡æ±‡æ€»")
    print("="*60)
    
    if all_metrics:
        avg_precision = np.mean([m.precision for m in all_metrics])
        avg_recall = np.mean([m.recall for m in all_metrics])
        avg_f1 = np.mean([m.f1_score for m in all_metrics])
        avg_mrr = np.mean([m.mrr for m in all_metrics])
        avg_time = np.mean([m.query_time for m in all_metrics])
        
        print(f"\nğŸ¯ å¹³å‡æŒ‡æ ‡:")
        print(f"  - Precision: {avg_precision:.3f}")
        print(f"  - Recall: {avg_recall:.3f}")
        print(f"  - F1-Score: {avg_f1:.3f}")
        print(f"  - MRR: {avg_mrr:.3f}")
        print(f"  - æŸ¥è¯¢æ—¶é—´: {avg_time:.2f}ç§’")
        
        print(f"\nğŸ“ˆ Hit@K:")
        for k in [1, 3, 5, 10]:
            hit_rate = hit_at_k[k] / len(queries_data) * 100
            print(f"  - Hit@{k}: {hit_at_k[k]}/{len(queries_data)} ({hit_rate:.1f}%)")
    
    # 6. æ˜¾ç¤ºAgentåä½œç»†èŠ‚
    final_status = orchestrator.get_detailed_status()
    print(f"\nğŸ¤ Agentåä½œç»Ÿè®¡:")
    print(f"  - å¤„ç†æŸ¥è¯¢æ•°: {final_status['performance']['queries_processed']}")
    print(f"  - å¹³å‡å¤„ç†æ—¶é—´: {final_status['performance']['avg_time']:.2f}ç§’")
    print(f"  - æ¶ˆæ¯æ€»æ•°: {final_status['system']['message_count']}")
    
    # æ˜¾ç¤ºä¼˜åŒ–å™¨æŠ¥å‘Š
    if 'optimizer_report' in final_status and final_status['optimizer_report']:
        opt_report = final_status['optimizer_report']
        if 'recommendations' in opt_report:
            print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for rec in opt_report['recommendations']:
                print(f"  - {rec}")
    
    print("\n" + "="*80)
    print("âœ… å¤šæ™ºèƒ½ä½“ç³»ç»Ÿé›†æˆæµ‹è¯•å®Œæˆï¼")
    print("="*80)
    
    # 7. å¯¹æ¯”åˆ†æ
    print("\n" + "="*80)
    print("ğŸ“Š æ¶æ„å¯¹æ¯”åˆ†æ")
    print("="*80)
    print("\nâœ¨ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¼˜åŠ¿:")
    print("  1. æ¯ä¸ªAgentç‹¬ç«‹å†³ç­–ï¼Œå¯æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©ä½¿ç”¨LLMæˆ–è§„åˆ™")
    print("  2. Agenté—´ååŒå·¥ä½œï¼Œå…±äº«ä¿¡æ¯å’Œä¼˜åŒ–ç­–ç•¥")
    print("  3. ä¸‰å±‚åŠ é€Ÿä½œä¸ºå·¥å…·ä¾›Agentè°ƒç”¨ï¼Œè€Œéå›ºå®šæµç¨‹")
    print("  4. OptimizerAgentåŠ¨æ€è°ƒæ•´ç³»ç»Ÿæ€§èƒ½")
    print("  5. æ”¯æŒå¹¶è¡Œå¤„ç†å’Œæ™ºèƒ½ç¼“å­˜")
    
    print("\nğŸ”„ ä¸çº¯ä¸‰å±‚åŠ é€Ÿçš„åŒºåˆ«:")
    print("  â€¢ ä¸‰å±‚åŠ é€Ÿ: Layer1 â†’ Layer2 â†’ Layer3 (å›ºå®šæµç¨‹)")
    print("  â€¢ å¤šAgent+ä¸‰å±‚: AgentsååŒå†³ç­– + é€‰æ‹©æ€§ä½¿ç”¨åŠ é€Ÿå±‚")
    print("    - PlannerAgent: å¯ç”¨LLMåˆ†æå¤æ‚æŸ¥è¯¢")
    print("    - AnalyzerAgent: å¯ç”¨LLMæ·±åº¦åˆ†æschema")
    print("    - SearcherAgent: çµæ´»é€‰æ‹©Layer1/Layer2/æ··åˆ")
    print("    - MatcherAgent: æ™ºèƒ½é€‰æ‹©æ˜¯å¦è°ƒç”¨Layer3")
    print("    - AggregatorAgent: å¯ç”¨LLMé‡æ’åº")
    print("    - OptimizerAgent: åŠ¨æ€ä¼˜åŒ–ç³»ç»Ÿé…ç½®")
    
    return all_metrics


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_multi_agent_with_acceleration())