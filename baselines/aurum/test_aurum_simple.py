#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆAurumæµ‹è¯•è„šæœ¬
æµ‹è¯•Aurumåœ¨è½¬æ¢åçš„æ•°æ®ä¸Šçš„åŸºæœ¬åŠŸèƒ½

ä½¿ç”¨ä½ çš„ä¸‰ä¸ªæ•°æ®é›†:
- NLCTables 
- WebTable
- OpenData
"""

import os
import sys
import json
import pandas as pd
from pathlib import Path
import time
import logging
from datasketch import MinHash
import pickle

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class AurumSimpleTest:
    """ç®€åŒ–ç‰ˆAurumæµ‹è¯•å™¨"""
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.hash_cache = {}
        
    def create_minhash(self, table_df: pd.DataFrame, num_perm: int = 128) -> MinHash:
        """ä¸ºè¡¨æ ¼åˆ›å»ºMinHash"""
        mh = MinHash(num_perm=num_perm)
        
        # å°†æ‰€æœ‰åˆ—çš„æ‰€æœ‰å€¼æ·»åŠ åˆ°MinHashä¸­
        for col in table_df.columns:
            for value in table_df[col].dropna().astype(str):
                if value.strip():  # å¿½ç•¥ç©ºå­—ç¬¦ä¸²
                    mh.update(value.strip().lower().encode('utf-8'))
        
        return mh
    
    def build_index(self, dataset: str, task: str) -> dict:
        """ä¸ºæŒ‡å®šæ•°æ®é›†æ„å»ºMinHashç´¢å¼•"""
        dataset_path = self.data_dir / dataset / task
        
        if not dataset_path.exists():
            logging.error(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
            return {}
        
        logging.info(f"æ„å»ºç´¢å¼•: {dataset}-{task}")
        
        index = {}
        csv_files = list(dataset_path.glob("*.csv"))
        
        if len(csv_files) == 0:
            logging.warning(f"æ²¡æœ‰æ‰¾åˆ°CSVæ–‡ä»¶: {dataset_path}")
            return {}
        
        logging.info(f"æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
        
        for csv_file in csv_files:
            try:
                # è¯»å–CSVæ–‡ä»¶
                df = pd.read_csv(csv_file)
                
                if len(df) == 0:
                    logging.warning(f"ç©ºè¡¨æ ¼: {csv_file.name}")
                    continue
                
                # åˆ›å»ºMinHash
                mh = self.create_minhash(df)
                
                # å­˜å‚¨ç´¢å¼•
                index[csv_file.name] = {
                    'minhash': mh,
                    'num_rows': len(df),
                    'num_cols': len(df.columns),
                    'columns': list(df.columns)
                }
                
            except Exception as e:
                logging.error(f"å¤„ç†æ–‡ä»¶ {csv_file.name} æ—¶å‡ºé”™: {e}")
                continue
        
        logging.info(f"æˆåŠŸæ„å»ºç´¢å¼•ï¼ŒåŒ…å« {len(index)} ä¸ªè¡¨æ ¼")
        return index
    
    def query_similar_tables(self, query_table_name: str, index: dict, 
                           threshold: float = 0.1, top_k: int = 10) -> list:
        """æŸ¥è¯¢ç›¸ä¼¼è¡¨æ ¼"""
        if query_table_name not in index:
            logging.error(f"æŸ¥è¯¢è¡¨æ ¼ä¸å­˜åœ¨äºç´¢å¼•ä¸­: {query_table_name}")
            return []
        
        query_mh = index[query_table_name]['minhash']
        similarities = []
        
        for table_name, table_info in index.items():
            if table_name == query_table_name:
                continue  # è·³è¿‡è‡ªå·±
            
            # è®¡ç®—Jaccardç›¸ä¼¼åº¦
            similarity = query_mh.jaccard(table_info['minhash'])
            
            if similarity >= threshold:
                similarities.append({
                    'table_name': table_name,
                    'similarity': similarity,
                    'num_rows': table_info['num_rows'],
                    'num_cols': table_info['num_cols'],
                    'columns': table_info['columns']
                })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        
        return similarities[:top_k]
    
    def load_queries(self, dataset: str, task: str) -> list:
        """åŠ è½½æŸ¥è¯¢æ•°æ®"""
        queries_file = self.data_dir / dataset / task / "queries.json"
        
        if not queries_file.exists():
            logging.warning(f"æŸ¥è¯¢æ–‡ä»¶ä¸å­˜åœ¨: {queries_file}")
            return []
        
        with open(queries_file, 'r', encoding='utf-8') as f:
            queries = json.load(f)
        
        return queries
    
    def load_ground_truth(self, dataset: str, task: str) -> dict:
        """åŠ è½½ground truthæ•°æ®"""
        gt_file = self.data_dir / dataset / task / "ground_truth.json"
        
        if not gt_file.exists():
            logging.warning(f"Ground truthæ–‡ä»¶ä¸å­˜åœ¨: {gt_file}")
            return {}
        
        with open(gt_file, 'r', encoding='utf-8') as f:
            ground_truth = json.load(f)
        
        return ground_truth
    
    def evaluate_performance(self, dataset: str, task: str, max_queries: int = 5):
        """è¯„ä¼°æ€§èƒ½"""
        logging.info(f"\n=== è¯„ä¼° {dataset}-{task} ===")
        
        # æ„å»ºç´¢å¼•
        start_time = time.time()
        index = self.build_index(dataset, task)
        index_time = time.time() - start_time
        
        if len(index) == 0:
            logging.error("ç´¢å¼•æ„å»ºå¤±è´¥")
            return
        
        logging.info(f"ç´¢å¼•æ„å»ºè€—æ—¶: {index_time:.2f}ç§’")
        
        # åŠ è½½æŸ¥è¯¢å’Œground truth
        queries = self.load_queries(dataset, task)
        ground_truth = self.load_ground_truth(dataset, task)
        
        if len(queries) == 0:
            logging.warning("æ²¡æœ‰æŸ¥è¯¢æ•°æ®ï¼Œä½¿ç”¨ç´¢å¼•ä¸­çš„è¡¨æ ¼è¿›è¡Œæµ‹è¯•")
            # ä½¿ç”¨å‰5ä¸ªè¡¨æ ¼ä½œä¸ºæŸ¥è¯¢
            query_tables = list(index.keys())[:max_queries]
            queries = [{"query_table": table} for table in query_tables]
        
        logging.info(f"å¤„ç† {min(len(queries), max_queries)} ä¸ªæŸ¥è¯¢")
        
        # æ‰§è¡ŒæŸ¥è¯¢
        results = []
        total_query_time = 0
        
        for i, query in enumerate(queries[:max_queries]):
            query_table = query.get('query_table', query.get('seed_table'))
            
            if not query_table:
                logging.warning(f"æŸ¥è¯¢ {i} ç¼ºå°‘è¡¨æ ¼åç§°")
                continue
            
            # ç¡®ä¿æŸ¥è¯¢è¡¨æ ¼åç§°æ ¼å¼æ­£ç¡®
            if not query_table.endswith('.csv'):
                query_table += '.csv'
            
            logging.info(f"æŸ¥è¯¢ {i+1}: {query_table}")
            
            # æ‰§è¡ŒæŸ¥è¯¢
            start_time = time.time()
            similar_tables = self.query_similar_tables(
                query_table, index, threshold=0.05, top_k=10
            )
            query_time = time.time() - start_time
            total_query_time += query_time
            
            results.append({
                'query_table': query_table,
                'similar_tables': similar_tables,
                'query_time': query_time
            })
            
            # æ˜¾ç¤ºç»“æœ
            if similar_tables:
                logging.info(f"  æ‰¾åˆ° {len(similar_tables)} ä¸ªç›¸ä¼¼è¡¨æ ¼:")
                for j, sim_table in enumerate(similar_tables[:3]):
                    logging.info(f"    {j+1}. {sim_table['table_name']} (ç›¸ä¼¼åº¦: {sim_table['similarity']:.3f})")
            else:
                logging.info("  æœªæ‰¾åˆ°ç›¸ä¼¼è¡¨æ ¼")
        
        # è®¡ç®—å¹³å‡æ€§èƒ½
        if results:
            avg_query_time = total_query_time / len(results)
            logging.info(f"\næ€§èƒ½ç»Ÿè®¡:")
            logging.info(f"  å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_query_time:.3f}ç§’")
            logging.info(f"  æ€»æŸ¥è¯¢æ—¶é—´: {total_query_time:.2f}ç§’")
            logging.info(f"  ç´¢å¼•æ„å»ºæ—¶é—´: {index_time:.2f}ç§’")
            logging.info(f"  å¤„ç†çš„æŸ¥è¯¢æ•°: {len(results)}")
        
        return results

def main():
    # Aurumæ•°æ®ç›®å½•
    data_dir = "/root/dataLakesMulti/baselines/data/aurum"
    
    tester = AurumSimpleTest(data_dir)
    
    # æµ‹è¯•æ•°æ®é›†
    datasets = [
        ('nlctables', 'join'),
        ('webtable', 'join'), 
        ('opendata', 'join')
    ]
    
    print("ğŸ” Aurum Baseline æµ‹è¯•")
    print("=" * 50)
    
    all_results = {}
    
    for dataset, task in datasets:
        try:
            results = tester.evaluate_performance(dataset, task, max_queries=3)
            all_results[f"{dataset}-{task}"] = results
        except Exception as e:
            logging.error(f"æµ‹è¯• {dataset}-{task} æ—¶å‡ºé”™: {e}")
            continue
    
    print("\nğŸ“Š æ€»ä½“ç»“æœæ‘˜è¦:")
    for key, results in all_results.items():
        if results:
            avg_time = sum(r['query_time'] for r in results) / len(results)
            avg_results = sum(len(r['similar_tables']) for r in results) / len(results)
            print(f"  {key}: {len(results)}ä¸ªæŸ¥è¯¢, å¹³å‡{avg_time:.3f}s/æŸ¥è¯¢, å¹³å‡{avg_results:.1f}ä¸ªç»“æœ")
    
    print("\nâœ… Aurumæµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()