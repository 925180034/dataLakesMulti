#!/usr/bin/env python3
"""
å¿«é€ŸLSH Ensembleæµ‹è¯•
åªæµ‹è¯•å°æ•°æ®é›†é¿å…è¶…æ—¶
"""

import os
import sys
import pandas as pd
from pathlib import Path
import time
import logging

# ç¡®ä¿ä½¿ç”¨æœ¬åœ°datasketchç‰ˆæœ¬
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from datasketch import MinHashLSHEnsemble, MinHash
import farmhash

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def _hash_32(d):
    """ä½¿ç”¨farmhashçš„32ä½å“ˆå¸Œå‡½æ•°"""
    return farmhash.hash32(d)

def quick_lsh_test():
    """å¿«é€ŸLSH Ensembleæµ‹è¯•"""
    data_dir = Path("/root/dataLakesMulti/baselines/data/lsh/nlctables/join")
    
    if not data_dir.exists():
        logging.error(f"æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_dir}")
        return
    
    # åªé€‰æ‹©å‰5ä¸ªæœ‰æ•ˆçš„CSVæ–‡ä»¶
    csv_files = []
    for csv_file in data_dir.glob("*.csv"):
        try:
            df = pd.read_csv(csv_file, dtype=str).dropna()
            if len(df) > 0 and len(df.columns) > 0:
                csv_files.append(csv_file)
                if len(csv_files) >= 5:
                    break
        except:
            continue
    
    logging.info(f"ä½¿ç”¨ {len(csv_files)} ä¸ªCSVæ–‡ä»¶è¿›è¡Œæµ‹è¯•")
    
    # è®¡ç®—åˆ—å¤§å°
    sizes = []
    keys = []
    
    for csv_file in csv_files:
        df = pd.read_csv(csv_file, dtype=str).dropna()
        for column in df.columns:
            vals = df[column].dropna().astype(str).tolist()
            vals = list(set(vals))  # å»é‡
            
            key = f"{csv_file.name}.{column}"
            keys.append(key)
            sizes.append(len(vals))
    
    logging.info(f"æ€»å…± {len(sizes)} åˆ—")
    
    # åˆ›å»ºLSH Ensemble
    start_time = time.time()
    lsh = MinHashLSHEnsemble(
        threshold=0.1, 
        num_perm=64,  # å‡å°‘permutationæ•°é‡
        num_part=4,   # å‡å°‘åˆ†åŒºæ•°é‡
        m=2           # å‡å°‘må€¼
    )
    
    # åˆ†åŒºè®¡æ•°
    lsh.count_partition(sizes)
    
    # åˆ›å»ºMinHashå¹¶ç´¢å¼•
    key_idx = 0
    for csv_file in csv_files:
        df = pd.read_csv(csv_file, dtype=str).dropna()
        for column in df.columns:
            vals = df[column].dropna().astype(str).tolist()
            vals = list(set(vals))
            
            # åˆ›å»ºMinHash
            mh = MinHash(64, hashfunc=_hash_32)  # å‡å°‘num_perm
            for val in vals:
                if val.strip():
                    mh.update(val.strip().lower().encode('utf-8'))
            
            # æ·»åŠ åˆ°ç´¢å¼•
            key = keys[key_idx]
            size = sizes[key_idx]
            lsh.index((key, mh, size))
            
            key_idx += 1
    
    index_time = time.time() - start_time
    logging.info(f"ç´¢å¼•æ„å»ºè€—æ—¶: {index_time:.2f}ç§’")
    
    # æ‰§è¡ŒæŸ¥è¯¢æµ‹è¯•
    if len(keys) > 0:
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªé”®è¿›è¡ŒæŸ¥è¯¢ - ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰æ•°æ®
        test_key = keys[0]
        logging.info(f"æµ‹è¯•æŸ¥è¯¢key: {test_key}")
        
        # ä½¿ç”¨å·²ç»æ„å»ºç´¢å¼•æ—¶çš„æ•°æ®è¿›è¡ŒæŸ¥è¯¢æµ‹è¯•
        # ç›´æ¥åˆ›å»ºä¸€ä¸ªç®€å•çš„MinHashè¿›è¡ŒæŸ¥è¯¢
        mh = MinHash(64, hashfunc=_hash_32)
        for i in range(10):  # æ·»åŠ ä¸€äº›æµ‹è¯•æ•°æ®
            mh.update(f"test_value_{i}".encode('utf-8'))
        
        # æ‰§è¡ŒæŸ¥è¯¢
        start_time = time.time()
        results = list(lsh.query(mh, 10))
        query_time = time.time() - start_time
        
        logging.info(f"æŸ¥è¯¢æµ‹è¯•:")
        logging.info(f"  æŸ¥è¯¢æ—¶é—´: {query_time:.3f}ç§’")
        logging.info(f"  æ‰¾åˆ° {len(results)} ä¸ªç›¸ä¼¼åˆ—")
        
        for i, result in enumerate(results[:5]):
            logging.info(f"    {i+1}. {result}")
    
    return {
        'index_time': index_time,
        'query_time': query_time if 'query_time' in locals() else 0,
        'num_columns': len(keys),
        'num_results': len(results) if 'results' in locals() else 0
    }

if __name__ == "__main__":
    print("ğŸš€ å¿«é€ŸLSH Ensembleæµ‹è¯•")
    print("=" * 40)
    
    try:
        result = quick_lsh_test()
        print("\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"  ç´¢å¼•æ„å»ºæ—¶é—´: {result['index_time']:.2f}ç§’")
        print(f"  æŸ¥è¯¢æ—¶é—´: {result['query_time']:.3f}ç§’")
        print(f"  å¤„ç†åˆ—æ•°: {result['num_columns']}")
        print(f"  æŸ¥è¯¢ç»“æœæ•°: {result['num_results']}")
        print("\nâœ… LSH Ensembleæµ‹è¯•å®Œæˆ!")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()