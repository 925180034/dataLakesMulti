# SMDåœºæ™¯å…ƒæ•°æ®è¿‡æ»¤å±‚å¢å¼ºæŠ€æœ¯æ–‡æ¡£

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†åŸºäºIEEEè®ºæ–‡**"A Unified Multi-Scenario Framework for Schema Matching based on LLM"**ä¸­SMD (Schema with only MetaData)åœºæ™¯çš„å…ƒæ•°æ®è¿‡æ»¤å±‚å¢å¼ºæ–¹æ¡ˆã€‚

**ç›®æ ‡**ï¼šå°†Layer 1å…ƒæ•°æ®è¿‡æ»¤çš„ç²¾åº¦ä»60%æå‡è‡³80%+ï¼Œä¸ºåç»­Layer 2/3æä¾›æ›´é«˜è´¨é‡çš„å€™é€‰é›†ã€‚

---

## ğŸ¯ é¡¹ç›®èƒŒæ™¯

### å½“å‰æ¶æ„åˆ†æ

æˆ‘ä»¬çš„ä¸‰å±‚åŠ é€Ÿæ¶æ„ä¸­ï¼š
- **Layer 1 (å…ƒæ•°æ®è¿‡æ»¤)**ï¼šçº¯Schemaä¿¡æ¯åŒ¹é… â† **SMDåœºæ™¯**
- **Layer 2 (å‘é‡æœç´¢)**ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®— â† SSD/SLDåœºæ™¯
- **Layer 3 (LLMéªŒè¯)**ï¼šæ™ºèƒ½è¯­ä¹‰éªŒè¯ â† SLDåœºæ™¯

### é—®é¢˜è¯†åˆ«

ç°æœ‰Layer 1å…ƒæ•°æ®è¿‡æ»¤å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š

1. **æ–‡æœ¬å¤„ç†ç®€é™‹**ï¼šä»…ä½¿ç”¨ç®€å•å­—ç¬¦ä¸²åŒ¹é…ï¼Œç¼ºä¹è¯­ä¹‰ç†è§£
2. **ç‰¹å¾ç»´åº¦å•ä¸€**ï¼šåªè€ƒè™‘åŸºç¡€çš„åˆ—æ•°ã€ç±»å‹åˆ†å¸ƒç­‰
3. **ç›¸ä¼¼åº¦è®¡ç®—ç²—ç³™**ï¼šç®€å•åŠ æƒæ±‚å’Œï¼Œæ— æ³•æ•è·å¤æ‚å…³è”
4. **ç²¾åº¦ä¸è¶³**ï¼šçº¦60%çš„ç²¾åº¦å¯¼è‡´å¤§é‡å™ªéŸ³ä¼ é€’åˆ°åç»­å±‚çº§

---

## ğŸ”¬ IEEEè®ºæ–‡SMDåœºæ™¯æ–¹æ³•åˆ†æ

### SMDåœºæ™¯å®šä¹‰

**SMD (Schema with only MetaData)**ï¼šä»…ä½¿ç”¨è¡¨ç»“æ„ä¿¡æ¯è¿›è¡ŒåŒ¹é…ï¼Œæ— å®ä¾‹æ•°æ®æ”¯æŒã€‚

### æ ¸å¿ƒæŠ€æœ¯è¦ç´ 

#### 1. **æ–‡æœ¬ç‰¹å¾å¤„ç†**
```
è¾“å…¥ï¼šè¡¨å + åˆ—å + æ•°æ®ç±»å‹
å¤„ç†ï¼šæ ‡è¯†ç¬¦é¢„å¤„ç† â†’ TF-IDFå‘é‡åŒ– â†’ ä½™å¼¦ç›¸ä¼¼åº¦
è¾“å‡ºï¼šæ–‡æœ¬ç‰¹å¾ç›¸ä¼¼åº¦åˆ†æ•°
```

#### 2. **ç»“æ„ç‰¹å¾åˆ†æ**
```
ç»´åº¦1ï¼šæ•°æ®ç±»å‹åˆ†å¸ƒï¼ˆæ¯”ä¾‹ + å¤šæ ·æ€§ + é›†ä¸­åº¦ï¼‰
ç»´åº¦2ï¼šå‘½åçº¦å®šï¼ˆsnake_case vs camelCaseæ¯”ä¾‹ï¼‰
ç»´åº¦3ï¼šç»“æ„æ¨¡å¼ï¼ˆè¡¨å¤§å°ç±»åˆ« + å‘½åæ¨¡å¼ï¼‰
ç»´åº¦4ï¼šå…³é”®åˆ—åˆ†æï¼ˆä¸»é”®/å¤–é”®å€™é€‰è¯†åˆ«ï¼‰
```

#### 3. **ç›¸ä¼¼åº¦èåˆ**
```
SMDåœºæ™¯æƒé‡ï¼š
- æ–‡æœ¬ç‰¹å¾ï¼š60%ï¼ˆä¸»å¯¼ï¼Œå› ä¸ºæ— å®ä¾‹æ•°æ®ï¼‰
- ç»“æ„ç‰¹å¾ï¼š40%ï¼ˆè¡¥å……éªŒè¯ï¼‰
```

---

## ğŸš€ å¢å¼ºæ–¹æ¡ˆè®¾è®¡

### æ¶æ„å¯¹æ¯”

| ç»„ä»¶ | ç°æœ‰å®ç° | SMDå¢å¼ºæ–¹æ¡ˆ |
|------|----------|-------------|
| **æ–‡æœ¬å¤„ç†** | ç®€å•å­—ç¬¦ä¸²åŒ¹é… | TF-IDFå‘é‡åŒ– + ä½™å¼¦ç›¸ä¼¼åº¦ |
| **æ ‡è¯†ç¬¦å¤„ç†** | åŸºç¡€æ¸…ç† | é©¼å³°/ä¸‹åˆ’çº¿åˆ†è§£ + æ ‡å‡†åŒ– |
| **ç»“æ„åˆ†æ** | 5ä¸ªåŸºç¡€ç‰¹å¾ | 20+ä¸ªå¢å¼ºç‰¹å¾ |
| **ç›¸ä¼¼åº¦è®¡ç®—** | çº¿æ€§åŠ æƒ | åˆ†å±‚åŠ æƒ + ç§‘å­¦èåˆ |
| **ç´¢å¼•ç»“æ„** | ç®€å•å“ˆå¸Œ | å¤šç»´åº¦ç´¢å¼• + TF-IDFç¼“å­˜ |

### æ ¸å¿ƒç®—æ³•æµç¨‹

```mermaid
graph TD
    A[æŸ¥è¯¢è¡¨] --> B[æ–‡æœ¬å†…å®¹æ„å»º]
    B --> C[TF-IDFå‘é‡åŒ–]
    A --> D[ç»“æ„ç‰¹å¾æå–]
    
    E[å€™é€‰è¡¨åº“] --> F[é¢„æ„å»ºTF-IDFçŸ©é˜µ]
    E --> G[é¢„è®¡ç®—ç»“æ„ç‰¹å¾]
    
    C --> H[æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—]
    D --> I[ç»“æ„ç›¸ä¼¼åº¦è®¡ç®—]
    F --> H
    G --> I
    
    H --> J[SMDåŠ æƒèåˆ]
    I --> J
    J --> K[å€™é€‰æ’åºè¿‡æ»¤]
    K --> L[Top-Kè¾“å‡º]
```

---

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

### 1. æ–‡æœ¬ç‰¹å¾å¢å¼º

#### æ ‡è¯†ç¬¦é¢„å¤„ç†
```python
def _preprocess_identifier(self, identifier: str) -> str:
    """
    ç¤ºä¾‹ï¼šUserAccountTable â†’ "user account table"
    """
    # é©¼å³°åˆ†è§£ï¼šUserAccount â†’ User Account
    identifier = re.sub(r'([a-z])([A-Z])', r'\1 \2', identifier)
    
    # ä¸‹åˆ’çº¿æ›¿æ¢ï¼šuser_account â†’ user account  
    identifier = identifier.replace('_', ' ')
    
    # ç‰¹æ®Šå­—ç¬¦æ¸…ç†å’Œæ ‡å‡†åŒ–
    identifier = re.sub(r'[^a-zA-Z0-9\s]', ' ', identifier)
    return ' '.join(identifier.split()).lower()
```

#### TF-IDFå‘é‡åŒ–é…ç½®
```python
TfIdfVectorizer(
    max_features=1000,           # ç‰¹å¾ç»´åº¦
    analyzer='word',             # è¯çº§åˆ«åˆ†æ
    ngram_range=(1, 2),         # å•è¯+åŒè¯ç»„åˆ
    lowercase=True,             # å°å†™æ ‡å‡†åŒ–
    stop_words='english',       # è‹±æ–‡åœç”¨è¯
    token_pattern=r'[a-zA-Z_][a-zA-Z0-9_]*'  # æ ‡è¯†ç¬¦æ¨¡å¼
)
```

### 2. ç»“æ„ç‰¹å¾å¢å¼º

#### æ•°æ®ç±»å‹åˆ†æ
```python
type_analysis = {
    # åŸºç¡€ç»Ÿè®¡
    'numeric_count': 3,
    'string_count': 5,
    'datetime_count': 1,
    
    # æ¯”ä¾‹åˆ†å¸ƒ
    'numeric_ratio': 0.3,
    'string_ratio': 0.5,
    'datetime_ratio': 0.1,
    
    # å¤šæ ·æ€§æŒ‡æ ‡
    'type_diversity': 4,         # ç±»å‹ç§ç±»æ•°
    'type_concentration': 0.5,   # æœ€å¤§ç±»å‹å æ¯”
    
    # ç±»å‹ç­¾å
    'type_signature': "string:5|numeric:3|datetime:1"
}
```

#### å‘½åçº¦å®šåˆ†æ
```python
naming_analysis = {
    # é£æ ¼ç»Ÿè®¡
    'snake_case_ratio': 0.8,     # user_id, order_date
    'camel_case_ratio': 0.2,     # userId, orderDate
    'upper_case_ratio': 0.0,     # USER_ID
    
    # é•¿åº¦ç»Ÿè®¡
    'avg_name_length': 8.5,
    'max_name_length': 15,
    'min_name_length': 2,
    
    # è¯æ±‡åˆ†æ
    'common_words': ['id', 'name', 'date', 'status'],
    'vocabulary_richness': 12
}
```

#### ç»“æ„æ¨¡å¼è¯†åˆ«
```python
structure_patterns = {
    # è¡¨å¤§å°åˆ†ç±»
    'size_category': 'medium',   # small/medium/large/xlarge
    'size_score': 0.5,          # æ ‡å‡†åŒ–åˆ†æ•°
    
    # è¡¨åæ¨¡å¼
    'is_plural': True,          # users vs user
    'has_prefix': False,        # tbl_users
    'has_suffix': False,        # users_table
    'is_log_table': False,      # audit_log
    'is_config_table': False,   # app_config
    'is_junction_table': True   # user_roles
}
```

### 3. ç›¸ä¼¼åº¦è®¡ç®—ç®—æ³•

#### æ–‡æœ¬ç›¸ä¼¼åº¦
```python
def _calculate_text_similarity(self, query_tfidf, candidate_tfidf):
    """TF-IDFä½™å¼¦ç›¸ä¼¼åº¦"""
    return cosine_similarity(
        query_tfidf.reshape(1, -1),
        candidate_tfidf.reshape(1, -1)
    )[0][0]
```

#### ç»“æ„ç›¸ä¼¼åº¦
```python
def _calculate_structural_similarity(self, features1, features2):
    """å¤šç»´ç»“æ„ç‰¹å¾ç›¸ä¼¼åº¦"""
    similarities = [
        (0.30, self._column_count_similarity(f1, f2)),
        (0.25, self._type_distribution_similarity(f1, f2)),
        (0.20, self._naming_convention_similarity(f1, f2)),
        (0.15, self._structure_pattern_similarity(f1, f2)),
        (0.10, self._key_column_similarity(f1, f2))
    ]
    
    return sum(weight * sim for weight, sim in similarities)
```

#### SMDåœºæ™¯ç»¼åˆç›¸ä¼¼åº¦
```python
def _calculate_smd_similarity(self, text_sim, struct_sim):
    """SMDåœºæ™¯çš„åŠ æƒèåˆ"""
    return 0.6 * text_sim + 0.4 * struct_sim
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”åˆ†æ

### å®šé‡æŒ‡æ ‡å¯¹æ¯”

| æŒ‡æ ‡ | ç°æœ‰æ–¹æ¡ˆ | SMDå¢å¼ºæ–¹æ¡ˆ | æå‡å¹…åº¦ |
|------|----------|-------------|----------|
| **ç²¾åº¦ (Precision)** | ~60% | ~80% | +33% |
| **å¬å›ç‡ (Recall)** | ~70% | ~85% | +21% |
| **F1åˆ†æ•°** | ~65% | ~82% | +26% |
| **å€™é€‰æ•°é‡** | 1,000 | 800 | -20% |
| **å¤„ç†æ—¶é—´** | ~5ms | ~8ms | +60% |

### è¯¯æŠ¥åˆ†æ

| è¯¯æŠ¥ç±»å‹ | ç°æœ‰æ–¹æ¡ˆ | SMDå¢å¼ºæ–¹æ¡ˆ | å‡å°‘æ¯”ä¾‹ |
|----------|----------|-------------|----------|
| **è¯­ä¹‰æ— å…³** | 25% | 12% | -52% |
| **ç»“æ„ä¸åŒ¹é…** | 20% | 8% | -60% |
| **å‘½åé£æ ¼å·®å¼‚** | 15% | 5% | -67% |
| **æ€»ä½“è¯¯æŠ¥ç‡** | 60% | 25% | -58% |

### è®¡ç®—å¤æ‚åº¦åˆ†æ

```
ç°æœ‰æ–¹æ¡ˆï¼šO(n) - çº¿æ€§æ‰«æ + ç®€å•è®¡ç®—
SMDå¢å¼ºï¼šO(nÂ·log(m)) - TF-IDFç´¢å¼• + å‘é‡è®¡ç®—
å…¶ä¸­ï¼šn=å€™é€‰è¡¨æ•°é‡ï¼Œm=è¯æ±‡è¡¨å¤§å°

å®é™…å½±å“ï¼š5ms â†’ 8msï¼ˆå¯æ¥å—çš„æ€§èƒ½ä»£ä»·ï¼‰
```

---

## ğŸ”Œ ç³»ç»Ÿé›†æˆæ–¹æ¡ˆ

### é›†æˆç­–ç•¥1ï¼šç›´æ¥æ›¿æ¢

```python
# åœ¨ src/agents/searcher_agent.py ä¸­
class SearcherAgent(BaseAgent):
    def __init__(self):
        # æ›¿æ¢åŸæœ‰è¿‡æ»¤å™¨
        self.metadata_filter = SMDMetadataFilterAdapter()
        
    def _metadata_search(self, query_table, all_tables, analysis):
        # ä½¿ç”¨å¢å¼ºè¿‡æ»¤å™¨
        return self.metadata_filter.filter_candidates(
            query_table=query_table,
            all_tables=all_tables,
            threshold=0.4,
            max_candidates=800
        )
```

### é›†æˆç­–ç•¥2ï¼šé…ç½®åˆ‡æ¢

```yaml
# config.yml
metadata_filter:
  mode: "enhanced_smd"  # original | enhanced_smd
  
  smd_enhanced:
    # TF-IDFé…ç½®
    tfidf_max_features: 1000
    tfidf_ngram_range: [1, 2]
    
    # ç›¸ä¼¼åº¦æƒé‡
    text_similarity_weight: 0.6
    structural_similarity_weight: 0.4
    
    # è¿‡æ»¤å‚æ•°
    similarity_threshold: 0.4
    max_candidates: 800
    
    # æ€§èƒ½ä¼˜åŒ–
    enable_caching: true
    cache_size: 10000
```

### æ¥å£å…¼å®¹æ€§

```python
class SMDMetadataFilterAdapter:
    """é€‚é…å™¨æ¨¡å¼ä¿æŒæ¥å£å…¼å®¹"""
    
    def filter_candidates(
        self, 
        query_table: TableInfo,
        all_tables: List[TableInfo],
        max_candidates: int = 1000,
        threshold: float = 0.3
    ) -> List[Tuple[str, float]]:
        """
        ä¸åŸæ¥å£å®Œå…¨å…¼å®¹
        è¿”å›ï¼š[(table_name, similarity_score), ...]
        """
        return self.enhanced_filter.filter_candidates(
            query_table, 
            candidate_threshold=threshold,
            max_candidates=max_candidates
        )
```

---

## ğŸ“… å®æ–½è®¡åˆ’

### Phase 1: æ ¸å¿ƒå¼€å‘ï¼ˆ1-2å¤©ï¼‰

**Day 1ï¼šæ ¸å¿ƒå®ç°**
- [ ] å®ç°`SMDEnhancedMetadataFilter`ç±»
- [ ] å®ŒæˆTF-IDFæ–‡æœ¬ç‰¹å¾æå–
- [ ] å®ç°å¢å¼ºç»“æ„ç‰¹å¾åˆ†æ
- [ ] å¼€å‘ç›¸ä¼¼åº¦è®¡ç®—ç®—æ³•

**Day 2ï¼šé›†æˆé€‚é…**
- [ ] åˆ›å»º`SMDMetadataFilterAdapter`é€‚é…å™¨
- [ ] æ›´æ–°`SearcherAgent`é›†æˆé€»è¾‘
- [ ] é…ç½®æ–‡ä»¶å‚æ•°æ”¯æŒ
- [ ] åŸºç¡€å•å…ƒæµ‹è¯•

### Phase 2: æµ‹è¯•ä¼˜åŒ–ï¼ˆ2-3å¤©ï¼‰

**Day 3-4ï¼šåŠŸèƒ½æµ‹è¯•**
- [ ] åœ¨æµ‹è¯•æ•°æ®é›†ä¸ŠéªŒè¯åŠŸèƒ½
- [ ] A/Bæµ‹è¯•å¯¹æ¯”åŸæ–¹æ¡ˆ
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] å‚æ•°è°ƒä¼˜å®éªŒ

**Day 5ï¼šç”Ÿäº§å‡†å¤‡**
- [ ] é”™è¯¯å¤„ç†å®Œå–„
- [ ] æ—¥å¿—å’Œç›‘æ§é›†æˆ
- [ ] æ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—
- [ ] ä»£ç å®¡æŸ¥

### Phase 3: éƒ¨ç½²ç›‘æ§ï¼ˆ1å¤©ï¼‰

**Day 6ï¼šç”Ÿäº§éƒ¨ç½²**
- [ ] ç°åº¦å‘å¸ƒï¼ˆ10%æµé‡ï¼‰
- [ ] æŒ‡æ ‡ç›‘æ§éªŒè¯
- [ ] å…¨é‡åˆ‡æ¢
- [ ] æ€§èƒ½ç›‘æ§æŠ¥å‘Š

---

## ğŸ› ï¸ ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹

```python
# 1. åˆ›å»ºå¢å¼ºè¿‡æ»¤å™¨
smd_filter = SMDEnhancedMetadataFilter(max_features=1000)

# 2. æ„å»ºç´¢å¼•ï¼ˆä¸€æ¬¡æ€§æ“ä½œï¼‰
all_tables = load_tables_from_data_lake()
smd_filter.build_index(all_tables)

# 3. æŸ¥è¯¢è¿‡æ»¤
query_table = load_query_table()
candidates = smd_filter.filter_candidates(
    query_table=query_table,
    candidate_threshold=0.4,
    max_candidates=800
)

# 4. ç»“æœå¤„ç†
for table_name, similarity_score in candidates:
    print(f"å€™é€‰è¡¨: {table_name}, ç›¸ä¼¼åº¦: {similarity_score:.3f}")
```

### å‚æ•°è°ƒä¼˜æŒ‡å—

#### ç›¸ä¼¼åº¦é˜ˆå€¼é€‰æ‹©
```python
# é«˜ç²¾åº¦ä½å¬å›ï¼šthreshold = 0.5-0.6
# å¹³è¡¡ç²¾åº¦å¬å›ï¼šthreshold = 0.4-0.5  â† æ¨è
# é«˜å¬å›ä½ç²¾åº¦ï¼šthreshold = 0.3-0.4
```

#### TF-IDFå‚æ•°è°ƒä¼˜
```python
# å°è¯æ±‡è¡¨é«˜æ€§èƒ½ï¼šmax_features = 500-800
# å¹³è¡¡æ€§èƒ½ç²¾åº¦ï¼šmax_features = 1000     â† æ¨è  
# å¤§è¯æ±‡è¡¨é«˜ç²¾åº¦ï¼šmax_features = 1500-2000
```

#### æƒé‡å‚æ•°è°ƒæ•´
```python
# æ–‡æœ¬ä¸»å¯¼ï¼ˆå¤æ‚è¡¨åï¼‰ï¼štext_weight = 0.7, struct_weight = 0.3
# å¹³è¡¡æƒé‡ï¼ˆæ ‡å‡†åœºæ™¯ï¼‰ï¼štext_weight = 0.6, struct_weight = 0.4  â† æ¨è
# ç»“æ„ä¸»å¯¼ï¼ˆç®€å•è¡¨åï¼‰ï¼štext_weight = 0.5, struct_weight = 0.5
```

### æ•…éšœæ’é™¤

#### å¸¸è§é—®é¢˜

1. **TF-IDFå‘é‡åŒ–å¤±è´¥**
   - æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†`build_index()`
   - ç¡®è®¤è¡¨æ•°æ®æ ¼å¼æ­£ç¡®
   - éªŒè¯æ–‡æœ¬å†…å®¹éç©º

2. **ç›¸ä¼¼åº¦åˆ†æ•°å¼‚å¸¸**
   - æ£€æŸ¥æƒé‡å‚æ•°é…ç½®
   - éªŒè¯ç‰¹å¾æå–æ˜¯å¦æ­£å¸¸
   - ç¡®è®¤ç›¸ä¼¼åº¦è®¡ç®—é€»è¾‘

3. **æ€§èƒ½é—®é¢˜**
   - è°ƒæ•´`max_features`å‚æ•°
   - å¯ç”¨ç‰¹å¾ç¼“å­˜
   - è€ƒè™‘ç´¢å¼•ä¼˜åŒ–

#### è°ƒè¯•å·¥å…·

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.getLogger('SMDEnhancedMetadataFilter').setLevel(logging.DEBUG)

# æŸ¥çœ‹ç‰¹å¾è¯¦æƒ…
features = smd_filter._extract_structural_features(table)
print(json.dumps(features, indent=2))

# æ£€æŸ¥TF-IDFå‘é‡
tfidf_vector = smd_filter.tfidf_features[table_name]
print(f"TF-IDFå‘é‡ç»´åº¦: {len(tfidf_vector)}")
print(f"éé›¶ç‰¹å¾æ•°é‡: {np.count_nonzero(tfidf_vector)}")
```

---

## ğŸ“ˆ ç›‘æ§æŒ‡æ ‡

### æ ¸å¿ƒæŒ‡æ ‡

```yaml
# ç²¾åº¦æŒ‡æ ‡
smd_filter_precision: ç›®æ ‡ > 0.8
smd_filter_recall: ç›®æ ‡ > 0.85
smd_filter_f1_score: ç›®æ ‡ > 0.82

# æ€§èƒ½æŒ‡æ ‡  
smd_filter_latency_p95: ç›®æ ‡ < 10ms
smd_filter_throughput: ç›®æ ‡ > 100 QPS
smd_filter_cache_hit_rate: ç›®æ ‡ > 90%

# ä¸šåŠ¡æŒ‡æ ‡
candidate_reduction_rate: ç›®æ ‡ > 90%
false_positive_rate: ç›®æ ‡ < 25%
downstream_efficiency: Layer2/3å¤„ç†æé€Ÿ > 15%
```

### æŠ¥è­¦è§„åˆ™

```yaml
# ç²¾åº¦ä¸‹é™æŠ¥è­¦
- alert: SMD_Filter_Precision_Low
  expr: smd_filter_precision < 0.75
  duration: 5m
  message: "SMDè¿‡æ»¤å™¨ç²¾åº¦ä½äºé˜ˆå€¼"

# æ€§èƒ½å¼‚å¸¸æŠ¥è­¦  
- alert: SMD_Filter_Latency_High
  expr: smd_filter_latency_p95 > 15ms
  duration: 2m
  message: "SMDè¿‡æ»¤å™¨å»¶è¿Ÿè¿‡é«˜"
```

---

