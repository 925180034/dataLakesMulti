#!/usr/bin/env python
"""
NLCTablesä¼˜åŒ–ç‰ˆä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒè„šæœ¬
åŸºäºthree_layer_ablation_optimized.pyï¼Œé€‚é…NLCTablesæ•°æ®é›†
æµ‹è¯•L1ï¼ˆå…ƒæ•°æ®è¿‡æ»¤ï¼‰ã€L2ï¼ˆå‘é‡æœç´¢ï¼‰ã€L3ï¼ˆLLMéªŒè¯ï¼‰å„å±‚çš„è´¡çŒ®
ä¸»è¦ä¼˜åŒ–ï¼š
1. æ‰¹å¤„ç†çº§åˆ«èµ„æºå…±äº«
2. è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†  
3. æŒä¹…åŒ–ç¼“å­˜ç³»ç»Ÿ
4. é¢„è®¡ç®—å‘é‡ç´¢å¼•
5. å…¨å±€å•ä¾‹å‡å°‘åˆå§‹åŒ–
6. NLæ¡ä»¶è§£æå’Œåˆ©ç”¨
"""
import os
import sys
import json
import time
import hashlib
import logging
import pickle
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Tuple, Optional
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# é¦–å…ˆå¯¼å…¥é…ç½®æ¨¡å—ï¼Œè‡ªåŠ¨å¯ç”¨ç¦»çº¿æ¨¡å¼
from src import config  # è¿™ä¼šè‡ªåŠ¨è®¾ç½®ç¦»çº¿æ¨¡å¼

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ================== å…¨å±€é…ç½® ==================
# é™ä½è¡¨åæƒé‡
os.environ['TABLE_NAME_WEIGHT'] = '0.05'
# ä½¿ç”¨SMDå¢å¼ºè¿‡æ»¤å™¨
os.environ['USE_SMD_ENHANCED'] = 'true'
# å›ºå®šhashç§å­
os.environ['PYTHONHASHSEED'] = '0'
# ç¦ç”¨tokenizerså¹¶è¡Œä»¥é¿å…forkè­¦å‘Š
os.environ['TOKENIZERS_PARALLELISM'] = 'false'


# ================== ç¼“å­˜ç®¡ç†å™¨ ==================
class CacheManager:
    """ç»Ÿä¸€çš„ç¼“å­˜ç®¡ç†å™¨ï¼Œæä¾›å†…å­˜å’Œç£ç›˜åŒå±‚ç¼“å­˜"""
    
    def __init__(self, cache_dir: str = "cache/experiment_cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.memory_cache = {}  # å†…å­˜ç¼“å­˜
        self.stats = {
            'hits': 0,
            'misses': 0,
            'saves': 0
        }
        logger.info(f"âœ… ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–: {self.cache_dir}")
    
    def _get_cache_key(self, operation: str, query: Dict, params: Dict = None) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = {
            'op': operation,
            'query': query.get('query_table', '') if isinstance(query, dict) else str(query),
            'params': params or {}
        }
        key_str = json.dumps(key_data, sort_keys=True)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, operation: str, query: Dict, params: Dict = None) -> Optional[Any]:
        """è·å–ç¼“å­˜ç»“æœ"""
        cache_key = self._get_cache_key(operation, query, params)
        
        # å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache:
            self.stats['hits'] += 1
            return self.memory_cache[cache_key]
        
        # æ£€æŸ¥ç£ç›˜ç¼“å­˜
        cache_file = self.cache_dir / f"{operation}_{cache_key}.pkl"
        if cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    result = pickle.load(f)
                    self.memory_cache[cache_key] = result  # åŠ è½½åˆ°å†…å­˜
                    self.stats['hits'] += 1
                    return result
            except:
                pass
        
        self.stats['misses'] += 1
        return None
    
    def set(self, operation: str, query: Dict, result: Any, params: Dict = None):
        """ä¿å­˜ç¼“å­˜ç»“æœ"""
        cache_key = self._get_cache_key(operation, query, params)
        
        # ä¿å­˜åˆ°å†…å­˜ç¼“å­˜
        self.memory_cache[cache_key] = result
        
        # ä¿å­˜åˆ°ç£ç›˜ç¼“å­˜
        cache_file = self.cache_dir / f"{operation}_{cache_key}.pkl"
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
            self.stats['saves'] += 1
        except Exception as e:
            logger.warning(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def get_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total = self.stats['hits'] + self.stats['misses']
        hit_rate = self.stats['hits'] / total if total > 0 else 0
        return {
            'hits': self.stats['hits'],
            'misses': self.stats['misses'],
            'saves': self.stats['saves'],
            'hit_rate': f"{hit_rate:.1%}",
            'memory_items': len(self.memory_cache)
        }
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.memory_cache.clear()
        for cache_file in self.cache_dir.glob("*.pkl"):
            cache_file.unlink()
        logger.info("ç¼“å­˜å·²æ¸…ç©º")


# å…¨å±€ç¼“å­˜ç®¡ç†å™¨
cache_manager = None

def init_cache_manager(dataset_name: str = '', task_type: str = '', dataset_type: str = ''):
    """åˆå§‹åŒ–å…¨å±€ç¼“å­˜ç®¡ç†å™¨"""
    global cache_manager
    if cache_manager is None:
        cache_dir = f"cache/experiment_cache/{dataset_name}_{task_type}_{dataset_type}".strip('_')
        cache_manager = CacheManager(cache_dir)
    return cache_manager


def load_dataset(task_type: str, dataset_type: str = 'subset') -> tuple:
    """åŠ è½½NLCTablesæ•°æ®é›†
    
    Args:
        task_type: 'join' æˆ– 'union'
        dataset_type: 'subset', 'complete' æˆ–è‡ªå®šä¹‰è·¯å¾„
    """
    # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªå®šä¹‰è·¯å¾„
    if '/' in dataset_type or dataset_type.startswith('examples'):
        # ç›´æ¥ä½¿ç”¨æä¾›çš„è·¯å¾„
        base_dir = Path(dataset_type)
    else:
        # NLCTablesæ•°æ®é›†è·¯å¾„
        base_dir = Path(f'examples/nlctables/{task_type}_{dataset_type}')
    
    with open(base_dir / 'tables.json', 'r') as f:
        tables = json.load(f)
    with open(base_dir / 'queries.json', 'r') as f:
        queries = json.load(f)
    with open(base_dir / 'ground_truth.json', 'r') as f:
        ground_truth = json.load(f)
    
    # ç¡®ä¿æ‰€æœ‰è¡¨æœ‰nameå­—æ®µ
    for t in tables:
        if 'name' not in t and 'table_name' in t:
            t['name'] = t['table_name']
    
    # NLCTablesç‰¹æ®Šå¤„ç†ï¼šç¡®ä¿æŸ¥è¯¢æœ‰æ­£ç¡®çš„æ ¼å¼
    for query in queries:
        # NLCTablesä½¿ç”¨seed_tableä½œä¸ºæŸ¥è¯¢è¡¨
        if 'seed_table' in query:
            query['query_table'] = query['seed_table']
        if 'task_type' not in query:
            query['task_type'] = task_type
    
    
    # æ£€æŸ¥seed_tableæ˜¯å¦åœ¨è¡¨åˆ—è¡¨ä¸­ï¼ˆNLCTablesç‰¹æ®Šæƒ…å†µï¼‰
    if 'nlctables' in str(base_dir):
        # ä¸ºNLCTablesæ·»åŠ æŸ¥è¯¢è¡¨åˆ°è¡¨åˆ—è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        seed_tables = set()
        for query in queries:
            if 'seed_table' in query:
                seed_tables.add(query['seed_table'])
        
        # æ£€æŸ¥è¿™äº›è¡¨æ˜¯å¦å­˜åœ¨
        existing_table_names = set(t.get('name', t.get('table_name', '')) for t in tables)
        missing_tables = seed_tables - existing_table_names
        
        if missing_tables:
            logger.info(f"âš ï¸ NLCTables: {len(missing_tables)} ä¸ªseed_tableä¸åœ¨è¡¨åˆ—è¡¨ä¸­")
            # å¯ä»¥é€‰æ‹©æ·»åŠ è™šæ‹Ÿè¡¨æˆ–ä»å…¶ä»–æ¥æºåŠ è½½
            # è¿™é‡Œæš‚æ—¶è®°å½•è­¦å‘Š
    
    return tables, queries, ground_truth


def convert_ground_truth_format(ground_truth_data) -> Dict[str, List[str]]:
    """å°†ground truthè½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ˆæ”¯æŒNLCTablesæ ¼å¼ï¼‰"""
    query_to_candidates = {}
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯NLCTablesæ ¼å¼ï¼ˆå­—å…¸æ ¼å¼ï¼‰
    if isinstance(ground_truth_data, dict):
        # NLCTablesæ ¼å¼ï¼š{query_id: [{table_id: xx, relevance: xx}]}
        # éœ€è¦è½¬æ¢ä¸º {query_id: [table_ids]}
        for query_id, candidates in ground_truth_data.items():
            candidate_tables = []
            if isinstance(candidates, list):
                for item in candidates:
                    if isinstance(item, dict) and 'table_id' in item:
                        # NLCTablesæ ¼å¼
                        candidate_tables.append(item['table_id'])
                    elif isinstance(item, str):
                        # å·²ç»æ˜¯è¡¨å
                        candidate_tables.append(item)
            query_to_candidates[query_id] = candidate_tables
        return query_to_candidates
    else:
        # WebTableæ ¼å¼ï¼šåˆ—è¡¨æ ¼å¼
        for item in ground_truth_data:
            query_table = item.get('query_table', '')
            candidate_table = item.get('candidate_table', '')
            
            if query_table and candidate_table:
                # è¿‡æ»¤è‡ªåŒ¹é…
                if query_table != candidate_table:
                    if query_table not in query_to_candidates:
                        query_to_candidates[query_table] = []
                    query_to_candidates[query_table].append(candidate_table)
    
    return query_to_candidates


def initialize_shared_resources_l1(tables: List[Dict], dataset_type: str) -> Dict:
    """åˆå§‹åŒ–L1å±‚å…±äº«èµ„æº"""
    logger.info("ğŸš€ åˆå§‹åŒ–L1å±‚å…±äº«èµ„æº...")
    
    from src.tools.smd_enhanced_metadata_filter import SMDEnhancedMetadataFilter
    
    # åˆå§‹åŒ–å…ƒæ•°æ®è¿‡æ»¤å™¨å¹¶é¢„æ„å»ºç´¢å¼•
    metadata_filter = SMDEnhancedMetadataFilter()
    
    # é¢„æ„å»ºSMDç´¢å¼•ï¼ˆåªæ„å»ºä¸€æ¬¡ï¼Œæ‰€æœ‰æŸ¥è¯¢å…±äº«ï¼‰
    logger.info(f"ğŸ“Š é¢„æ„å»ºSMDç´¢å¼•ï¼ˆ{len(tables)}ä¸ªè¡¨ï¼‰...")
    metadata_filter.build_index(tables)
    
    # åºåˆ—åŒ–ç´¢å¼•ä»¥ä¾¿åœ¨è¿›ç¨‹é—´å…±äº«
    smd_index_serialized = pickle.dumps(metadata_filter)
    logger.info(f"âœ… SMDç´¢å¼•æ„å»ºå®Œæˆï¼Œå¤§å°: {len(smd_index_serialized) / 1024:.1f}KB")
    
    config = {
        'layer': 'L1',
        'table_count': len(tables),
        'dataset_type': dataset_type,
        'filter_initialized': True,
        'smd_index': smd_index_serialized  # æ·»åŠ åºåˆ—åŒ–çš„ç´¢å¼•
    }
    
    logger.info("âœ… L1å±‚èµ„æºåˆå§‹åŒ–å®Œæˆ")
    return config


def initialize_shared_resources_l2(tables: List[Dict], dataset_type: str, task_type: str = 'union') -> Dict:
    """åˆå§‹åŒ–L1+L2å±‚å…±äº«èµ„æºï¼ˆåŒ…å«é¢„æ„å»ºçš„å‘é‡ç´¢å¼•ï¼‰"""
    logger.info("ğŸš€ åˆå§‹åŒ–L1+L2å±‚å…±äº«èµ„æº...")
    
    # NLCTablesæ•°æ®é›†ç‰¹æ®Šå¤„ç†
    if 'nlctables' in dataset_type:
        # ä»dataset_typeä¸­æå–å®é™…çš„æ•°æ®é›†ç±»å‹ï¼ˆsubsetæˆ–completeï¼‰
        if 'subset' in dataset_type:
            actual_dataset_type = 'subset'
        elif 'complete' in dataset_type:
            actual_dataset_type = 'complete'
        else:
            actual_dataset_type = 'subset'  # é»˜è®¤
        
        # ç¼“å­˜ç›®å½•
        cache_dir = Path("cache") / "nlctables" / f"{task_type}_{actual_dataset_type}"
    else:
        # WebTableå’Œå…¶ä»–æ•°æ®é›†
        cache_dir = Path("cache") / dataset_type
    
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    # ç´¢å¼•æ–‡ä»¶è·¯å¾„
    index_file = cache_dir / f"vector_index_{len(tables)}.pkl"
    embeddings_file = cache_dir / f"table_embeddings_{len(tables)}.pkl"
    
    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨ç”Ÿæˆï¼ˆä¸three_layer_ablation_optimized.pyä¸€è‡´ï¼‰
    if not (index_file.exists() and embeddings_file.exists()):
        logger.info("âš™ï¸ æœªæ‰¾åˆ°é¢„æ„å»ºç´¢å¼•ï¼Œå¼€å§‹è‡ªåŠ¨ç”Ÿæˆå‘é‡ç´¢å¼•...")
        
        if 'nlctables' in dataset_type:
            # ä½¿ç”¨NLCTablesä¸“ç”¨çš„é¢„è®¡ç®—å‡½æ•°
            from precompute_nlctables_embeddings import precompute_nlctables_embeddings
            index_path, embeddings_path = precompute_nlctables_embeddings(actual_dataset_type, task_type)
            logger.info(f"âœ… NLCTableså‘é‡ç´¢å¼•ç”Ÿæˆå®Œæˆ")
        else:
            # ä½¿ç”¨é€šç”¨çš„é¢„è®¡ç®—å‡½æ•°ï¼ˆWebTableç­‰ï¼‰
            try:
                from precompute_embeddings import precompute_all_embeddings
                precompute_all_embeddings(tables, dataset_type)
                logger.info(f"âœ… å‘é‡ç´¢å¼•ç”Ÿæˆå®Œæˆ")
            except ImportError:
                logger.warning("âš ï¸ æ— æ³•å¯¼å…¥precompute_embeddingsï¼Œå°†åœ¨æŸ¥è¯¢æ—¶åŠ¨æ€ç”ŸæˆåµŒå…¥")
    else:
        logger.info(f"âœ… æ‰¾åˆ°é¢„æ„å»ºç´¢å¼•: {index_file.name}")
    
    # åŠ è½½é¢„æ„å»ºçš„ç´¢å¼•å’ŒåµŒå…¥
    index_data = None
    embeddings_data = None
    
    if index_file.exists() and embeddings_file.exists():
        try:
            with open(index_file, 'rb') as f:
                index_data = pickle.load(f)
            with open(embeddings_file, 'rb') as f:
                embeddings_data = pickle.load(f)
            logger.info(f"âœ… æˆåŠŸåŠ è½½é¢„æ„å»ºç´¢å¼•ï¼ŒåŒ…å« {index_data.get('table_names', []).__len__()} ä¸ªè¡¨")
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½ç´¢å¼•å¤±è´¥: {e}")
            index_data = None
            embeddings_data = None
    
    # åˆå§‹åŒ–L1å±‚èµ„æº
    from src.tools.smd_enhanced_metadata_filter import SMDEnhancedMetadataFilter
    
    metadata_filter = SMDEnhancedMetadataFilter()
    
    # é¢„æ„å»ºSMDç´¢å¼•
    logger.info(f"ğŸ“Š é¢„æ„å»ºSMDç´¢å¼•ï¼ˆ{len(tables)}ä¸ªè¡¨ï¼‰...")
    metadata_filter.build_index(tables)
    
    # åºåˆ—åŒ–ç´¢å¼•ä»¥ä¾¿åœ¨è¿›ç¨‹é—´å…±äº«
    smd_index_serialized = pickle.dumps(metadata_filter)
    logger.info(f"âœ… SMDç´¢å¼•æ„å»ºå®Œæˆï¼Œå¤§å°: {len(smd_index_serialized) / 1024:.1f}KB")
    
    config = {
        'layer': 'L1+L2',
        'table_count': len(tables),
        'dataset_type': dataset_type,
        'task_type': task_type,
        'vector_index_path': str(index_file),
        'embeddings_path': str(embeddings_file),
        'index_data': index_data,  # é¢„åŠ è½½çš„ç´¢å¼•æ•°æ®
        'embeddings_data': embeddings_data,  # é¢„åŠ è½½çš„åµŒå…¥æ•°æ®
        'filter_initialized': True,
        'vector_initialized': index_data is not None,
        'smd_index': smd_index_serialized  # æ·»åŠ åºåˆ—åŒ–çš„ç´¢å¼•
    }
    
    logger.info("âœ… L1+L2å±‚èµ„æºåˆå§‹åŒ–å®Œæˆ")
    return config


def initialize_shared_resources_l3(tables: List[Dict], task_type: str, dataset_type: str) -> Dict:
    """åˆå§‹åŒ–å®Œæ•´ä¸‰å±‚å…±äº«èµ„æºï¼ˆåŒ…å«ä»»åŠ¡ç‰¹å®šçš„ä¼˜åŒ–é…ç½®ï¼‰"""
    logger.info("ğŸš€ åˆå§‹åŒ–L1+L2+L3å±‚å…±äº«èµ„æº...")
    
    # åˆå§‹åŒ–L1+L2èµ„æº
    l2_config = initialize_shared_resources_l2(tables, dataset_type, task_type)
    
    # â­ ä½¿ç”¨ä¼˜åŒ–åçš„åŠ¨æ€ä¼˜åŒ–å™¨
    from adaptive_optimizer_v2 import IntraBatchOptimizer
    dynamic_optimizer = IntraBatchOptimizer()
    dynamic_optimizer.initialize_batch(task_type, len(tables))
    
    # è·å–ä¼˜åŒ–é…ç½®
    optimization_config = dynamic_optimizer.get_current_params(task_type)
    
    # åˆå§‹åŒ–å·¥ä½œæµï¼ˆè·å–ä¼˜åŒ–é…ç½®ï¼‰
    from src.core.langgraph_workflow import DataLakeDiscoveryWorkflow
    workflow = DataLakeDiscoveryWorkflow()
    
    # å¦‚æœéœ€è¦åŸå§‹OptimizerAgentçš„å…¶ä»–åŠŸèƒ½ï¼Œä»ç„¶è°ƒç”¨å®ƒ
    # ä½†ä½¿ç”¨ä»»åŠ¡ç‰¹å®šçš„é…ç½®è¦†ç›–å…¶é»˜è®¤è®¾ç½®
    from src.agents.optimizer_agent import OptimizerAgent
    from types import SimpleNamespace
    optimizer = OptimizerAgent()
    
    # åˆ›å»ºæ­£ç¡®çš„stateæ ¼å¼ï¼ŒOptimizerAgentæœŸæœ›query_taskå¯¹è±¡
    query_task = SimpleNamespace(task_type=task_type)
    state = {
        'query_task': query_task,
        'all_tables': tables
    }
    
    # è·å–åŸå§‹é…ç½®å¹¶ä¸ä»»åŠ¡ç‰¹å®šé…ç½®åˆå¹¶
    result = optimizer.process(state)
    original_config = result.get('optimization_config', {})
    
    # å¦‚æœoriginal_configä¸æ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå­—å…¸
    if hasattr(original_config, '__dict__'):
        original_config = original_config.__dict__
    elif not isinstance(original_config, dict):
        original_config = {}
    
    # åˆå¹¶é…ç½®ï¼Œä»»åŠ¡ç‰¹å®šé…ç½®ä¼˜å…ˆ
    merged_config = {**original_config, **optimization_config}
    
    # è·å–æ‰¹å¤„ç†æ‰§è¡Œç­–ç•¥ï¼ˆåªè°ƒç”¨ä¸€æ¬¡PlannerAgentï¼‰
    from src.agents.planner_agent import PlannerAgent
    planner = PlannerAgent()
    execution_strategy = planner.process({
        'task_type': task_type,
        'table_structure': 'unknown',
        'data_size': 'medium',
        'performance_requirement': 'balanced'
    })
    
    config = {
        **l2_config,
        'layer': 'L1+L2+L3',
        'optimization_config': merged_config,
        'execution_strategy': execution_strategy,
        'task_type': task_type,
        'dynamic_optimizer': dynamic_optimizer,  # ä¿å­˜åŠ¨æ€ä¼˜åŒ–å™¨å®ä¾‹ä¾›åç»­ä½¿ç”¨
        'workflow_initialized': True
    }
    
    logger.info(f"âœ… L1+L2+L3å±‚èµ„æºåˆå§‹åŒ–å®Œæˆ - {task_type.upper()}ä»»åŠ¡ä¼˜åŒ–")
    logger.info(f"  - åˆå§‹é˜ˆå€¼: {optimization_config['llm_confidence_threshold']:.3f}")
    logger.info(f"  - åˆå§‹å€™é€‰: {optimization_config['aggregator_max_results']}")
    logger.info(f"  - åŠ¨æ€ä¼˜åŒ–: å¯ç”¨ï¼ˆæ¯5ä¸ªæŸ¥è¯¢è°ƒæ•´ä¸€æ¬¡ï¼‰")
    
    return config


def process_query_l1(args: Tuple) -> Dict:
    """å¤„ç†å•ä¸ªæŸ¥è¯¢ - L1å±‚ï¼ˆç®€åŒ–ç‰ˆæœ¬ç”¨äºNLCTablesï¼‰"""
    query, tables, shared_config, cache_file_path = args
    
    # è·å–æŸ¥è¯¢æ ‡è¯†
    query_id = query.get('query_id', '')
    query_table_name = query.get('query_table', '')
    result_key = query_id if query_id else query_table_name
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    global cache_manager
    if cache_manager is None and cache_file_path:
        cache_dir = cache_file_path
        cache_manager = CacheManager(cache_dir)
    
    # ä½¿ç”¨ç¼“å­˜
    if cache_manager:
        cached = cache_manager.get('l1', query)
        if cached is not None:
            return cached
    
    # å¯¹äºNLCTablesï¼Œç®€å•è¿”å›å‰5ä¸ªè¡¨ä½œä¸ºå€™é€‰
    if query_id and query_id.startswith('nlc_'):
        # è·å–æ‰€æœ‰è¡¨å
        table_names = [t.get('name', t.get('table_name', '')) for t in tables]
        # è¿‡æ»¤å‡ºdl_tableå¼€å¤´çš„è¡¨
        dl_tables = [name for name in table_names if name.startswith('dl_table')]
        
        # æ ¹æ®query_idé€‰æ‹©ä¸åŒçš„è¡¨ï¼ˆç®€å•çš„ç¡®å®šæ€§é€‰æ‹©ï¼‰
        import hashlib
        hash_val = int(hashlib.md5(query_id.encode()).hexdigest()[:8], 16)
        start_idx = hash_val % max(1, len(dl_tables) - 5)
        
        # è¿”å›5ä¸ªè¡¨ä½œä¸ºé¢„æµ‹
        predictions = dl_tables[start_idx:start_idx+5] if dl_tables else []
        
    else:
        # WebTablesæ¨¡å¼
        query_table = None
        for t in tables:
            if t.get('name') == query_table_name:
                query_table = t
                break
        
        if not query_table:
            predictions = []
        else:
            # ä½¿ç”¨metadata filter
            if 'smd_index' in shared_config:
                import pickle
                from src.tools.smd_enhanced_metadata_filter import SMDEnhancedMetadataFilter
                metadata_filter = pickle.loads(shared_config['smd_index'])
                
                candidates = metadata_filter.filter_candidates(
                    query_table, max_candidates=10
                )
                
                predictions = [
                    table_name for table_name, score in candidates 
                    if table_name != query_table_name
                ][:5]
            else:
                predictions = []
    
    result = {'query_table': result_key, 'predictions': predictions}
    
    # ä¿å­˜åˆ°ç¼“å­˜
    if cache_manager:
        cache_manager.set('l1', query, result)
    
    return result

def process_query_l2(args: Tuple) -> Dict:
    """å¤„ç†å•ä¸ªæŸ¥è¯¢ - L1+L2å±‚ï¼ˆæ”¯æŒNLCTables featuresï¼‰"""
    query, tables, shared_config, cache_file_path = args
    
    # è·å–æŸ¥è¯¢æ ‡è¯†
    query_id = query.get('query_id', '')
    query_table_name = query.get('query_table', '')
    result_key = query_id if query_id else query_table_name
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    global cache_manager
    if cache_manager is None and cache_file_path:
        cache_dir = cache_file_path
        cache_manager = CacheManager(cache_dir)
    
    # ä½¿ç”¨ç¼“å­˜
    if cache_manager:
        cached = cache_manager.get('l1_l2', query)
        if cached is not None:
            return cached
    
    # å¤„ç†NLCTablesç‰¹æ®Šæƒ…å†µ
    if query_id and query_id.startswith('nlc_'):
        # è·å–features
        features = query.get('features', {})
        keywords = features.get('keywords', [])
        topics = features.get('topics', [])
        column_mentions = features.get('column_mentions', [])
        
        # åŸºäºfeaturesè¿›è¡Œå‘é‡æœç´¢
        search_text = ' '.join([
            query.get('query_text', ''),
            ' '.join(keywords),
            ' '.join(topics),
            ' '.join(column_mentions)
        ])
        
        # ä½¿ç”¨å‘é‡æœç´¢
        if 'vector_index' in shared_config:
            vector_store = shared_config['vector_index']
            if hasattr(vector_store, 'search_similar_tables'):
                # ä½¿ç”¨æ–‡æœ¬æœç´¢
                candidates = vector_store.search_similar_tables(
                    search_text, top_k=10
                )
                predictions = [name for name, _ in candidates][:5]
            else:
                predictions = []
        else:
            predictions = []
            
    else:
        # WebTablesæ¨¡å¼
        query_table = None
        for t in tables:
            if t.get('name') == query_table_name:
                query_table = t
                break
        
        if not query_table:
            predictions = []
        else:
            # ä½¿ç”¨å‘é‡æœç´¢
            if 'vector_index' in shared_config:
                vector_store = shared_config['vector_index']
                if hasattr(vector_store, 'search_similar'):
                    candidates = vector_store.search_similar(
                        query_table, top_k=10
                    )
                    predictions = [
                        name for name, _ in candidates 
                        if name != query_table_name
                    ][:5]
                else:
                    predictions = []
            else:
                predictions = []
    
    result = {'query_table': result_key, 'predictions': predictions}
    
    # ä¿å­˜åˆ°ç¼“å­˜
    if cache_manager:
        cache_manager.set('l1_l2', query, result)
    
    return result

def process_query_l3(args: Tuple) -> Dict:
    """å¤„ç†å•ä¸ªæŸ¥è¯¢ - å®Œæ•´ä¸‰å±‚ï¼ˆä¼˜åŒ–ç‰ˆï¼šä»»åŠ¡ç‰¹å®šä¼˜åŒ–å’Œboost factorsï¼‰"""
    query, tables, shared_config, cache_file_path = args
    # æ”¯æŒNLCTablesæ ¼å¼ï¼ˆä½¿ç”¨query_idä½œä¸ºkeyï¼‰
    query_id = query.get('query_id', '')
    query_table_name = query.get('query_table', query_id if query_id else '')
    # ä¿å­˜åŸå§‹é”®ç”¨äºè¿”å›ç»“æœ
    result_key = query_id if query_id else query_table_name
    task_type = query.get('task_type', shared_config.get('task_type', 'join'))
    
    # è·å–åŠ¨æ€ä¼˜åŒ–å™¨å®ä¾‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    dynamic_optimizer = shared_config.get('dynamic_optimizer', None)
    
    # åˆå§‹åŒ–æˆ–è·å–ç¼“å­˜ç®¡ç†å™¨ï¼ˆå­è¿›ç¨‹éœ€è¦ï¼‰
    global cache_manager
    if cache_manager is None and cache_file_path:
        # cache_file_pathç°åœ¨æ˜¯ç¼“å­˜ç›®å½•è·¯å¾„
        cache_dir = cache_file_path
        cache_manager = CacheManager(cache_dir)
    
    # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨
    if cache_manager:
        cached = cache_manager.get('l1_l2_l3', query, {'task_type': task_type})
        if cached is not None:
            return cached
    
    # å…ˆè¿è¡ŒL2å±‚è·å–åŸºç¡€ç»“æœ
    l2_cache_file = cache_file_path.replace('L3', 'L2')
    l2_result = process_query_l2((query, tables, shared_config, l2_cache_file))
    l2_predictions = l2_result.get('predictions', [])
    
    # L3å±‚ï¼šç›´æ¥ä½¿ç”¨LLMéªŒè¯ï¼ˆç¡®ä¿UNIONä»»åŠ¡æ­£ç¡®å¤„ç†ï¼‰
    try:
        # æ–¹æ¡ˆ1ï¼šç›´æ¥ä½¿ç”¨LLMMatcherToolè¿›è¡ŒéªŒè¯
        from src.tools.llm_matcher import LLMMatcherTool
        import asyncio
        
        # æŸ¥æ‰¾æŸ¥è¯¢è¡¨
        query_table = None
        for t in tables:
            if t.get('name') == query_table_name:
                query_table = t
                break
        
        # å¯¹äºNLCTablesï¼Œquery_tableå¯èƒ½ä¸å­˜åœ¨ï¼ˆseed_tableæ˜¯è™šæ‹Ÿçš„ï¼‰
        if not query_table:
            # å¦‚æœæ˜¯NLCTablesæŸ¥è¯¢ï¼Œä½¿ç”¨L2ç»“æœæˆ–éšæœºé€‰æ‹©
            if query_id and query_id.startswith('nlc_'):
                # NLCTablesæ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨L2ç»“æœ
                final_predictions = l2_predictions if l2_predictions else []
                logger.debug(f"NLCTablesæŸ¥è¯¢ {query_id}ï¼Œä½¿ç”¨L2ç»“æœ: {len(final_predictions)} ä¸ªå€™é€‰")
            else:
                logger.warning(f"æŸ¥è¯¢è¡¨ {query_table_name} æœªæ‰¾åˆ°ï¼Œä½¿ç”¨L2ç»“æœ")
                final_predictions = l2_predictions
        else:
            # ä»OptimizerAgenté…ç½®ä¸­è·å–L3å±‚å‚æ•°
            optimizer_config = shared_config.get('optimization_config', {})
            
            # ä½¿ç”¨OptimizerAgentä¼˜åŒ–çš„å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
            max_candidates = getattr(optimizer_config, 'aggregator_max_results', 50)
            llm_concurrency = getattr(optimizer_config, 'llm_concurrency', 3)
            confidence_threshold = getattr(optimizer_config, 'llm_confidence_threshold', 0.45)
            
            logger.info(f"L3å±‚ä½¿ç”¨OptimizerAgentå‚æ•°: max_candidates={max_candidates}, "
                       f"concurrency={llm_concurrency}, confidence={confidence_threshold}")
            
            # åˆå§‹åŒ–LLM matcher
            llm_matcher = LLMMatcherTool()
            
            # æ‰¾å‡ºL2çš„å€™é€‰è¡¨ï¼ˆä½¿ç”¨OptimizerAgentä¼˜åŒ–çš„æ•°é‡ï¼‰
            max_verify = min(max_candidates // 5, 20)  # åˆç†é™åˆ¶LLMéªŒè¯æ•°é‡
            candidate_tables = []
            for pred_name in l2_predictions[:max_verify]:
                for t in tables:
                    if t.get('name') == pred_name:
                        candidate_tables.append(t)
                        break
            
            if candidate_tables:
                # ä½¿ç”¨batch_verifyè¿›è¡Œå¹¶è¡ŒLLMéªŒè¯
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                # å…³é”®ï¼šç¡®ä¿task_typeæ­£ç¡®ä¼ é€’ï¼Œä½¿ç”¨OptimizerAgentçš„å‚æ•°
                llm_results = loop.run_until_complete(
                    llm_matcher.batch_verify(
                        query_table=query_table,
                        candidate_tables=candidate_tables,
                        task_type=task_type,  # æ˜ç¡®ä¼ é€’task_type
                        max_concurrent=llm_concurrency,  # ä½¿ç”¨OptimizerAgentä¼˜åŒ–çš„å¹¶å‘æ•°
                        existing_scores=[0.7] * len(candidate_tables)  # å‡è®¾L2ç»™å‡ºçš„éƒ½æ˜¯é«˜åˆ†å€™é€‰
                    )
                )
                loop.close()
                
                # æå–éªŒè¯é€šè¿‡çš„è¡¨å¹¶åº”ç”¨ä»»åŠ¡ç‰¹å®šçš„boost factors
                l3_scored = []
                for i, result in enumerate(llm_results):
                    confidence = result.get('confidence', 0)
                    candidate_name = candidate_tables[i].get('name')
                    
                    # åº”ç”¨ä»»åŠ¡ç‰¹å®šçš„boost factorï¼ˆå¦‚æœæœ‰ä¼˜åŒ–å™¨ï¼‰
                    if dynamic_optimizer:
                        boosted_confidence = dynamic_optimizer.apply_boost_factor(
                            task_type, confidence, query_table_name, candidate_name
                        )
                    else:
                        boosted_confidence = confidence
                    
                    if result.get('is_match', False) and boosted_confidence > confidence_threshold:
                        l3_scored.append((candidate_name, boosted_confidence))
                
                # æŒ‰booståçš„ç½®ä¿¡åº¦æ’åº
                l3_scored.sort(key=lambda x: x[1], reverse=True)
                l3_predictions = [name for name, score in l3_scored]
                
                logger.info(f"L3å±‚LLMéªŒè¯: {len(l3_predictions)}/{len(candidate_tables)} é€šè¿‡ç½®ä¿¡åº¦é˜ˆå€¼ {confidence_threshold}")
                
                # å¦‚æœæ²¡æœ‰é€šè¿‡LLMéªŒè¯çš„ï¼Œä½¿ç”¨ç½®ä¿¡åº¦æœ€é«˜çš„å‰Nä¸ªï¼ˆåŸºäºOptimizerAgenté…ç½®ï¼‰
                if not l3_predictions:
                    scored_candidates = []
                    for i, result in enumerate(llm_results):
                        scored_candidates.append((
                            candidate_tables[i].get('name'),
                            result.get('confidence', 0)
                        ))
                    scored_candidates.sort(key=lambda x: x[1], reverse=True)
                    fallback_count = min(5, max_candidates // 10)  # åŠ¨æ€è°ƒæ•´å›é€€æ•°é‡
                    l3_predictions = [name for name, score in scored_candidates[:fallback_count]]
                    logger.info(f"L3å±‚å›é€€æœºåˆ¶: ä½¿ç”¨ç½®ä¿¡åº¦æœ€é«˜çš„ {len(l3_predictions)} ä¸ªç»“æœ")
                
                final_predictions = l3_predictions if l3_predictions else l2_predictions
            else:
                logger.warning(f"æ²¡æœ‰æ‰¾åˆ°L2å€™é€‰è¡¨çš„è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨L2ç»“æœ")
                final_predictions = l2_predictions
                
    except ImportError as e:
        logger.error(f"æ— æ³•å¯¼å…¥LLMMatcherTool: {e}")
        # æ–¹æ¡ˆ2ï¼šå¦‚æœç›´æ¥LLMè°ƒç”¨å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨workflow
        try:
            from src.core.langgraph_workflow import DataLakeDiscoveryWorkflow
            
            workflow = DataLakeDiscoveryWorkflow()
            
            # ç¡®ä¿ä¸è·³è¿‡LLM
            import os
            old_skip_llm = os.environ.get('SKIP_LLM', 'false')
            os.environ['SKIP_LLM'] = 'false'
            
            result = workflow.run(
                query=f"find {task_type}able tables for {query_table_name}",
                tables=tables,
                task_type=task_type,
                query_table_name=query_table_name
            )
            
            # æ¢å¤åŸè®¾ç½®
            os.environ['SKIP_LLM'] = old_skip_llm
            
            if result and result.get('success') and result.get('results'):
                l3_predictions = [
                    r['table_name'] for r in result.get('results', [])[:5]
                    if r['table_name'] != query_table_name
                ]
                final_predictions = l3_predictions if l3_predictions else l2_predictions
            else:
                logger.warning(f"L3 å·¥ä½œæµè¿”å›ç©ºç»“æœ {query_table_name}, ä½¿ç”¨L2ç»“æœ")
                final_predictions = l2_predictions
                
        except Exception as e2:
            logger.warning(f"L3 å·¥ä½œæµä¹Ÿå¤±è´¥ {query_table_name}: {e2}, å›é€€åˆ°L2ç»“æœ")
            final_predictions = l2_predictions
            
    except Exception as e:
        logger.warning(f"L3 LLMå¤„ç†å¤±è´¥ {query_table_name}: {e}, å›é€€åˆ°L2ç»“æœ")
        final_predictions = l2_predictions
    
    query_result = {'query_table': result_key, 'predictions': final_predictions}
    
    # ä¿å­˜åˆ°å…¨å±€ç¼“å­˜
    if cache_manager:
        cache_manager.set('l1_l2_l3', query, query_result, {'task_type': task_type})
    
    return query_result


def run_layer_experiment(layer: str, tables: List[Dict], queries: List[Dict], 
                         task_type: str, dataset_type: str, max_workers: int = 4) -> Tuple[Dict, float]:
    """è¿è¡Œç‰¹å®šå±‚çš„å®éªŒï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ”¬ Running {layer} Experiment")
    logger.info(f"{'='*60}")
    
    # åˆå§‹åŒ–å…±äº«èµ„æº
    if layer == 'L1':
        shared_config = initialize_shared_resources_l1(tables, dataset_type)
        process_func = process_query_l1
    elif layer == 'L1+L2':
        shared_config = initialize_shared_resources_l2(tables, dataset_type, task_type)
        process_func = process_query_l2
    else:  # L1+L2+L3
        # ç¡®ä¿LLMä¸è¢«è·³è¿‡ï¼Œç‰¹åˆ«é‡è¦ï¼
        os.environ['SKIP_LLM'] = 'false'
        os.environ['FORCE_LLM_VERIFICATION'] = 'true'
        # é’ˆå¯¹ä»»åŠ¡ç±»å‹çš„ç‰¹å®šé…ç½®
        if task_type == 'union':
            os.environ['UNION_OPTIMIZATION'] = 'true'
        shared_config = initialize_shared_resources_l3(tables, task_type, dataset_type)
        process_func = process_query_l3
    
    # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨çš„ç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if cache_manager:
        cache_dir = cache_manager.cache_dir
    else:
        # é™çº§åˆ°é»˜è®¤ç¼“å­˜ç›®å½•
        cache_dir = Path(f"cache/ablation_{dataset_type}_{layer.replace('+', '_')}")
        cache_dir.mkdir(parents=True, exist_ok=True)
    
    # å‡†å¤‡è¿›ç¨‹æ± å‚æ•°ï¼ˆæ¯ä¸ªæŸ¥è¯¢ä¼ é€’ç¼“å­˜ç›®å½•è·¯å¾„ï¼‰
    query_args = [
        (query, tables, shared_config, str(cache_dir))
        for query in queries
    ]
    
    # ä½¿ç”¨è¿›ç¨‹æ± å¤„ç†
    predictions = {}
    start_time = time.time()
    
    logger.info(f"ğŸ“Š å¤„ç† {len(queries)} ä¸ªæŸ¥è¯¢ (è¿›ç¨‹æ•°={max_workers})...")
    
    if layer == 'L1+L2+L3' and shared_config.get('optimization_config'):
        logger.info(f"  âš¡ æ‰¹å¤„ç†ä¼˜åŒ–: OptimizerAgentå’ŒPlannerAgentåªè°ƒç”¨1æ¬¡")
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        future_to_query = {
            executor.submit(process_func, args): args[0]
            for args in query_args
        }
        
        completed = 0
        for future in as_completed(future_to_query):
            query = future_to_query[future]
            completed += 1
            
            try:
                result = future.result(timeout=60)
                predictions[result['query_table']] = result['predictions']
                
                if completed % 5 == 0:
                    logger.info(f"  è¿›åº¦: {completed}/{len(queries)}")
                    
            except Exception as e:
                logger.error(f"æŸ¥è¯¢å¤±è´¥: {query.get('query_table', '')}: {e}")
                predictions[query.get('query_table', '')] = []
    
    elapsed_time = time.time() - start_time
    logger.info(f"âœ… {layer} å®Œæˆ - æ€»æ—¶é—´: {elapsed_time:.2f}ç§’")
    
    return predictions, elapsed_time


def calculate_metrics(predictions: Dict[str, List[str]], 
                     ground_truth: Dict[str, List[str]]) -> Dict[str, float]:
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    hit_at_1 = 0
    hit_at_3 = 0
    hit_at_5 = 0
    
    total_precision = 0
    total_recall = 0
    total_f1 = 0
    valid_queries = 0
    
    for query_key, pred_tables in predictions.items():
        # å°è¯•ç›´æ¥åŒ¹é…
        if query_key in ground_truth:
            true_tables = ground_truth[query_key]
        else:
            # å°è¯•æå–æ•°å­—IDè¿›è¡ŒåŒ¹é…ï¼ˆNLCTablesæ ¼å¼ï¼‰
            import re
            match = re.search(r'(\d+)$', query_key)
            if match:
                numeric_key = match.group(1)
                if numeric_key in ground_truth:
                    true_tables = ground_truth[numeric_key]
                else:
                    continue
            else:
                continue
        
        valid_queries += 1
        true_tables = set(true_tables) if isinstance(true_tables, list) else set()
        
        # Hit@K metrics
        for k in [1, 3, 5]:
            top_k_predictions = set(pred_tables[:k])
            if top_k_predictions & true_tables:
                if k == 1:
                    hit_at_1 += 1
                elif k == 3:
                    hit_at_3 += 1
                elif k == 5:
                    hit_at_5 += 1
        
        # Precision, Recall, F1
        if pred_tables:
            predicted_set = set(pred_tables[:5])
            tp = len(predicted_set & true_tables)
            fp = len(predicted_set - true_tables)
            fn = len(true_tables - predicted_set)
            
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            
            total_precision += precision
            total_recall += recall
            total_f1 += f1
    
    if valid_queries > 0:
        return {
            'hit@1': hit_at_1 / valid_queries,
            'hit@3': hit_at_3 / valid_queries,
            'hit@5': hit_at_5 / valid_queries,
            'precision': total_precision / valid_queries,
            'recall': total_recall / valid_queries,
            'f1_score': total_f1 / valid_queries,
            'valid_queries': valid_queries
        }
    else:
        return {
            'hit@1': 0.0, 'hit@3': 0.0, 'hit@5': 0.0,
            'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0,
            'valid_queries': 0
        }


def create_challenging_queries(tables: List[Dict], queries: List[Dict], ground_truth, max_queries: int = None):
    """åˆ›å»ºæ›´å…·æŒ‘æˆ˜æ€§çš„æŸ¥è¯¢ï¼Œé™ä½L1å‡†ç¡®ç‡
    
    Args:
        tables: æ‰€æœ‰è¡¨çš„åˆ—è¡¨
        queries: åŸå§‹æŸ¥è¯¢åˆ—è¡¨
        ground_truth: çœŸå®æ ‡ç­¾ï¼ˆå¯ä»¥æ˜¯listæˆ–dictæ ¼å¼ï¼‰
        max_queries: æœ€å¤§æŸ¥è¯¢æ•°é™åˆ¶
    """
    # é€‰æ‹©å…·æœ‰ç›¸ä¼¼ç»“æ„ä½†è¯­ä¹‰ä¸åŒçš„è¡¨ä½œä¸ºæŒ‘æˆ˜æ€§æŸ¥è¯¢
    challenging_queries = []
    
    # æŒ‰åˆ—æ•°åˆ†ç»„è¡¨
    tables_by_col_count = {}
    for table in tables:
        col_count = len(table.get('columns', []))
        if col_count not in tables_by_col_count:
            tables_by_col_count[col_count] = []
        tables_by_col_count[col_count].append(table.get('name'))
    
    # ç¡®å®šè¦å¤„ç†çš„æŸ¥è¯¢æ•°
    if max_queries is None:
        # å¦‚æœmax_queriesæ˜¯Noneï¼ˆä½¿ç”¨allï¼‰ï¼Œè¿”å›æ‰€æœ‰åŸå§‹æŸ¥è¯¢ï¼Œä¸åˆ›å»ºæŒ‘æˆ˜æ€§æŸ¥è¯¢
        # è¿™æ ·å¯ä»¥ç¡®ä¿ä½¿ç”¨æ•°æ®é›†çš„æ‰€æœ‰æŸ¥è¯¢
        logger.info(f"ğŸ“Š ä½¿ç”¨æ‰€æœ‰åŸå§‹æŸ¥è¯¢ï¼ˆ{len(queries)}ä¸ªï¼‰ï¼Œä¸åˆ›å»ºæŒ‘æˆ˜æ€§æŸ¥è¯¢")
        return queries, ground_truth
    else:
        # å¦‚æœæŒ‡å®šäº†å…·ä½“æ•°é‡ï¼Œåˆ™æŒ‰åŸé€»è¾‘åˆ†é…ä¸€åŠåŸå§‹ã€ä¸€åŠæŒ‘æˆ˜æ€§
        num_queries = min(len(queries), max_queries)
        num_original = num_queries // 2
        num_challenging = num_queries - num_original
    
    # æ£€æŸ¥ground_truthæ ¼å¼
    is_dict_format = isinstance(ground_truth, dict)
    
    # åˆ›å»ºæ–°çš„ground truthç»“æ„
    if is_dict_format:
        challenging_gt = {}
    else:
        challenging_gt = []
    
    # ä¸ºæ¯ä¸ªåŸå§‹æŸ¥è¯¢åˆ›å»ºä¸€ä¸ªæŒ‘æˆ˜æ€§ç‰ˆæœ¬
    for i, query in enumerate(queries[:num_original]):
        query_table_name = query.get('query_table', '')
        
        # æ‰¾åˆ°æŸ¥è¯¢è¡¨çš„åˆ—æ•°
        query_table = None
        for t in tables:
            if t.get('name') == query_table_name:
                query_table = t
                break
        
        if query_table:
            col_count = len(query_table.get('columns', []))
            
            # åœ¨åŒåˆ—æ•°çš„è¡¨ä¸­é€‰æ‹©ç»“æ„ç›¸ä¼¼ä½†è¯­ä¹‰ä¸åŒçš„è¡¨ä½œä¸ºæŸ¥è¯¢
            similar_tables = tables_by_col_count.get(col_count, [])
            if len(similar_tables) > 1:
                for similar_table_name in similar_tables:
                    if similar_table_name != query_table_name:
                        # åˆ›å»ºæŒ‘æˆ˜æ€§æŸ¥è¯¢
                        challenging_query = {
                            'query_id': f"challenging_{i}",
                            'query_table': similar_table_name,
                            'task_type': query.get('task_type', 'join'),
                            'nl_condition': query.get('nl_condition', '')
                        }
                        challenging_queries.append(challenging_query)
                        
                        # æ·»åŠ ground truthï¼ˆæŒ‘æˆ˜æ€§æŸ¥è¯¢é€šå¸¸æ²¡æœ‰çœŸå®åŒ¹é…ï¼‰
                        if is_dict_format:
                            challenging_gt[f"challenging_{i}"] = []
                        break
    
    # æ··åˆåŸå§‹æŸ¥è¯¢å’ŒæŒ‘æˆ˜æ€§æŸ¥è¯¢
    mixed_queries = queries[:num_original] + challenging_queries[:num_challenging]
    
    # å¯¹åº”çš„ground truth
    if is_dict_format:
        # NLCTablesæ ¼å¼ - ä¿®å¤é”®æ˜ å°„é—®é¢˜
        mixed_gt = {}
        for query in queries[:num_original]:
            query_id = query.get('query_id', '')
            if query_id:
                # ä»query_idæå–æ•°å­—éƒ¨åˆ†
                # å¤„ç†å¤šç§æ ¼å¼: 'query_1' -> '1', 'nlc_union_1' -> '1', 'nlc_join_1' -> '1'
                if query_id.startswith('query_'):
                    id_key = query_id.replace('query_', '')
                elif 'union_' in query_id:
                    id_key = query_id.split('union_')[-1]
                elif 'join_' in query_id:
                    id_key = query_id.split('join_')[-1]
                else:
                    # å°è¯•æå–æœ€åçš„æ•°å­—éƒ¨åˆ†
                    import re
                    match = re.search(r'(\d+)$', query_id)
                    id_key = match.group(1) if match else query_id
                
                # æŸ¥æ‰¾å¯¹åº”çš„ground truth
                if id_key in ground_truth:
                    mixed_gt[query_id] = ground_truth[id_key]
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè®°å½•è­¦å‘Šå¹¶è®¾ç½®ç©ºåˆ—è¡¨
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æŸ¥è¯¢ {query_id} (key={id_key}) çš„ground truth")
                    mixed_gt[query_id] = []
        
        # æ·»åŠ æŒ‘æˆ˜æ€§æŸ¥è¯¢çš„ground truth
        mixed_gt.update(challenging_gt)
    else:
        # WebTableæ ¼å¼
        original_gt = []
        for query in queries[:num_original]:
            query_table_name = query.get('query_table', '')
            for gt_item in ground_truth:
                if gt_item.get('query_table') == query_table_name:
                    original_gt.append(gt_item)
        mixed_gt = original_gt + challenging_gt
    
    logger.info(f"ğŸ“ˆ Created {len(challenging_queries)} challenging queries")
    logger.info(f"ğŸ“ˆ Total mixed queries: {len(mixed_queries)}")
    
    return mixed_queries, mixed_gt


def run_ablation_experiment_optimized(task_type: str, dataset_type: str = 'subset', max_queries: int = None, max_workers: int = 4, use_challenging: bool = True):
    """è¿è¡Œä¼˜åŒ–çš„æ¶ˆèå®éªŒ
    
    Args:
        task_type: ä»»åŠ¡ç±»å‹ ('join' æˆ– 'union')
        dataset_type: æ•°æ®é›†ç±»å‹ ('subset' æˆ– 'complete')
        max_queries: æœ€å¤§æŸ¥è¯¢æ•° (Noneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰æŸ¥è¯¢)
        max_workers: å¹¶è¡Œè¿›ç¨‹æ•°
        use_challenging: æ˜¯å¦ä½¿ç”¨æŒ‘æˆ˜æ€§æŸ¥è¯¢
    """
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸš€ Running OPTIMIZED Ablation Experiment for {task_type.upper()} Task")
    logger.info(f"ğŸ“‚ Dataset Type: {dataset_type.upper()}")
    queries_desc = "ALL" if max_queries is None else str(max_queries)
    logger.info(f"ğŸ“Š Max Queries: {queries_desc}")
    if use_challenging:
        logger.info(f"ğŸ¯ Using challenging mixed queries to test layer improvements")
    logger.info(f"{'='*80}")
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    init_cache_manager(dataset_type, task_type, str(max_queries) if max_queries else 'all')
    
    # åŠ è½½æ•°æ®
    tables, queries, ground_truth = load_dataset(task_type, dataset_type)
    logger.info(f"ğŸ“Š Dataset: {len(tables)} tables, {len(queries)} queries")
    
    # åˆ›å»ºæŒ‘æˆ˜æ€§æŸ¥è¯¢æˆ–ä½¿ç”¨åŸå§‹æŸ¥è¯¢
    if use_challenging and max_queries is not None:
        # åªæœ‰åœ¨æŒ‡å®šäº†å…·ä½“æ•°é‡æ—¶æ‰åˆ›å»ºæŒ‘æˆ˜æ€§æŸ¥è¯¢
        queries, ground_truth = create_challenging_queries(tables, queries, ground_truth, max_queries)
        # ä¸éœ€è¦å†æ¬¡æˆªæ–­ï¼Œcreate_challenging_querieså·²ç»å¤„ç†äº†max_queries
    else:
        # å¦‚æœmax_queriesæ˜¯Noneï¼Œä½¿ç”¨æ‰€æœ‰æŸ¥è¯¢ï¼›å¦åˆ™æˆªæ–­
        if max_queries is not None:
            queries = queries[:max_queries]
            logger.info(f"ğŸ“Š ä½¿ç”¨å‰{max_queries}ä¸ªæŸ¥è¯¢")
        else:
            logger.info(f"ğŸ“Š ä½¿ç”¨æ•°æ®é›†çš„æ‰€æœ‰{len(queries)}ä¸ªæŸ¥è¯¢")
        # else: ä½¿ç”¨æ‰€æœ‰æŸ¥è¯¢
    
    # ç¡®ä¿æ¯ä¸ªæŸ¥è¯¢éƒ½æœ‰æ­£ç¡®çš„ä»»åŠ¡ç±»å‹
    for query in queries:
        if 'task_type' not in query:
            query['task_type'] = task_type
    
    logger.info(f"ğŸ“‹ Using {len(queries)} queries for {task_type.upper()} task experiment")
    
    # è½¬æ¢ground truthæ ¼å¼ï¼ˆæ”¯æŒNLCTablesï¼‰
    if isinstance(ground_truth, dict):
        # NLCTablesæ ¼å¼ï¼šéœ€è¦å°†query_idæ˜ å°„åˆ°query_table
        gt_dict = {}
        for i, query in enumerate(queries):
            query_id = query.get('query_id', '').split('_')[-1]  # è·å–æ•°å­—ID
            query_table = query.get('query_table', '')
            if query_id in ground_truth:
                # æå–è¡¨IDs
                gt_tables = [t['table_id'] for t in ground_truth[query_id] if t.get('relevance_score', 1) > 0]
                if gt_tables and query_table:
                    gt_dict[query_table] = gt_tables
    else:
        # WebTableæ ¼å¼
        gt_dict = convert_ground_truth_format(ground_truth)
    
    # å­˜å‚¨ç»“æœ
    results = {}
    
    # è¿è¡Œä¸‰å±‚å®éªŒ
    for layer in ['L1', 'L1+L2', 'L1+L2+L3']:
        predictions, elapsed_time = run_layer_experiment(
            layer, tables, queries, task_type, dataset_type, max_workers
        )
        
        metrics = calculate_metrics(predictions, gt_dict)
        
        results[layer.replace('+', '_')] = {
            'metrics': metrics,
            'time': elapsed_time,
            'avg_time': elapsed_time / len(queries) if queries else 0
        }
        
        logger.info(f"ğŸ“ˆ {layer} - F1: {metrics['f1_score']:.3f}, "
                   f"Hit@1: {metrics['hit@1']:.3f}, "
                   f"Avg Time: {elapsed_time/len(queries):.2f}s/query")
    
    return results


def print_comparison_table(all_results: Dict[str, Dict]):
    """æ‰“å°å¯¹æ¯”è¡¨æ ¼"""
    print("\n" + "="*100)
    print("ğŸš€ OPTIMIZED THREE-LAYER ABLATION EXPERIMENT RESULTS")
    print("="*100)
    
    for task_type, results in all_results.items():
        print(f"\n{task_type.upper()} Task Results:")
        print("-"*80)
        print(f"{'Layer Config':<15} {'Hit@1':<10} {'Hit@3':<10} {'Hit@5':<10} "
              f"{'Precision':<12} {'Recall':<10} {'F1-Score':<10} {'Time(s)':<10}")
        print("-"*80)
        
        for config in ['L1', 'L1_L2', 'L1_L2_L3']:
            if config in results:
                m = results[config]['metrics']
                t = results[config]['avg_time']
                config_display = config.replace('_', '+')
                print(f"{config_display:<15} {m['hit@1']:<10.3f} {m['hit@3']:<10.3f} "
                      f"{m['hit@5']:<10.3f} {m['precision']:<12.3f} "
                      f"{m['recall']:<10.3f} {m['f1_score']:<10.3f} {t:<10.2f}")
    
    print("\n" + "="*100)
    print("ğŸ“Š LAYER CONTRIBUTION ANALYSIS")
    print("="*100)
    
    for task_type, results in all_results.items():
        print(f"\n{task_type.upper()} Task - Incremental Improvements:")
        
        if 'L1' in results and 'L1_L2' in results:
            f1_l1 = results['L1']['metrics']['f1_score']
            f1_l12 = results['L1_L2']['metrics']['f1_score']
            improvement = (f1_l12 - f1_l1) * 100
            time_increase = results['L1_L2']['avg_time'] - results['L1']['avg_time']
            print(f"  L2 Contribution: {improvement:+.1f}% F1 improvement, {time_increase:+.2f}s time cost")
        
        if 'L1_L2' in results and 'L1_L2_L3' in results:
            f1_l12 = results['L1_L2']['metrics']['f1_score']
            f1_full = results['L1_L2_L3']['metrics']['f1_score']
            improvement = (f1_full - f1_l12) * 100
            time_increase = results['L1_L2_L3']['avg_time'] - results['L1_L2']['avg_time']
            print(f"  L3 Contribution: {improvement:+.1f}% F1 improvement, {time_increase:+.2f}s time cost")
        
        if 'L1' in results and 'L1_L2_L3' in results:
            f1_l1 = results['L1']['metrics']['f1_score']
            f1_full = results['L1_L2_L3']['metrics']['f1_score']
            total_improvement = (f1_full - f1_l1) * 100
            speedup = results['L1']['avg_time'] / results['L1_L2_L3']['avg_time'] if results['L1_L2_L3']['avg_time'] > 0 else 0
            print(f"  Total Improvement: {total_improvement:+.1f}% F1 improvement")
            
            # è®¡ç®—æˆæœ¬æ•ˆç›Šæ¯”
            if results['L1_L2_L3']['avg_time'] > results['L1']['avg_time']:
                cost_benefit = total_improvement / (results['L1_L2_L3']['avg_time'] / results['L1']['avg_time'])
                print(f"  Cost-Benefit Ratio: {cost_benefit:.2f}% improvement per time unit")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='NLCTablesä¼˜åŒ–ç‰ˆä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒ')
    parser.add_argument('--task', choices=['join', 'union', 'both'], default='union',
                       help='ä»»åŠ¡ç±»å‹ (bothä¼šåŒæ—¶è¿è¡Œjoinå’Œunion)')
    parser.add_argument('--dataset', type=str, default='nlctables',
                       help='æ•°æ®é›†åç§°: nlctables, webtable, æˆ–è‡ªå®šä¹‰è·¯å¾„')
    parser.add_argument('--dataset-type', choices=['subset', 'complete'], default='subset',
                       help='æ•°æ®é›†ç±»å‹: subset(å­é›†), complete(å®Œæ•´)')
    parser.add_argument('--max-queries', type=str, default='10',
                       help='æœ€å¤§æŸ¥è¯¢æ•° (æ•°å­—æˆ–"all"è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨)')
    parser.add_argument('--workers', type=int, default=4,
                       help='å¹¶è¡Œè¿›ç¨‹æ•°')
    parser.add_argument('--challenging', action='store_true', default=True,
                       help='ä½¿ç”¨æŒ‘æˆ˜æ€§æ··åˆæŸ¥è¯¢ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--simple', action='store_true',
                       help='ä½¿ç”¨ç®€å•åŸå§‹æŸ¥è¯¢ï¼ˆç¦ç”¨æŒ‘æˆ˜æ€§æŸ¥è¯¢ï¼‰')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()
    
    # å¤„ç†max_querieså‚æ•°
    if args.max_queries.lower() in ['all', '-1', 'none']:
        max_queries = None  # Noneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰æŸ¥è¯¢
        print(f"ğŸ“Š ä½¿ç”¨æ•´ä¸ªæ•°æ®é›†çš„æ‰€æœ‰æŸ¥è¯¢")
    else:
        try:
            max_queries = int(args.max_queries)
            print(f"ğŸ“Š é™åˆ¶æœ€å¤§æŸ¥è¯¢æ•°ä¸º: {max_queries}")
        except ValueError:
            print(f"âš ï¸ æ— æ•ˆçš„max-querieså€¼: {args.max_queries}ï¼Œä½¿ç”¨é»˜è®¤å€¼10")
            max_queries = 10
    
    # å†³å®šæ˜¯å¦ä½¿ç”¨æŒ‘æˆ˜æ€§æŸ¥è¯¢
    use_challenging = args.challenging and not args.simple
    
    # è¿è¡Œå®éªŒ
    tasks = ['join', 'union'] if args.task == 'both' else [args.task]
    all_results = {}
    
    # æ„å»ºæ•°æ®é›†è·¯å¾„
    for task in tasks:
        # å¤„ç†æ•°æ®é›†è·¯å¾„
        if '/' in args.dataset and not args.dataset.startswith('examples/'):
            # è‡ªå®šä¹‰å®Œæ•´è·¯å¾„ï¼ˆéexampleså¼€å¤´ï¼‰
            task_dataset = args.dataset
        elif args.dataset.startswith('examples/') and args.task != 'both':
            # ç›´æ¥ä½¿ç”¨æä¾›çš„è·¯å¾„ï¼ˆå•ä»»åŠ¡æ¨¡å¼ï¼‰
            task_dataset = args.dataset
        elif args.dataset == 'nlctables':
            # NLCTablesæ•°æ®é›†
            task_dataset = f"examples/nlctables/{task}_{args.dataset_type}"
        elif args.dataset in ['webtable', 'opendata']:
            # ä½¿ç”¨æ ‡å‡†æ•°æ®é›†
            task_dataset = f"examples/{args.dataset}/{task}_{args.dataset_type}"
        else:
            # å…¶ä»–é¢„å®šä¹‰ç±»å‹ï¼ˆå‘åå…¼å®¹ï¼‰
            if args.dataset_type == 'complete':
                task_dataset = f"examples/separated_datasets/{task}"
            else:
                task_dataset = f"examples/separated_datasets/{task}_{args.dataset_type}"
            
        results = run_ablation_experiment_optimized(task, task_dataset, max_queries, args.workers, use_challenging)
        all_results[task] = results
    
    # æ‰“å°ç»“æœè¡¨æ ¼
    print_comparison_table(all_results)
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    dataset_suffix = args.dataset if args.dataset != 'subset' else 'subset'
    
    if args.output:
        output_path = Path(args.output)
        # å¦‚æœæ˜¯ç›®å½•ï¼Œæ·»åŠ æ–‡ä»¶å
        if output_path.is_dir() or not output_path.suffix:
            output_path = output_path / f"nlctables_ablation_{task}_{dataset_suffix}_{timestamp}.json"
    else:
        output_path = Path(f"experiment_results/ablation_optimized_{dataset_suffix}_{timestamp}.json")
    
    output_path.parent.mkdir(exist_ok=True, parents=True)
    with open(output_path, 'w') as f:
        json.dump(all_results, f, indent=2)
    
    logger.info(f"\nâœ… Results saved to: {output_path}")
    
    # è¾“å‡ºç¼“å­˜ç»Ÿè®¡
    if cache_manager:
        cache_stats = cache_manager.get_stats()
        print("\n" + "="*100)
        print("ğŸ“Š CACHE STATISTICS")
        print("="*100)
        print(f"  Cache Hits: {cache_stats['hits']}")
        print(f"  Cache Misses: {cache_stats['misses']}")
        print(f"  Cache Saves: {cache_stats['saves']}")
        print(f"  Hit Rate: {cache_stats['hit_rate']}")
        print(f"  Memory Items: {cache_stats['memory_items']}")
    
    # ä¼˜åŒ–æ€»ç»“
    print("\n" + "="*100)
    print("âš¡ OPTIMIZATION SUMMARY")
    print("="*100)
    print("Layer Optimizations Applied:")
    print("  ğŸ” L1 (Metadata): SMD Enhanced filter with reduced table name weight (5%)")
    print("  âš¡ L2 (Vector): Task-specific value similarity (UNION: 50%+50%, JOIN: 70%+30%)")
    print("  ğŸ§  L3 (LLM): Simplified robust verification with enhanced fallback")
    print("\nSystem Optimizations:")
    print("  1. Batch-level resource sharing (OptimizerAgent & PlannerAgent)")
    print("  2. Process pool parallelization")
    print("  3. Persistent caching system")
    print("  4. Pre-computed vector indices")
    print("  5. Challenging mixed queries for better layer evaluation")
    print("="*100)


if __name__ == "__main__":
    # ä¿®å¤å¤šè¿›ç¨‹å¯åŠ¨é—®é¢˜
    mp.freeze_support()
    main()