#!/usr/bin/env python
"""
NLCTablesæ•°æ®é€‚é…å™¨ - ä½¿å…¶èƒ½åœ¨ä¸»ç³»ç»Ÿä¸Šè¿è¡Œ
åŸºäºthree_layer_ablation_optimized.pyçš„æ¶æ„
"""

import json
import logging
from pathlib import Path
from typing import List, Dict, Tuple, Any
import sys

logger = logging.getLogger(__name__)

class NLCTablesAdapter:
    """å°†NLCTablesæ•°æ®æ ¼å¼é€‚é…åˆ°ä¸»ç³»ç»Ÿæ ¼å¼"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
    
    def load_nlctables_dataset(self, task_type: str, subset_type: str = 'subset') -> Tuple[List[Dict], List[Dict], List[Dict]]:
        """
        åŠ è½½NLCTablesæ•°æ®é›†å¹¶è½¬æ¢ä¸ºä¸»ç³»ç»Ÿæ ¼å¼
        
        Args:
            task_type: 'join' æˆ– 'union'
            subset_type: 'subset' æˆ– 'complete'
        
        Returns:
            (tables, queries, ground_truth) - ä¸»ç³»ç»Ÿæ ¼å¼
        """
        # NLCTablesæ•°æ®è·¯å¾„
        base_dir = Path(f'examples/nlctables/{task_type}_{subset_type}')
        
        if not base_dir.exists():
            raise FileNotFoundError(f"NLCTablesæ•°æ®é›†ä¸å­˜åœ¨: {base_dir}")
        
        # åŠ è½½NLCTablesæ•°æ®
        with open(base_dir / 'tables.json', 'r') as f:
            tables = json.load(f)
        
        with open(base_dir / 'queries.json', 'r') as f:
            nlc_queries = json.load(f)
        
        with open(base_dir / 'ground_truth.json', 'r') as f:
            nlc_ground_truth = json.load(f)
        
        # è½¬æ¢æ•°æ®æ ¼å¼
        tables = self._convert_tables(tables, task_type)
        queries = self._convert_queries(nlc_queries, task_type)
        ground_truth = self._convert_ground_truth(nlc_ground_truth, task_type, subset_type)
        
        self.logger.info(f"âœ… åŠ è½½NLCTablesæ•°æ®: {len(tables)} è¡¨, {len(queries)} æŸ¥è¯¢, {len(ground_truth)} ground truthæ¡ç›®")
        
        return tables, queries, ground_truth
    
    def _convert_tables(self, nlc_tables: List[Dict], task_type: str = 'join') -> List[Dict]:
        """è½¬æ¢è¡¨æ ¼å¼ï¼Œå¹¶ä¿®å¤ç©ºåˆ—çš„seedè¡¨"""
        converted_tables = []
        
        # å°è¯•åŠ è½½åŸå§‹seedè¡¨æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        original_seed_tables = {}
        original_base = Path('/root/autodl-tmp/datalakes/nlcTables')
        if original_base.exists():
            task_dir = f'nlcTables-J' if task_type == 'join' else 'nlcTables-U'
            
            # æ–¹æ³•1ï¼šä»query-testç›®å½•åŠ è½½å•ä¸ªseedè¡¨æ–‡ä»¶
            query_dir = original_base / task_dir / 'query-test'
            if query_dir.exists():
                try:
                    for seed_file in query_dir.glob('q_table_*.json'):
                        # Skip empty files
                        if seed_file.stat().st_size == 0:
                            self.logger.debug(f"è·³è¿‡ç©ºæ–‡ä»¶: {seed_file.name}")
                            continue
                            
                        with open(seed_file, 'r') as f:
                            seed_data = json.load(f)
                            table_name = seed_file.stem  # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºè¡¨å
                            
                            # è½¬æ¢seedè¡¨æ ¼å¼
                            table = {
                                'name': table_name,
                                'table_name': table_name,
                                'columns': []
                            }
                            
                            # ä»"title"å­—æ®µæå–åˆ—å
                            if 'title' in seed_data and seed_data['title']:
                                for col_name in seed_data['title']:
                                    column = {
                                        'name': col_name,
                                        'column_name': col_name,
                                        'type': 'string',  # é»˜è®¤ç±»å‹
                                        'data_type': 'string',
                                        'sample_values': []
                                    }
                                    table['columns'].append(column)
                            
                            # æå–æ ·æœ¬æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
                            if 'data' in seed_data:
                                for row in seed_data['data'][:5]:  # åªå–å‰5è¡Œä½œä¸ºæ ·æœ¬
                                    for i, value in enumerate(row):
                                        if i < len(table['columns']):
                                            table['columns'][i]['sample_values'].append(str(value))
                            
                            original_seed_tables[table_name] = table
                    
                    if original_seed_tables:
                        self.logger.info(f"âœ… ä»query-teståŠ è½½äº† {len(original_seed_tables)} ä¸ªåŸå§‹seedè¡¨")
                except Exception as e:
                    self.logger.warning(f"æ— æ³•ä»query-teståŠ è½½seedè¡¨: {e}")
            
            # æ–¹æ³•2ï¼šä»origin-seed-table.jsonåŠ è½½ï¼ˆå¤‡ç”¨ï¼‰
            if not original_seed_tables:
                seed_path = original_base / task_dir / 'origin-seed-table.json'
                if seed_path.exists():
                    try:
                        with open(seed_path, 'r') as f:
                            seed_data = json.load(f)
                            for table in seed_data:
                                table_name = table.get('name', table.get('table_name', ''))
                                original_seed_tables[table_name] = table
                        self.logger.info(f"âœ… ä»origin-seed-tableåŠ è½½äº† {len(original_seed_tables)} ä¸ªåŸå§‹seedè¡¨")
                    except Exception as e:
                        self.logger.warning(f"æ— æ³•ä»origin-seed-tableåŠ è½½seedè¡¨: {e}")
        
        for table in nlc_tables:
            # ç¡®ä¿æ‰€æœ‰è¡¨æœ‰æ ‡å‡†çš„nameå­—æ®µ
            table_name = table.get('name', table.get('table_name', ''))
            if 'name' not in table and 'table_name' in table:
                table['name'] = table['table_name']
            elif 'table_name' not in table and 'name' in table:
                table['table_name'] = table['name']
            
            # å¦‚æœæ˜¯seedè¡¨ä¸”åˆ—ä¸ºç©ºï¼Œå°è¯•ä»åŸå§‹æ•°æ®åŠ è½½
            if table_name.startswith('q_table_') and not table.get('columns'):
                if table_name in original_seed_tables:
                    original_table = original_seed_tables[table_name]
                    table['columns'] = original_table.get('columns', [])
                    if 'sample_data' not in table and 'sample_data' in original_table:
                        table['sample_data'] = original_table['sample_data']
                    self.logger.debug(f"ä¿®å¤äº†seedè¡¨ {table_name} çš„åˆ—ä¿¡æ¯")
            
            # ç¡®ä¿åˆ—æ ¼å¼æ­£ç¡®
            if 'columns' in table:
                converted_columns = []
                for col in table['columns']:
                    # æ ‡å‡†åŒ–åˆ—æ ¼å¼
                    converted_col = {
                        'name': col.get('name', col.get('column_name', '')),
                        'column_name': col.get('column_name', col.get('name', '')),
                        'type': col.get('type', col.get('data_type', 'string')),
                        'data_type': col.get('data_type', col.get('type', 'string')),
                        'sample_values': col.get('sample_values', [])
                    }
                    converted_columns.append(converted_col)
                table['columns'] = converted_columns
            
            converted_tables.append(table)
        
        return converted_tables
    
    def _convert_queries(self, nlc_queries: List[Dict], task_type: str) -> List[Dict]:
        """è½¬æ¢æŸ¥è¯¢æ ¼å¼"""
        converted_queries = []
        
        for query in nlc_queries:
            # NLCTablesæŸ¥è¯¢æ ¼å¼ï¼š{query_id, seed_table, expected_tables}
            # ä¸»ç³»ç»ŸæŸ¥è¯¢æ ¼å¼ï¼š{query_table, task_type}
            
            converted_query = {
                'query_table': query.get('seed_table', query.get('query_table', '')),
                'task_type': task_type,
                'query_id': query.get('query_id', '')
            }
            
            # ä¿ç•™åŸå§‹ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
            if 'expected_tables' in query:
                converted_query['expected_tables'] = query['expected_tables']
            
            converted_queries.append(converted_query)
        
        return converted_queries
    
    def _convert_ground_truth(self, nlc_ground_truth: Any, task_type: str, subset_type: str) -> List[Dict]:
        """è½¬æ¢ground truthæ ¼å¼
        
        NLCTablesçš„ground truthæ˜¯ä¸€ä¸ªå­—å…¸ï¼š
        {
            "1": [{"table_id": "dl_table_xxx", "relevance_score": 2}, ...],
            "3": [{"table_id": "dl_table_yyy", "relevance_score": 2}, ...],
            ...
        }
        
        éœ€è¦è½¬æ¢ä¸ºä¸»ç³»ç»Ÿæ ¼å¼ï¼š
        [
            {"query_table": "q_table_xxx", "ground_truth": ["dl_table_xxx", ...]},
            ...
        ]
        """
        converted_gt = []
        
        # å¤„ç†å­—å…¸æ ¼å¼çš„ground truth
        if isinstance(nlc_ground_truth, dict):
            # éœ€è¦æŸ¥è¯¢è¡¨åçš„æ˜ å°„
            # ä»queriesä¸­è·å–query_idåˆ°seed_tableçš„æ˜ å°„
            queries_path = Path(f'examples/nlctables/{task_type}_{subset_type}/queries.json')
            
            query_mapping = {}
            if queries_path.exists():
                with open(queries_path, 'r') as f:
                    queries = json.load(f)
                    for q in queries:
                        # æå–query_idä¸­çš„æ•°å­—éƒ¨åˆ†
                        query_id = q.get('query_id', '')
                        if '_' in query_id:
                            # ä¾‹å¦‚ 'nlc_join_1' -> '1'
                            id_num = query_id.split('_')[-1]
                            query_mapping[id_num] = q.get('seed_table', '')
            
            # è½¬æ¢ground truth
            for query_id, expected_tables in nlc_ground_truth.items():
                # è·å–å¯¹åº”çš„seedè¡¨å
                seed_table = query_mapping.get(query_id, f'q_table_{query_id}')
                
                # æå–è¡¨ååˆ—è¡¨
                table_names = []
                if isinstance(expected_tables, list):
                    for table_info in expected_tables:
                        if isinstance(table_info, dict):
                            table_id = table_info.get('table_id', '')
                            if table_id:
                                table_names.append(table_id)
                        elif isinstance(table_info, str):
                            table_names.append(table_info)
                
                converted_item = {
                    'query_table': seed_table,
                    'ground_truth': table_names
                }
                converted_gt.append(converted_item)
        
        # å¤„ç†åˆ—è¡¨æ ¼å¼çš„ground truthï¼ˆå¤‡ç”¨ï¼‰
        elif isinstance(nlc_ground_truth, list):
            for gt_item in nlc_ground_truth:
                if isinstance(gt_item, dict):
                    # å·²ç»æ˜¯å­—å…¸æ ¼å¼
                    if 'query_table' in gt_item and 'ground_truth' in gt_item:
                        converted_gt.append(gt_item)
                    elif 'seed_table' in gt_item and 'expected_tables' in gt_item:
                        converted_item = {
                            'query_table': gt_item['seed_table'],
                            'ground_truth': gt_item['expected_tables']
                        }
                        converted_gt.append(converted_item)
                    else:
                        converted_gt.append(gt_item)
        
        return converted_gt
    
    def prepare_for_main_system(self, task_type: str, subset_type: str = 'subset') -> Dict[str, Any]:
        """
        å‡†å¤‡æ•°æ®ä¾›ä¸»ç³»ç»Ÿä½¿ç”¨
        
        Returns:
            åŒ…å«æ‰€æœ‰å¿…è¦æ•°æ®çš„å­—å…¸
        """
        tables, queries, ground_truth = self.load_nlctables_dataset(task_type, subset_type)
        
        return {
            'tables': tables,
            'queries': queries,
            'ground_truth': ground_truth,
            'dataset_name': f'nlctables_{task_type}_{subset_type}',
            'task_type': task_type
        }
    
    def convert_seed_table_to_query(self, seed_table_name: str, tables: List[Dict], task_type: str = 'join') -> Dict:
        """
        å°†NLCTablesçš„seedè¡¨è½¬æ¢ä¸ºä¸»ç³»ç»Ÿçš„æŸ¥è¯¢æ ¼å¼
        
        Args:
            seed_table_name: seedè¡¨åï¼ˆå¦‚q_table_xxxï¼‰
            tables: æ‰€æœ‰è¡¨çš„åˆ—è¡¨
            task_type: ä»»åŠ¡ç±»å‹
        
        Returns:
            ä¸»ç³»ç»Ÿæ ¼å¼çš„æŸ¥è¯¢
        """
        return {
            'query_table': seed_table_name,
            'task_type': task_type
        }
    
    @staticmethod
    def filter_candidates_for_nlctables(tables: List[Dict]) -> List[Dict]:
        """
        è¿‡æ»¤NLCTablesçš„å€™é€‰è¡¨ï¼ˆæ’é™¤seedè¡¨ï¼‰
        
        Args:
            tables: æ‰€æœ‰è¡¨
        
        Returns:
            å€™é€‰è¡¨åˆ—è¡¨ï¼ˆdl_table_å¼€å¤´çš„è¡¨ï¼‰
        """
        candidates = []
        for table in tables:
            table_name = table.get('name', table.get('table_name', ''))
            # NLCTablesçš„å€™é€‰è¡¨ä»¥dl_table_å¼€å¤´ï¼Œseedè¡¨ä»¥q_table_å¼€å¤´
            if table_name.startswith('dl_table_'):
                candidates.append(table)
        
        return candidates


def integrate_with_main_system():
    """
    å°†NLCTablesé›†æˆåˆ°ä¸»ç³»ç»Ÿçš„ç¤ºä¾‹ä»£ç 
    
    è¿™ä¸ªå‡½æ•°å±•ç¤ºå¦‚ä½•ä¿®æ”¹three_layer_ablation_optimized.pyæ¥æ”¯æŒNLCTables
    """
    code_snippet = '''
    # åœ¨three_layer_ablation_optimized.pyçš„load_datasetå‡½æ•°ä¸­æ·»åŠ :
    
    def load_dataset(task_type: str, dataset_type: str = 'subset') -> tuple:
        """åŠ è½½æ•°æ®é›†ï¼ˆæ”¯æŒNLCTablesï¼‰"""
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯NLCTablesæ•°æ®é›†
        if 'nlctables' in dataset_type.lower():
            from nlctables_adapter import NLCTablesAdapter
            adapter = NLCTablesAdapter()
            
            # è§£æsubsetç±»å‹
            if 'complete' in dataset_type:
                subset_type = 'complete'
            else:
                subset_type = 'subset'
            
            # ä½¿ç”¨é€‚é…å™¨åŠ è½½æ•°æ®
            tables, queries, ground_truth = adapter.load_nlctables_dataset(task_type, subset_type)
            
            logger.info(f"ğŸ“Š Loaded NLCTables dataset: {len(tables)} tables, {len(queries)} queries")
            return tables, queries, ground_truth
        
        # åŸæœ‰çš„æ•°æ®åŠ è½½é€»è¾‘...
        # [existing code]
    '''
    
    return code_snippet


if __name__ == "__main__":
    # æµ‹è¯•é€‚é…å™¨
    import argparse
    
    parser = argparse.ArgumentParser(description='NLCTablesé€‚é…å™¨æµ‹è¯•')
    parser.add_argument('--task', choices=['join', 'union'], default='join')
    parser.add_argument('--subset', choices=['subset', 'complete'], default='subset')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé€‚é…å™¨
    adapter = NLCTablesAdapter()
    
    # åŠ è½½æ•°æ®
    try:
        data = adapter.prepare_for_main_system(args.task, args.subset)
        
        print(f"âœ… æˆåŠŸåŠ è½½NLCTablesæ•°æ®é›†")
        print(f"   è¡¨æ•°é‡: {len(data['tables'])}")
        print(f"   æŸ¥è¯¢æ•°é‡: {len(data['queries'])}")
        print(f"   Ground Truthæ•°é‡: {len(data['ground_truth'])}")
        print(f"   æ•°æ®é›†åç§°: {data['dataset_name']}")
        print(f"   ä»»åŠ¡ç±»å‹: {data['task_type']}")
        
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæŸ¥è¯¢ç¤ºä¾‹
        if data['queries']:
            print(f"\nğŸ“‹ ç¬¬ä¸€ä¸ªæŸ¥è¯¢ç¤ºä¾‹:")
            print(f"   {data['queries'][0]}")
        
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()