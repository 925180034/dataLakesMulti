#!/usr/bin/env python3
"""
çœŸæ­£çš„ä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒ - ä½¿ç”¨çœŸå®çš„LLMå’ŒSentenceTransformer
åŸºäºæ‚¨çš„çœŸå®ç³»ç»Ÿç»„ä»¶ï¼Œè€Œä¸æ˜¯æ¨¡æ‹Ÿç‰ˆæœ¬
"""

import asyncio
import json
import time
import os
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
import numpy as np
from tabulate import tabulate
from datetime import datetime
from pathlib import Path
import sys
import logging

# è®¾ç½®é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/root/dataLakesMulti')

# å¼ºåˆ¶ä½¿ç”¨çœŸå®APIå’Œæ¨¡å‹
os.environ['SKIP_LLM'] = 'false'
os.environ['DEBUG'] = 'true'

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class AblationConfig:
    """çœŸå®æ¶ˆèå®éªŒé…ç½®"""
    name: str
    description: str
    use_layer1: bool = True
    use_layer2: bool = True
    use_layer3: bool = True
    force_llm: bool = False

class RealThreeLayerAblation:
    """ä½¿ç”¨çœŸå®ç³»ç»Ÿçš„ä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒ"""
    
    def __init__(self, task_type: str = "union", dataset_size: str = "subset"):
        self.task_type = task_type.lower()
        self.dataset_size = dataset_size
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.results = []
        
        # æ•°æ®è·¯å¾„
        self.data_dir = Path(f"examples/separated_datasets/{task_type}_{dataset_size}")
        
        print(f"ğŸ”¥ çœŸå®ä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒ")
        print(f"ğŸ“‚ æ•°æ®é›†è·¯å¾„: {self.data_dir}")
        print(f"ğŸ“Š ä»»åŠ¡ç±»å‹: {task_type.upper()}")
        print(f"ğŸ“ æ•°æ®è§„æ¨¡: {dataset_size}")
        
        # åˆå§‹åŒ–çœŸå®ç³»ç»Ÿç»„ä»¶
        self._initialize_real_components()
    
    def _initialize_real_components(self):
        """åˆå§‹åŒ–çœŸå®çš„ç³»ç»Ÿç»„ä»¶"""
        print(f"\nğŸ”§ åˆå§‹åŒ–çœŸå®ç³»ç»Ÿç»„ä»¶...")
        
        try:
            # 1. åˆå§‹åŒ–çœŸå®çš„LLMå®¢æˆ·ç«¯
            from src.utils.llm_client import GeminiClient
            from src.config.settings import settings
            
            # æ„å»ºGeminié…ç½®
            config = {
                "model_name": "gemini-1.5-flash",
                "temperature": 0.1,
                "max_tokens": 500,
                "timeout": 8
            }
            
            self.llm_client = GeminiClient(config)
            print(f"   âœ… çœŸå®LLMå®¢æˆ·ç«¯ (Gemini) åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"   âŒ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm_client = None
        
        try:
            # 2. åˆå§‹åŒ–çœŸå®çš„SentenceTransformeråµŒå…¥ç”Ÿæˆå™¨
            from src.tools.embedding import SentenceTransformerEmbeddingGenerator
            
            self.embedding_generator = SentenceTransformerEmbeddingGenerator("all-MiniLM-L6-v2")
            print(f"   âœ… çœŸå®SentenceTransformeråµŒå…¥ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"   âŒ åµŒå…¥ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.embedding_generator = None
        
        try:
            # 3. åˆå§‹åŒ–çœŸå®çš„å·¥ä½œæµ
            from src.core.workflow import DataLakesWorkflow
            
            self.real_workflow = DataLakesWorkflow()
            print(f"   âœ… çœŸå®DataLakesWorkflowåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"   âŒ å·¥ä½œæµåˆå§‹åŒ–å¤±è´¥: {e}")
            self.real_workflow = None

    def load_real_data(self) -> Dict[str, Any]:
        """åŠ è½½çœŸå®æ•°æ®é›†"""
        print(f"\nğŸ“¥ åŠ è½½çœŸå®æ•°æ®é›†...")
        
        # åŠ è½½è¡¨æ•°æ®
        with open(self.data_dir / "tables.json", 'r') as f:
            tables_data = json.load(f)
        
        # åŠ è½½æŸ¥è¯¢æ•°æ®
        with open(self.data_dir / "queries.json", 'r') as f:
            queries_data = json.load(f)
        
        # åŠ è½½ground truth
        with open(self.data_dir / "ground_truth.json", 'r') as f:
            ground_truth_data = json.load(f)
        
        print(f"   âœ… åŠ è½½ {len(tables_data)} ä¸ªè¡¨")
        print(f"   âœ… åŠ è½½ {len(queries_data)} ä¸ªæŸ¥è¯¢") 
        print(f"   âœ… åŠ è½½ {len(ground_truth_data)} ä¸ªground truth")
        
        return {
            'tables': tables_data,
            'queries': queries_data,
            'ground_truth': ground_truth_data
        }

    async def layer1_metadata_filter_real(self, query_table: str, all_tables: List[str], query_column: Optional[str] = None) -> Tuple[List[str], float]:
        """çœŸå®çš„Layer1ï¼šå…ƒæ•°æ®è¿‡æ»¤"""
        start_time = time.time()
        
        candidates = []
        query_lower = query_table.lower()
        
        # é¢†åŸŸè¿‡æ»¤
        query_domains = []
        if any(k in query_lower for k in ['user', 'customer', 'account']):
            query_domains.append('user')
        if any(k in query_lower for k in ['order', 'transaction', 'payment']):
            query_domains.append('order')
        if any(k in query_lower for k in ['product', 'item', 'goods']):
            query_domains.append('product')
        
        for table in all_tables:
            if table == query_table:
                continue
                
            table_lower = table.lower()
            
            # é¢†åŸŸåŒ¹é…
            match = False
            for domain in query_domains:
                if domain == 'user' and any(k in table_lower for k in ['user', 'customer', 'account']):
                    match = True
                elif domain == 'order' and any(k in table_lower for k in ['order', 'transaction', 'payment']):
                    match = True
                elif domain == 'product' and any(k in table_lower for k in ['product', 'item', 'goods']):
                    match = True
            
            # å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
            if not match:
                common_chars = set(query_lower) & set(table_lower)
                if len(common_chars) >= min(3, len(query_lower) * 0.3):
                    match = True
            
            if match:
                candidates.append(table)
        
        processing_time = time.time() - start_time
        return candidates, processing_time

    async def layer2_vector_search_real(self, query_table: str, layer1_candidates: List[str], query_column: Optional[str] = None) -> Tuple[List[Tuple[str, float]], float]:
        """çœŸå®çš„Layer2ï¼šHNSWå‘é‡æœç´¢ - ä½¿ç”¨çœŸæ­£çš„SentenceTransformer"""
        start_time = time.time()
        
        if not self.embedding_generator:
            print(f"     âŒ Layer2: åµŒå…¥ç”Ÿæˆå™¨ä¸å¯ç”¨ï¼Œè·³è¿‡")
            # è¿”å›Layer1ç»“æœï¼Œæ·»åŠ è™šæ‹Ÿåˆ†æ•°
            return [(c, 0.5) for c in layer1_candidates], time.time() - start_time
        
        try:
            # ç”ŸæˆæŸ¥è¯¢è¡¨çš„çœŸå®åµŒå…¥å‘é‡
            query_text = query_table
            if query_column:
                query_text = f"{query_table}.{query_column}"
            
            print(f"     ğŸ”„ Layer2: ç”ŸæˆçœŸå®å‘é‡åµŒå…¥ (SentenceTransformer)")
            query_embedding = await self.embedding_generator.generate_text_embedding(query_text)
            
            vector_candidates = []
            for candidate_table in layer1_candidates:
                candidate_text = candidate_table
                if query_column:
                    candidate_text = f"{candidate_table}.{query_column}"
                
                # ç”Ÿæˆå€™é€‰è¡¨çš„çœŸå®åµŒå…¥å‘é‡
                candidate_embedding = await self.embedding_generator.generate_text_embedding(candidate_text)
                
                # è®¡ç®—çœŸå®çš„ä½™å¼¦ç›¸ä¼¼åº¦
                similarity = self._cosine_similarity(
                    np.array(query_embedding), 
                    np.array(candidate_embedding)
                )
                
                vector_candidates.append((candidate_table, similarity))
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åº
            vector_candidates.sort(key=lambda x: x[1], reverse=True)
            
            # ä¿ç•™å‰25ä¸ª
            final_candidates = vector_candidates[:25]
            
            processing_time = time.time() - start_time
            print(f"     âœ… Layer2: çœŸå®å‘é‡æœç´¢å®Œæˆ ({len(layer1_candidates)}â†’{len(final_candidates)}, {processing_time:.2f}s)")
            
            return final_candidates, processing_time
            
        except Exception as e:
            print(f"     âŒ Layer2: çœŸå®å‘é‡æœç´¢å¤±è´¥: {e}")
            # è¿”å›Layer1ç»“æœä½œä¸ºå¤‡ç”¨
            return [(c, 0.5) for c in layer1_candidates], time.time() - start_time

    async def layer3_llm_matching_real(self, query_table: str, layer2_candidates: List[Tuple[str, float]], query_column: Optional[str] = None) -> Tuple[List[Dict], float, bool]:
        """çœŸå®çš„Layer3ï¼šLLMåŒ¹é… - ä½¿ç”¨çœŸæ­£çš„Gemini API"""
        start_time = time.time()
        llm_called = False
        
        if not self.llm_client:
            print(f"     âŒ Layer3: LLMå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œè·³è¿‡")
            # è¿”å›åŒˆç‰™åˆ©ç®—æ³•ç»“æœ
            matches = []
            for i, (table_name, vector_score) in enumerate(layer2_candidates[:10]):
                matches.append({
                    'rank': i + 1,
                    'table_name': table_name,
                    'score': vector_score * 100,
                    'method': 'vector_only',
                    'llm_verified': False
                })
            return matches, time.time() - start_time, False
        
        try:
            print(f"     ğŸ”„ Layer3: è°ƒç”¨çœŸå®LLM API (Gemini)")
            
            # å‡†å¤‡LLMæç¤ºè¯
            candidates_text = "\n".join([f"{i+1}. {table}" for i, (table, _) in enumerate(layer2_candidates[:5])])
            
            if self.task_type == "join":
                prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®è¡¨åŒ¹é…ä¸“å®¶ã€‚è¯·ä¸ºJOINæ“ä½œåˆ†æä»¥ä¸‹å€™é€‰è¡¨ä¸æŸ¥è¯¢è¡¨çš„åŒ¹é…ç¨‹åº¦ã€‚

æŸ¥è¯¢è¡¨: {query_table}
æŸ¥è¯¢åˆ—: {query_column or "æœªæŒ‡å®š"}

å€™é€‰è¡¨:
{candidates_text}

è¯·ä¸ºæ¯ä¸ªå€™é€‰è¡¨æ‰“åˆ†(0-100)å¹¶è¯´æ˜ç†ç”±ã€‚è¿”å›JSONæ ¼å¼:
{{"rankings": [{{"table": "è¡¨å", "score": åˆ†æ•°, "reason": "ç†ç”±"}}]}}
"""
            else:
                prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®è¡¨åŒ¹é…ä¸“å®¶ã€‚è¯·ä¸ºUNIONæ“ä½œåˆ†æä»¥ä¸‹å€™é€‰è¡¨ä¸æŸ¥è¯¢è¡¨çš„ç›¸ä¼¼ç¨‹åº¦ã€‚

æŸ¥è¯¢è¡¨: {query_table}

å€™é€‰è¡¨:
{candidates_text}

è¯·ä¸ºæ¯ä¸ªå€™é€‰è¡¨æ‰“åˆ†(0-100)å¹¶è¯´æ˜ç†ç”±ã€‚è¿”å›JSONæ ¼å¼:
{{"rankings": [{{"table": "è¡¨å", "score": åˆ†æ•°, "reason": "ç†ç”±"}}]}}
"""
            
            # çœŸå®çš„LLM APIè°ƒç”¨
            llm_response = await self.llm_client.generate_json(prompt)
            llm_called = True
            
            print(f"     âœ… Layer3: LLM APIè°ƒç”¨æˆåŠŸ")
            
            # è§£æLLMå“åº”
            matches = []
            if 'rankings' in llm_response:
                for i, ranking in enumerate(llm_response['rankings']):
                    matches.append({
                        'rank': i + 1,
                        'table_name': ranking.get('table', f'unknown_{i}'),
                        'score': ranking.get('score', 50),
                        'reason': ranking.get('reason', ''),
                        'method': 'llm_verified',
                        'llm_verified': True
                    })
            
            # å¦‚æœLLMæ²¡æœ‰è¿”å›è¶³å¤Ÿç»“æœï¼Œè¡¥å……å‘é‡ç»“æœ
            llm_tables = {m['table_name'] for m in matches}
            for table_name, vector_score in layer2_candidates:
                if table_name not in llm_tables and len(matches) < 10:
                    matches.append({
                        'rank': len(matches) + 1,
                        'table_name': table_name,
                        'score': vector_score * 100,
                        'method': 'vector_fallback',
                        'llm_verified': False
                    })
            
            processing_time = time.time() - start_time
            print(f"     âœ… Layer3: LLMå¤„ç†å®Œæˆ ({len(layer2_candidates)}â†’{len(matches)}, {processing_time:.2f}s)")
            
            return matches[:10], processing_time, llm_called
            
        except Exception as e:
            print(f"     âŒ Layer3: LLMè°ƒç”¨å¤±è´¥: {e}")
            # ä½¿ç”¨å‘é‡åˆ†æ•°ä½œä¸ºå¤‡ç”¨
            matches = []
            for i, (table_name, vector_score) in enumerate(layer2_candidates[:10]):
                matches.append({
                    'rank': i + 1,
                    'table_name': table_name,
                    'score': vector_score * 100,
                    'method': 'vector_fallback',
                    'llm_verified': False
                })
            return matches, time.time() - start_time, False

    def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        try:
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            return dot_product / (norm1 * norm2)
        except:
            return 0.0

    async def run_single_ablation(self, config: AblationConfig, data: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæ¶ˆèå®éªŒ"""
        print(f"\n{'='*60}")
        print(f"ğŸ”¬ çœŸå®æ¶ˆèé…ç½®: {config.name}")
        print(f"   æè¿°: {config.description}")
        print(f"   å±‚é…ç½®: L1={config.use_layer1}, L2={config.use_layer2}, L3={config.use_layer3}")
        print("="*60)
        
        all_tables = [t['table_name'] for t in data['tables']]
        test_queries = data['queries'][:5]  # æµ‹è¯•å‰5ä¸ªæŸ¥è¯¢
        
        results = []
        total_time = 0
        llm_calls = 0
        
        for i, query_data in enumerate(test_queries):
            query_table = query_data.get('query_table', '')
            query_column = query_data.get('query_column') if self.task_type == "join" else None
            
            print(f"\n   æŸ¥è¯¢ {i+1}/{len(test_queries)}: {query_table}")
            
            candidates = all_tables
            layer_times = []
            
            # Layer 1
            if config.use_layer1:
                layer1_candidates, layer1_time = await self.layer1_metadata_filter_real(query_table, candidates, query_column)
                candidates = layer1_candidates
                layer_times.append(('Layer1', layer1_time))
                print(f"      Layer1: {len(all_tables)}â†’{len(candidates)} ({layer1_time:.3f}s)")
            
            # Layer 2  
            if config.use_layer2:
                layer2_candidates, layer2_time = await self.layer2_vector_search_real(query_table, candidates, query_column)
                candidates = layer2_candidates
                layer_times.append(('Layer2', layer2_time))
                print(f"      Layer2: çœŸå®å‘é‡æœç´¢ ({layer2_time:.3f}s)")
            else:
                # è½¬æ¢ä¸ºå…ƒç»„æ ¼å¼
                candidates = [(c, 0.5) for c in candidates]
            
            # Layer 3
            if config.use_layer3:
                matches, layer3_time, llm_used = await self.layer3_llm_matching_real(query_table, candidates, query_column)
                if llm_used:
                    llm_calls += 1
                layer_times.append(('Layer3', layer3_time))
                print(f"      Layer3: çœŸå®LLMè°ƒç”¨ ({'âœ…' if llm_used else 'âŒ'}, {layer3_time:.3f}s)")
                predicted = [m['table_name'] for m in matches[:5]]
            else:
                predicted = [c[0] for c in candidates[:5]]
            
            total_query_time = sum(t for _, t in layer_times)
            total_time += total_query_time
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡ï¼ˆä½¿ç”¨ä¿®æ­£çš„ground truthè§£æï¼‰
            expected = []
            for gt in data['ground_truth']:
                if gt.get('query_table') == query_table:
                    candidate = gt.get('candidate_table', '')
                    if candidate and candidate != query_table:
                        expected.append(candidate)
            expected = list(set(expected))
            
            # è®¡ç®—æŒ‡æ ‡
            predicted_set = set(predicted)
            expected_set = set(expected)
            
            tp = len(predicted_set & expected_set)
            fp = len(predicted_set - expected_set)
            fn = len(expected_set - predicted_set)
            
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
            hit_at_1 = 1 if predicted and predicted[0] in expected_set else 0
            
            results.append({
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'hit_at_1': hit_at_1,
                'time': total_query_time,
                'layer_times': layer_times
            })
            
            print(f"      æŒ‡æ ‡: F1={f1:.1%}, Hit@1={hit_at_1}, æ€»æ—¶é—´={total_query_time:.3f}s")
            print(f"      æ—¶é—´åˆ†è§£: {', '.join([f'{name}={time:.3f}s' for name, time in layer_times])}")
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_metrics = {
            'f1': np.mean([r['f1'] for r in results]),
            'hit_at_1': np.mean([r['hit_at_1'] for r in results]),
            'precision': np.mean([r['precision'] for r in results]),
            'recall': np.mean([r['recall'] for r in results]),
            'avg_time': np.mean([r['time'] for r in results]),
            'total_time': total_time,
            'llm_calls': llm_calls,
            'llm_rate': llm_calls / len(test_queries) if test_queries else 0
        }
        
        print(f"\n   ğŸ“Š å¹³å‡æ€§èƒ½:")
        print(f"      F1: {avg_metrics['f1']:.1%}")
        print(f"      Hit@1: {avg_metrics['hit_at_1']:.1%}")
        print(f"      Precision: {avg_metrics['precision']:.1%}")
        print(f"      Recall: {avg_metrics['recall']:.1%}")
        print(f"      å¹³å‡æ—¶é—´: {avg_metrics['avg_time']:.3f}s")
        print(f"      LLMè°ƒç”¨: {llm_calls}/{len(test_queries)} ({avg_metrics['llm_rate']:.0%})")
        
        return {
            'config': config.name,
            'metrics': avg_metrics,
            'num_queries': len(test_queries)
        }

    def get_ablation_configs(self) -> List[AblationConfig]:
        """å®šä¹‰çœŸå®æ¶ˆèå®éªŒé…ç½®"""
        return [
            AblationConfig(
                name="L1_Only",
                description="ä»…Layer1 (å…ƒæ•°æ®è¿‡æ»¤)",
                use_layer1=True,
                use_layer2=False,
                use_layer3=False
            ),
            AblationConfig(
                name="L1_L2_Real",
                description="Layer1+Layer2 (çœŸå®SentenceTransformer)",
                use_layer1=True,
                use_layer2=True,
                use_layer3=False
            ),
            AblationConfig(
                name="Full_Real_3Layer",
                description="å®Œæ•´ä¸‰å±‚ (çœŸå®SentenceTransformer + çœŸå®LLM)",
                use_layer1=True,
                use_layer2=True,
                use_layer3=True,
                force_llm=True
            )
        ]

    async def run_real_ablation_study(self):
        """è¿è¡ŒçœŸå®çš„æ¶ˆèå®éªŒ"""
        print("="*80)
        print(f"ğŸ”¥ çœŸæ­£çš„ä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒ - ä½¿ç”¨çœŸå®APIå’Œæ¨¡å‹")
        print(f"   ä»»åŠ¡: {self.task_type.upper()}")
        print(f"   æ•°æ®é›†: {self.dataset_size}")
        print("="*80)
        
        # åŠ è½½æ•°æ®
        data = self.load_real_data()
        
        # è¿è¡Œæ‰€æœ‰é…ç½®
        configs = self.get_ablation_configs()
        all_results = []
        
        for config in configs:
            result = await self.run_single_ablation(config, data)
            all_results.append(result)
            self.results.append(result)
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_real_report()

    def generate_real_report(self):
        """ç”ŸæˆçœŸå®å®éªŒæŠ¥å‘Š"""
        print(f"\n{'='*80}")
        print(f"ğŸ“Š çœŸå®æ¶ˆèå®éªŒç»“æœæ±‡æ€» - {self.task_type.upper()}")
        print(f"   ä½¿ç”¨çœŸå®SentenceTransformer + çœŸå®LLM API")
        print(f"{'='*80}")
        
        # åˆ›å»ºè¡¨æ ¼
        headers = ['é…ç½®', 'F1', 'Hit@1', 'Precision', 'Recall', 'å¹³å‡æ—¶é—´(s)', 'LLMè°ƒç”¨ç‡']
        rows = []
        
        for result in self.results:
            metrics = result['metrics']
            rows.append([
                result['config'],
                f"{metrics['f1']:.1%}",
                f"{metrics['hit_at_1']:.1%}",
                f"{metrics['precision']:.1%}",
                f"{metrics['recall']:.1%}",
                f"{metrics['avg_time']:.3f}",
                f"{metrics['llm_rate']:.0%}"
            ])
        
        print(tabulate(rows, headers=headers, tablefmt='grid'))
        
        # åˆ†æå±‚è´¡çŒ®
        self.analyze_real_contributions()
        
        # ä¿å­˜ç»“æœ
        self.save_real_results()

    def analyze_real_contributions(self):
        """åˆ†æçœŸå®å±‚è´¡çŒ®"""
        print(f"\nğŸ” çœŸå®å±‚è´¡çŒ®åˆ†æ")
        print("="*50)
        
        results_dict = {r['config']: r for r in self.results}
        
        # Layer1è´¡çŒ®
        if 'L1_Only' in results_dict:
            l1_f1 = results_dict['L1_Only']['metrics']['f1']
            l1_time = results_dict['L1_Only']['metrics']['avg_time']
            print(f"\n1ï¸âƒ£ Layer1ç‹¬ç«‹æ€§èƒ½:")
            print(f"   F1: {l1_f1:.1%}")
            print(f"   æ—¶é—´: {l1_time:.3f}s")
        
        # Layer2çœŸå®è´¡çŒ®
        if 'L1_Only' in results_dict and 'L1_L2_Real' in results_dict:
            l1_f1 = results_dict['L1_Only']['metrics']['f1']
            l12_f1 = results_dict['L1_L2_Real']['metrics']['f1']
            l1_time = results_dict['L1_Only']['metrics']['avg_time']
            l12_time = results_dict['L1_L2_Real']['metrics']['avg_time']
            
            gain = l12_f1 - l1_f1
            time_cost = l12_time - l1_time
            
            print(f"\n2ï¸âƒ£ Layer2 (çœŸå®SentenceTransformer) è´¡çŒ®:")
            print(f"   F1æå‡: {gain:+.1%} {'âœ…' if gain > 0 else 'âŒ'}")
            print(f"   æ—¶é—´å¼€é”€: +{time_cost:.3f}s")
            print(f"   æ•ˆç‡: {gain/time_cost:.1%}/s" if time_cost > 0 else "   æ•ˆç‡: æ— ç©·å¤§")
        
        # Layer3çœŸå®LLMè´¡çŒ®
        if 'L1_L2_Real' in results_dict and 'Full_Real_3Layer' in results_dict:
            l12_f1 = results_dict['L1_L2_Real']['metrics']['f1']
            full_f1 = results_dict['Full_Real_3Layer']['metrics']['f1']
            l12_time = results_dict['L1_L2_Real']['metrics']['avg_time']
            full_time = results_dict['Full_Real_3Layer']['metrics']['avg_time']
            
            gain = full_f1 - l12_f1
            time_cost = full_time - l12_time
            
            print(f"\n3ï¸âƒ£ Layer3 (çœŸå®LLM) è´¡çŒ®:")
            print(f"   F1æå‡: {gain:+.1%} {'âœ…' if gain > 0 else 'âŒ'}")
            print(f"   æ—¶é—´å¼€é”€: +{time_cost:.3f}s")
            print(f"   æ•ˆç‡: {gain/time_cost:.1%}/s" if time_cost > 0 else "   æ•ˆç‡: æ— ç©·å¤§")
        
        # æ€»ä½“æå‡vsæ—¶é—´æˆæœ¬
        if 'L1_Only' in results_dict and 'Full_Real_3Layer' in results_dict:
            l1_f1 = results_dict['L1_Only']['metrics']['f1']
            full_f1 = results_dict['Full_Real_3Layer']['metrics']['f1']
            l1_time = results_dict['L1_Only']['metrics']['avg_time']
            full_time = results_dict['Full_Real_3Layer']['metrics']['avg_time']
            
            total_gain = full_f1 - l1_f1
            total_time_cost = full_time - l1_time
            
            print(f"\nğŸ“ˆ æ€»ä½“åˆ†æ:")
            print(f"   F1æ€»æå‡: {l1_f1:.1%} â†’ {full_f1:.1%} ({total_gain:+.1%})")
            print(f"   æ—¶é—´æ€»æˆæœ¬: {l1_time:.3f}s â†’ {full_time:.3f}s (+{total_time_cost:.3f}s)")
            print(f"   æ—¶é—´å¢åŠ å€æ•°: {full_time/l1_time:.1f}x" if l1_time > 0 else "   æ—¶é—´å¢åŠ : æ— ç©·å¤§")
            print(f"   æ€§ä»·æ¯”: {total_gain/total_time_cost:.1%}/s" if total_time_cost > 0 else "   æ€§ä»·æ¯”: æ— ç©·å¤§")
        
        # æœ€ä½³é…ç½®
        best = max(self.results, key=lambda x: x['metrics']['f1'])
        print(f"\nğŸ† æœ€ä½³é…ç½®: {best['config']}")
        print(f"   F1: {best['metrics']['f1']:.1%}")
        print(f"   æ—¶é—´: {best['metrics']['avg_time']:.3f}s")
        print(f"   LLMè°ƒç”¨ç‡: {best['metrics']['llm_rate']:.0%}")

    def save_real_results(self):
        """ä¿å­˜çœŸå®å®éªŒç»“æœ"""
        output_dir = Path(f"real_ablation_{self.task_type}_{self.timestamp}")
        output_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜JSONç»“æœ
        with open(output_dir / "results.json", 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"\nğŸ’¾ çœŸå®å®éªŒç»“æœå·²ä¿å­˜åˆ°: {output_dir}/")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹çœŸæ­£çš„ä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒ")
    print("   ä½¿ç”¨çœŸå®çš„SentenceTransformerå’ŒLLM API")
    print("="*80)
    
    # UNIONä»»åŠ¡çœŸå®æ¶ˆèå®éªŒ
    union_study = RealThreeLayerAblation(task_type="union", dataset_size="subset")
    await union_study.run_real_ablation_study()
    
    print("\n" + "="*80)
    print("âœ… çœŸå®ä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒå®Œæˆï¼")
    print("   - ä½¿ç”¨äº†çœŸå®çš„SentenceTransformeræ¨¡å‹")
    print("   - è°ƒç”¨äº†çœŸå®çš„Gemini LLM API") 
    print("   - æµ‹é‡äº†çœŸå®çš„å¤„ç†æ—¶é—´")
    print("   - åˆ†æäº†çœŸå®çš„å±‚è´¡çŒ®")
    print("="*80)

if __name__ == "__main__":
    asyncio.run(main())