#!/usr/bin/env python
"""
è¿è¡Œå¸¦ç¼“å­˜ä¼˜åŒ–çš„å®Œæ•´å®éªŒ
é€šè¿‡ç¼“å­˜OptimizerAgentå’ŒPlannerAgentçš„ç»“æœï¼Œå¤§å¹…å‡å°‘LLMè°ƒç”¨
"""
import os
import sys
import json
import time
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import subprocess

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_dataset(task_type: str, dataset_type: str) -> tuple:
    """åŠ è½½æ•°æ®é›†"""
    base_dir = Path(f'examples/separated_datasets/{task_type}_{dataset_type}')
    
    with open(base_dir / 'tables.json', 'r') as f:
        tables = json.load(f)
    with open(base_dir / 'queries.json', 'r') as f:
        queries = json.load(f)
    with open(base_dir / 'ground_truth.json', 'r') as f:
        ground_truth = json.load(f)
    
    return tables, queries, ground_truth


def filter_queries_with_ground_truth(queries: List[Dict], ground_truth: List[Dict], 
                                    max_queries: int = 100) -> List[Dict]:
    """åªé€‰æ‹©æœ‰ground truthçš„æŸ¥è¯¢"""
    gt_query_tables = set()
    for gt in ground_truth:
        if 'query_table' in gt:
            gt_query_tables.add(gt['query_table'])
    
    filtered = []
    seen = set()
    for q in queries:
        qt = q.get('query_table', '')
        if qt and qt in gt_query_tables and qt not in seen:
            filtered.append(q)
            seen.add(qt)
            if len(filtered) >= max_queries:
                break
    
    return filtered


def precompute_embeddings(tables: List[Dict], dataset_type: str):
    """é¢„è®¡ç®—å‘é‡åµŒå…¥"""
    cache_dir = Path("cache") / dataset_type
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    index_file = cache_dir / f"vector_index_{len(tables)}.pkl"
    embeddings_file = cache_dir / f"table_embeddings_{len(tables)}.pkl"
    
    if index_file.exists() and embeddings_file.exists():
        logger.info(f"âœ… å‘é‡ç´¢å¼•å·²å­˜åœ¨: {index_file}")
        os.environ['USE_PERSISTENT_INDEX'] = str(index_file)
        os.environ['USE_PRECOMPUTED_EMBEDDINGS'] = str(embeddings_file)
    else:
        logger.info(f"âš ï¸ éœ€è¦ç”Ÿæˆå‘é‡ç´¢å¼•...")
        from precompute_embeddings import precompute_all_embeddings
        precompute_all_embeddings(tables, dataset_type)
        os.environ['USE_PERSISTENT_INDEX'] = str(index_file)
        os.environ['USE_PRECOMPUTED_EMBEDDINGS'] = str(embeddings_file)


def convert_ground_truth_format(ground_truth_list: List[Dict]) -> List[Dict]:
    """
    å°†ground truthä»å•ä¸ªå€™é€‰è¡¨æ ¼å¼è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
    å¹¶æŒ‰æŸ¥è¯¢è¡¨èšåˆï¼ŒåŒæ—¶è¿‡æ»¤è‡ªåŒ¹é…
    """
    query_to_candidates = {}
    
    for item in ground_truth_list:
        query_table = item.get('query_table', '')
        candidate_table = item.get('candidate_table', '')
        
        if query_table and candidate_table:
            # è¿‡æ»¤è‡ªåŒ¹é…
            if query_table != candidate_table:
                if query_table not in query_to_candidates:
                    query_to_candidates[query_table] = set()
                query_to_candidates[query_table].add(candidate_table)
    
    # è½¬æ¢ä¸ºæœŸæœ›çš„æ ¼å¼
    converted = []
    for query_table, candidates in query_to_candidates.items():
        if candidates:  # åªä¿ç•™æœ‰å€™é€‰è¡¨çš„
            converted.append({
                'query_table': query_table,
                'candidate_tables': list(candidates)
            })
    
    return converted


def run_multi_agent_with_cache(tables: List[Dict], queries: List[Dict], 
                               ground_truth: List[Dict], task_type: str) -> Dict:
    """è¿è¡Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    from src.core.langgraph_workflow import DataLakeDiscoveryWorkflow
    
    # åˆ›å»ºå·¥ä½œæµå®ä¾‹ï¼ˆä¿æŒå•ä¾‹ä»¥åˆ©ç”¨ç¼“å­˜ï¼‰
    workflow = DataLakeDiscoveryWorkflow()
    
    results = []
    total_time = 0
    total_llm_calls = 0
    cache_hits = 0
    
    logger.info(f"å¼€å§‹å¤„ç† {len(queries)} ä¸ªæŸ¥è¯¢...")
    
    for i, query in enumerate(queries, 1):
        query_table_name = query.get('query_table', '')
        
        if i == 1:
            logger.info(f"ğŸ”¥ ç¬¬ä¸€ä¸ªæŸ¥è¯¢å°†åˆå§‹åŒ–ç¼“å­˜ï¼ˆ{task_type} ä»»åŠ¡ï¼‰...")
        elif i == 2:
            logger.info(f"âœ¨ ä»ç¬¬äºŒä¸ªæŸ¥è¯¢å¼€å§‹ä½¿ç”¨ç¼“å­˜...")
        
        start = time.time()
        
        # è¿è¡Œå·¥ä½œæµ
        result = workflow.run(
            query=f"find {task_type}able tables for {query_table_name}",
            tables=tables,
            task_type=task_type,
            query_table_name=query_table_name
        )
        
        elapsed = time.time() - start
        total_time += elapsed
        
        # æ”¶é›†æŒ‡æ ‡
        if result.get('success'):
            # è·å–é¢„æµ‹ç»“æœå¹¶è¿‡æ»¤è‡ªåŒ¹é…
            predictions = [r['table_name'] for r in result.get('results', [])[:10]]
            filtered_predictions = [p for p in predictions if p != query_table_name]
            
            results.append({
                'query_table': query_table_name,
                'predictions': filtered_predictions[:5],  # ä¿ç•™top-5
                'time': elapsed
            })
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç¼“å­˜
            metrics = result.get('metrics', {})
            agent_times = metrics.get('agent_times', {})
            
            # å¦‚æœä¼˜åŒ–å™¨å’Œè§„åˆ’å™¨æ—¶é—´æçŸ­ï¼Œè¯´æ˜ä½¿ç”¨äº†ç¼“å­˜
            if agent_times.get('optimizer', 1) < 0.01 and agent_times.get('planner', 1) < 0.01:
                cache_hits += 1
            
            total_llm_calls += metrics.get('llm_calls_made', 0)
        
        # è¿›åº¦æŠ¥å‘Š
        if i % 10 == 0:
            avg_time = total_time / i
            logger.info(f"è¿›åº¦: {i}/{len(queries)} | å¹³å‡æ—¶é—´: {avg_time:.2f}s | ç¼“å­˜å‘½ä¸­: {cache_hits}/{i}")
    
    # è½¬æ¢ground truthæ ¼å¼
    converted_ground_truth = convert_ground_truth_format(ground_truth)
    logger.info(f"Ground truthè½¬æ¢: {len(ground_truth)} æ¡ -> {len(converted_ground_truth)} ä¸ªæŸ¥è¯¢è¡¨")
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    from evaluate_with_metrics import calculate_metrics
    metrics = calculate_metrics(results, converted_ground_truth)
    
    return {
        'results': results,
        'metrics': metrics,
        'total_time': total_time,
        'avg_time': total_time / len(queries) if queries else 0,
        'total_llm_calls': total_llm_calls,
        'cache_hits': cache_hits,
        'cache_hit_rate': cache_hits / len(queries) if queries else 0
    }


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='è¿è¡Œå¸¦ç¼“å­˜çš„å®Œæ•´å®éªŒ')
    parser.add_argument('--task', choices=['join', 'union', 'both'], default='both',
                       help='ä»»åŠ¡ç±»å‹')
    parser.add_argument('--dataset', choices=['subset', 'complete'], default='complete',
                       help='æ•°æ®é›†ç±»å‹')
    parser.add_argument('--max-queries', type=int, default=100,
                       help='æœ€å¤§æŸ¥è¯¢æ•°')
    args = parser.parse_args()
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['SKIP_LLM'] = 'false'  # ç»ä¸è·³è¿‡LLM
    
    # è¿è¡Œå®éªŒ
    tasks = ['join', 'union'] if args.task == 'both' else [args.task]
    
    all_results = {}
    
    for task in tasks:
        logger.info("="*80)
        logger.info(f"è¿è¡Œ {task.upper()} ä»»åŠ¡ - {args.dataset.upper()} æ•°æ®é›†")
        logger.info("="*80)
        
        # åŠ è½½æ•°æ®
        tables, queries, ground_truth = load_dataset(task, args.dataset)
        logger.info(f"æ•°æ®é›†: {len(tables)} ä¸ªè¡¨, {len(queries)} ä¸ªæŸ¥è¯¢")
        
        # è¿‡æ»¤æŸ¥è¯¢
        filtered_queries = filter_queries_with_ground_truth(queries, ground_truth, args.max_queries)
        logger.info(f"è¿‡æ»¤å: {len(filtered_queries)} ä¸ªæœ‰ground truthçš„æŸ¥è¯¢")
        
        # é¢„è®¡ç®—åµŒå…¥
        precompute_embeddings(tables, args.dataset)
        
        # è¿è¡Œå®éªŒ
        result = run_multi_agent_with_cache(tables, filtered_queries, ground_truth, task)
        
        # ä¿å­˜ç»“æœ
        all_results[task] = result
        
        # è¾“å‡ºæ€»ç»“
        logger.info("="*80)
        logger.info(f"{task.upper()} ä»»åŠ¡ç»“æœ:")
        logger.info(f"  æ€»æ—¶é—´: {result['total_time']:.2f}ç§’")
        logger.info(f"  å¹³å‡æ—¶é—´: {result['avg_time']:.2f}ç§’/æŸ¥è¯¢")
        logger.info(f"  ç¼“å­˜å‘½ä¸­: {result['cache_hits']}/{len(filtered_queries)} ({result['cache_hit_rate']*100:.1f}%)")
        logger.info(f"  LLMè°ƒç”¨: {result['total_llm_calls']}æ¬¡")
        logger.info(f"  è¯„ä¼°æŒ‡æ ‡:")
        
        metrics = result['metrics']
        for k, v in metrics.items():
            if isinstance(v, float):
                logger.info(f"    {k}: {v:.3f}")
            else:
                logger.info(f"    {k}: {v}")
    
    # ä¿å­˜å®Œæ•´ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"experiment_results/cached_experiment_{args.dataset}_{timestamp}.json"
    Path("experiment_results").mkdir(exist_ok=True)
    
    with open(output_file, 'w') as f:
        json.dump(all_results, f, indent=2)
    
    logger.info(f"\nâœ… å®éªŒå®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {output_file}")
    
    # æ˜¾ç¤ºç¼“å­˜æ•ˆç‡æ€»ç»“
    logger.info("\n" + "="*80)
    logger.info("ç¼“å­˜æ•ˆç‡æ€»ç»“:")
    logger.info("="*80)
    
    for task, result in all_results.items():
        if result['cache_hits'] > 0:
            # ä¼°ç®—èŠ‚çœçš„æ—¶é—´ï¼ˆå‡è®¾æ¯ä¸ªä¼˜åŒ–å™¨+è§„åˆ’å™¨è°ƒç”¨éœ€è¦5ç§’ï¼‰
            saved_time = result['cache_hits'] * 5
            logger.info(f"{task.upper()} ä»»åŠ¡:")
            logger.info(f"  ç¼“å­˜å‘½ä¸­ç‡: {result['cache_hit_rate']*100:.1f}%")
            logger.info(f"  ä¼°è®¡èŠ‚çœæ—¶é—´: {saved_time:.1f}ç§’")
            logger.info(f"  å®é™…åŠ é€Ÿæ¯”: {(result['total_time'] + saved_time) / result['total_time']:.1f}x")


if __name__ == "__main__":
    main()