#!/usr/bin/env python3
"""
è¿è¡ŒOpenDataçš„JOINå’ŒUNIONä»»åŠ¡
æ”¯æŒsubsetå’Œcompleteç‰ˆæœ¬
"""

import subprocess
import sys
import json
from datetime import datetime
from pathlib import Path

def run_experiment(dataset_base: str, max_queries: int, output_prefix: str):
    """è¿è¡ŒJOINå’ŒUNIONå®éªŒ"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results = {}
    
    # åˆ†åˆ«è¿è¡ŒJOINå’ŒUNION
    for task in ['join', 'union']:
        dataset_path = f"{dataset_base}/{task}_subset" if 'subset' in dataset_base else f"{dataset_base}/{task}_complete"
        
        print(f"\n{'='*60}")
        print(f"ğŸš€ è¿è¡Œ {task.upper()} ä»»åŠ¡")
        print(f"ğŸ“‚ æ•°æ®é›†: {dataset_path}")
        print(f"ğŸ“Š æŸ¥è¯¢æ•°: {max_queries}")
        print(f"{'='*60}")
        
        # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
        if not Path(dataset_path).exists():
            print(f"âŒ æ•°æ®é›†ä¸å­˜åœ¨: {dataset_path}")
            continue
            
        # è¿è¡Œå®éªŒ
        cmd = [
            "python", "three_layer_ablation_optimized.py",
            "--task", task,
            "--dataset", dataset_path,
            "--max-queries", str(max_queries),
            "--simple"  # ä½¿ç”¨ç®€å•æŸ¥è¯¢ï¼Œä¸ä½¿ç”¨æŒ‘æˆ˜æ€§æŸ¥è¯¢
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            print(result.stdout)
            
            # æå–ç»“æœ
            output_file = f"experiment_results/ablation_optimized_{dataset_path.replace('/', '_')}_{timestamp}.json"
            if Path(output_file).exists():
                with open(output_file, 'r') as f:
                    task_results = json.load(f)
                    results[task] = task_results.get(task, {})
                    
        except subprocess.CalledProcessError as e:
            print(f"âŒ è¿è¡Œå¤±è´¥: {e}")
            print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
    
    # ä¿å­˜ç»¼åˆç»“æœ
    output_file = f"experiment_results/{output_prefix}_{timestamp}.json"
    Path("experiment_results").mkdir(exist_ok=True)
    
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nâœ… ç»¼åˆç»“æœä¿å­˜åˆ°: {output_file}")
    
    # æ‰“å°ç»“æœæ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ“Š å®éªŒç»“æœæ‘˜è¦")
    print("="*80)
    
    for task in results:
        print(f"\n{task.upper()} ä»»åŠ¡:")
        if 'L1_L2_L3' in results[task]:
            metrics = results[task]['L1_L2_L3']['metrics']
            print(f"  L1+L2+L3: F1={metrics['f1_score']:.3f}, Hit@1={metrics['hit@1']:.3f}")
        else:
            print("  æ— ç»“æœ")
    
    return results

def main():
    import argparse
    parser = argparse.ArgumentParser(description='è¿è¡ŒOpenData JOINå’ŒUNIONå®éªŒ')
    parser.add_argument('--version', choices=['subset', 'complete'], default='subset',
                       help='æ•°æ®é›†ç‰ˆæœ¬')
    parser.add_argument('--max-queries', type=int, default=20,
                       help='æœ€å¤§æŸ¥è¯¢æ•°')
    
    args = parser.parse_args()
    
    # ç¡®å®šæ•°æ®é›†è·¯å¾„
    if args.version == 'subset':
        dataset_base = "examples/opendata"
        output_prefix = "opendata_subset_both"
    else:
        dataset_base = "examples/opendata"
        output_prefix = "opendata_complete_both"
    
    # è¿è¡Œå®éªŒ
    run_experiment(dataset_base, args.max_queries, output_prefix)

if __name__ == "__main__":
    main()