#!/usr/bin/env python
"""
ç»Ÿä¸€å®éªŒè¿è¡Œå™¨ - æ”¯æŒWebTableã€SANTOSå’ŒNLCTablesä¸‰ä¸ªæ•°æ®é›†
å¯ä»¥ä½¿ç”¨åŒä¸€ä¸ªç³»ç»Ÿè¿è¡Œæ‰€æœ‰æ•°æ®é›†çš„å®éªŒ
æ”¯æŒä¸three_layer_ablation_optimized.pyç›¸åŒçš„æ‰€æœ‰å‚æ•°
"""

import os
import sys
import json
import time
import argparse
import logging
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def detect_dataset_type(tables_path: str) -> str:
    """è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†ç±»å‹"""
    path_str = str(tables_path).lower()
    
    if 'nlctables' in path_str:
        return 'nlctables'
    elif 'santos' in path_str:
        return 'santos'
    elif 'webtable' in path_str or 'final' in path_str:
        return 'webtable'
    else:
        # é»˜è®¤æ ¹æ®è¡¨åæ ¼å¼åˆ¤æ–­
        with open(tables_path, 'r') as f:
            tables = json.load(f)
            if tables and isinstance(tables[0], dict):
                first_table_name = tables[0].get('name', '')
                if first_table_name.startswith('dl_table_') or first_table_name.startswith('q_table_'):
                    return 'nlctables'
                elif 'santos' in first_table_name.lower():
                    return 'santos'
        return 'webtable'

def run_nlctables_experiment(layer: str, tables: List[Dict], queries: List[Dict], 
                            task_type: str, max_queries: int = None, 
                            max_workers: int = 4, challenging: bool = True) -> Tuple[List[Dict], float]:
    """è¿è¡ŒNLCTableså®éªŒ - ä½¿ç”¨ä¸»ç³»ç»Ÿé€šè¿‡é€‚é…å™¨"""
    logger.info(f"ğŸ”¬ Running NLCTables experiment with layer {layer}")
    logger.info(f"  Task type: {task_type}")
    logger.info(f"  Input queries: {len(queries)}")
    
    # ä½¿ç”¨ä¸»ç³»ç»Ÿè¿è¡ŒNLCTables
    from three_layer_ablation_optimized import run_layer_experiment
    
    # å¤„ç†æŸ¥è¯¢æ•°é‡ - åªåœ¨queriesé•¿åº¦å¤§äºmax_queriesæ—¶é™åˆ¶
    if max_queries is not None and len(queries) > max_queries:
        queries = queries[:max_queries]
        logger.info(f"  Limited to {max_queries} queries")
    
    # TODO: å¦‚æœéœ€è¦æŒ‘æˆ˜æ€§æŸ¥è¯¢ï¼Œå¯ä»¥åœ¨è¿™é‡Œå¤„ç†
    # if challenging:
    #     queries = create_challenging_queries(queries, tables)
    
    # è¿è¡Œå®éªŒ
    results_dict, elapsed_time = run_layer_experiment(
        layer=layer,
        tables=tables,
        queries=queries,
        task_type=task_type,
        dataset_type='nlctables',
        max_workers=max_workers
    )
    
    # è½¬æ¢ç»“æœæ ¼å¼ä»å­—å…¸åˆ°åˆ—è¡¨
    results = []
    if isinstance(results_dict, dict):
        for query_table, predictions in results_dict.items():
            results.append({
                'query_table': query_table,
                'predictions': predictions[:5] if isinstance(predictions, list) else []
            })
    else:
        results = results_dict
    
    logger.info(f"  Output results: {len(results)} entries")
    if results and len(results) > 0:
        logger.info(f"  First result: {results[0]['query_table']} -> {len(results[0].get('predictions', []))} predictions")
    
    return results, elapsed_time

def run_webtable_santos_experiment(layer: str, tables: List[Dict], queries: List[Dict],
                                  task_type: str, dataset_type: str, max_queries: int = None,
                                  max_workers: int = 4, challenging: bool = True) -> Tuple[List[Dict], float]:
    """è¿è¡ŒWebTable/SANTOSå®éªŒ - ä½¿ç”¨ä¸»ç³»ç»Ÿ"""
    logger.info(f"ğŸ”¬ Running {dataset_type.upper()} experiment with layer {layer}")
    
    # å¯¼å…¥ä¸»ç³»ç»Ÿ
    from three_layer_ablation_optimized import run_layer_experiment
    
    # å¤„ç†æŸ¥è¯¢æ•°é‡
    if max_queries is not None:
        queries = queries[:max_queries]
    
    # TODO: å¦‚æœéœ€è¦æŒ‘æˆ˜æ€§æŸ¥è¯¢ï¼Œå¯ä»¥åœ¨è¿™é‡Œå¤„ç†
    # if challenging:
    #     queries = create_challenging_queries(queries, tables)
    
    # è¿è¡Œå®éªŒ
    results_dict, elapsed_time = run_layer_experiment(
        layer=layer,
        tables=tables,
        queries=queries,
        task_type=task_type,
        dataset_type=dataset_type,
        max_workers=max_workers
    )
    
    # è½¬æ¢ç»“æœæ ¼å¼ä»å­—å…¸åˆ°åˆ—è¡¨
    results = []
    if isinstance(results_dict, dict):
        for query_table, predictions in results_dict.items():
            results.append({
                'query_table': query_table,
                'predictions': predictions[:5] if isinstance(predictions, list) else []
            })
    else:
        results = results_dict
    
    logger.info(f"  Output results: {len(results)} entries")
    if results and len(results) > 0:
        logger.info(f"  First result: {results[0]['query_table']} -> {len(results[0].get('predictions', []))} predictions")
    
    return results, elapsed_time

def evaluate_results(results: List[Dict], ground_truth, k_values: List[int] = [1, 3, 5]) -> Dict:
    """è¯„ä¼°ç»“æœ - ground_truth can be Dict or List"""
    from src.utils.evaluation import calculate_hit_at_k, calculate_precision_recall_f1
    
    metrics = {}
    
    # è®¡ç®—Hit@K
    for k in k_values:
        hit_rate = calculate_hit_at_k(results, ground_truth, k)
        metrics[f'hit@{k}'] = hit_rate
    
    # è®¡ç®—Precision/Recall/F1
    pr_metrics = calculate_precision_recall_f1(results, ground_truth)
    metrics.update(pr_metrics)
    
    return metrics

def print_results_table(all_results: Dict, all_metrics: Dict):
    """æ‰“å°ç»“æœç»Ÿè®¡è¡¨æ ¼"""
    # åˆ†ç¦»JOINå’ŒUNIONç»“æœ
    join_results = {}
    union_results = {}
    
    for exp_key, metrics in all_metrics.items():
        exp_data = all_results[exp_key]
        task = exp_data['task']
        layer = exp_data['layer']
        elapsed_time = exp_data['elapsed_time']
        
        result_data = {
            'layer': layer,
            'hit@1': metrics.get('hit@1', 0.0),
            'hit@3': metrics.get('hit@3', 0.0),
            'hit@5': metrics.get('hit@5', 0.0),
            'precision': metrics.get('precision', 0.0),
            'recall': metrics.get('recall', 0.0),
            'f1': metrics.get('f1', 0.0),
            'time': elapsed_time
        }
        
        if task == 'join':
            join_results[layer] = result_data
        elif task == 'union':
            union_results[layer] = result_data
    
    # æ‰“å°JOINç»“æœè¡¨æ ¼
    if join_results:
        print("\nJOIN Task Results:")
        print("-" * 116)
        print(f"{'Layer Config':<15} {'Hit@1':<10} {'Hit@3':<10} {'Hit@5':<10} {'Precision':<12} {'Recall':<10} {'F1-Score':<10} {'Time(s)':<10}")
        print("-" * 116)
        
        # æŒ‰L1, L1+L2, L1+L2+L3é¡ºåºæ’åº
        layer_order = ['L1', 'L1+L2', 'L1+L2+L3']
        for layer in layer_order:
            if layer in join_results:
                data = join_results[layer]
                print(f"{layer:<15} {data['hit@1']:<10.3f} {data['hit@3']:<10.3f} {data['hit@5']:<10.3f} "
                      f"{data['precision']:<12.3f} {data['recall']:<10.3f} {data['f1']:<10.3f} {data['time']:<10.2f}")
    
    # æ‰“å°UNIONç»“æœè¡¨æ ¼
    if union_results:
        print("\nUNION Task Results:")
        print("-" * 116)
        print(f"{'Layer Config':<15} {'Hit@1':<10} {'Hit@3':<10} {'Hit@5':<10} {'Precision':<12} {'Recall':<10} {'F1-Score':<10} {'Time(s)':<10}")
        print("-" * 116)
        
        # æŒ‰L1, L1+L2, L1+L2+L3é¡ºåºæ’åº
        for layer in layer_order:
            if layer in union_results:
                data = union_results[layer]
                print(f"{layer:<15} {data['hit@1']:<10.3f} {data['hit@3']:<10.3f} {data['hit@5']:<10.3f} "
                      f"{data['precision']:<12.3f} {data['recall']:<10.3f} {data['f1']:<10.3f} {data['time']:<10.2f}")

def main():
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€å®éªŒè¿è¡Œå™¨')
    parser.add_argument('--dataset', type=str, required=True,
                       help='æ•°æ®é›†è·¯å¾„æˆ–åç§° (webtable/santos/nlctables)')
    parser.add_argument('--task', type=str, choices=['join', 'union', 'both'], default='join',
                       help='ä»»åŠ¡ç±»å‹ (bothä¼šåŒæ—¶è¿è¡Œjoinå’Œunion)')
    parser.add_argument('--layer', type=str, choices=['L1', 'L1+L2', 'L1+L2+L3', 'all'], 
                       default='L1+L2+L3', help='è¿è¡Œçš„å±‚çº§ (allè¿è¡Œæ‰€æœ‰å±‚çº§)')
    parser.add_argument('--dataset-type', choices=['subset', 'complete', 'true_subset'], default='subset',
                       help='æ•°æ®é›†ç±»å‹: subset(å­é›†), complete(å®Œæ•´), true_subset(WebTableçš„çœŸå­é›†)')
    parser.add_argument('--max-queries', type=str, default='10',
                       help='æœ€å¤§æŸ¥è¯¢æ•° (æ•°å­—æˆ–"all"è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨)')
    parser.add_argument('--workers', type=int, default=4,
                       help='å¹¶è¡Œè¿›ç¨‹æ•°')
    parser.add_argument('--challenging', action='store_true', default=True,
                       help='ä½¿ç”¨æŒ‘æˆ˜æ€§æ··åˆæŸ¥è¯¢ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--simple', action='store_true',
                       help='ä½¿ç”¨ç®€å•åŸå§‹æŸ¥è¯¢ï¼ˆç¦ç”¨æŒ‘æˆ˜æ€§æŸ¥è¯¢ï¼‰')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', action='store_true',
                       help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º')
    parser.add_argument('--skip-llm', action='store_true',
                       help='è·³è¿‡LLMå±‚ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰')
    
    args = parser.parse_args()
    
    # å¤„ç†max_querieså‚æ•°
    if args.max_queries.lower() in ['all', '-1', 'none']:
        max_queries = None  # Noneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰æŸ¥è¯¢
        if args.verbose:
            print(f"ğŸ“Š ä½¿ç”¨æ•´ä¸ªæ•°æ®é›†çš„æ‰€æœ‰æŸ¥è¯¢")
    else:
        try:
            max_queries = int(args.max_queries)
            if args.verbose:
                print(f"ğŸ“Š é™åˆ¶æœ€å¤§æŸ¥è¯¢æ•°ä¸º: {max_queries}")
        except ValueError:
            print(f"âš ï¸ æ— æ•ˆçš„max-querieså€¼: {args.max_queries}ï¼Œä½¿ç”¨é»˜è®¤å€¼10")
            max_queries = 10
    
    # å¤„ç†simple/challengingå†²çª
    if args.simple:
        args.challenging = False
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœéœ€è¦è·³è¿‡LLMï¼‰
    if args.skip_llm:
        os.environ['SKIP_LLM'] = 'true'
    else:
        os.environ['SKIP_LLM'] = 'false'
    
    # ç¡®å®šæ•°æ®é›†è·¯å¾„
    if args.dataset in ['webtable', 'santos', 'nlctables']:
        # ä½¿ç”¨é¢„å®šä¹‰è·¯å¾„ï¼Œæ ¹æ®dataset-typeé€‰æ‹©
        if args.dataset == 'webtable':
            if args.dataset_type == 'subset' or args.dataset_type == 'true_subset':
                tables_path = 'examples/final_subset_tables.json'
            elif args.dataset_type == 'complete':
                tables_path = 'examples/final_complete_tables.json'
        elif args.dataset == 'santos':
            if args.dataset_type == 'subset':
                tables_path = 'examples/santos_subset/tables.json'
            elif args.dataset_type == 'complete':
                tables_path = 'examples/santos_complete/tables.json'  # å¦‚æœå­˜åœ¨
        elif args.dataset == 'nlctables':
            # NLCTablesè·¯å¾„æ ¼å¼ï¼šexamples/nlctables/{task}_{dataset_type}/
            tables_path = f'examples/nlctables/{args.task}_{args.dataset_type}/tables.json'
        
        dataset_type = args.dataset
    else:
        # ä½¿ç”¨æä¾›çš„è·¯å¾„
        tables_path = args.dataset
        dataset_type = detect_dataset_type(tables_path)
    
    logger.info(f"ğŸ“Š Dataset type detected: {dataset_type}")
    
    # åˆå§‹åŒ–ground_truth_pathï¼ˆå³ä½¿å¯¹NLCTablesä¹Ÿéœ€è¦ï¼‰
    base_dir = Path(tables_path).parent
    ground_truth_path = base_dir / 'ground_truth.json'
    
    # åŠ è½½æ•°æ® - å¯¹NLCTablesä½¿ç”¨é€‚é…å™¨
    if dataset_type == 'nlctables':
        # ä½¿ç”¨é€‚é…å™¨åŠ è½½NLCTablesæ•°æ®
        from nlctables_adapter import NLCTablesAdapter
        adapter = NLCTablesAdapter()
        
        # ä½¿ç”¨å‚æ•°ä¸­çš„dataset_type
        subset_type = args.dataset_type
        
        # å¦‚æœtaskæ˜¯bothï¼Œå…ˆåŠ è½½joinçš„æ•°æ®ï¼ˆåé¢ä¼šæ ¹æ®éœ€è¦é‡æ–°åŠ è½½ï¼‰
        initial_task = 'join' if args.task == 'both' else args.task
        
        tables, queries, ground_truth_list = adapter.load_nlctables_dataset(initial_task, subset_type)
        ground_truth = ground_truth_list  # é€‚é…å™¨å·²ç»è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        logger.info(f"Loaded {len(tables)} tables via NLCTables adapter")
        logger.info(f"Loaded {len(queries)} queries")
    else:
        # åŸæœ‰çš„åŠ è½½é€»è¾‘ï¼ˆWebTable/SANTOSï¼‰
        with open(tables_path, 'r') as f:
            tables = json.load(f)
        logger.info(f"Loaded {len(tables)} tables")
        
        # åŠ è½½æŸ¥è¯¢
        queries_path = base_dir / 'queries.json'
        
        if queries_path.exists():
            with open(queries_path, 'r') as f:
                queries = json.load(f)
            logger.info(f"Loaded {len(queries)} queries")
        else:
            # ç”Ÿæˆé»˜è®¤æŸ¥è¯¢
            queries = [{'query_table': t['name'], 'task_type': args.task} for t in tables[:10]]
            logger.warning("No queries file found, using first 10 tables as queries")
    
    # ç¡®å®šè¦è¿è¡Œçš„ä»»åŠ¡åˆ—è¡¨
    if args.task == 'both':
        tasks_to_run = ['join', 'union']
    else:
        tasks_to_run = [args.task]
    
    # ç¡®å®šè¦è¿è¡Œçš„å±‚çº§åˆ—è¡¨
    if args.layer == 'all':
        layers_to_run = ['L1', 'L1+L2', 'L1+L2+L3']
    else:
        layers_to_run = [args.layer]
    
    # è¿è¡Œæ‰€æœ‰ç»„åˆçš„å®éªŒ
    all_results = {}
    for task in tasks_to_run:
        for layer in layers_to_run:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸš€ è¿è¡Œå®éªŒ: ä»»åŠ¡={task}, å±‚çº§={layer}")
            logger.info(f"{'='*60}")
            
            # æ ¹æ®æ•°æ®é›†ç±»å‹è¿è¡Œå®éªŒ
            if dataset_type == 'nlctables':
                # NLCTableséœ€è¦ä¸ºä¸åŒä»»åŠ¡é‡æ–°åŠ è½½æ•°æ®
                if task != initial_task:
                    # é‡æ–°åŠ è½½å¯¹åº”ä»»åŠ¡çš„æ•°æ®
                    from nlctables_adapter import NLCTablesAdapter
                    adapter = NLCTablesAdapter()
                    current_tables, current_queries, current_ground_truth = adapter.load_nlctables_dataset(task, args.dataset_type)
                    logger.info(f"é‡æ–°åŠ è½½ {task} ä»»åŠ¡æ•°æ®: {len(current_tables)} è¡¨, {len(current_queries)} æŸ¥è¯¢")
                else:
                    # ä½¿ç”¨åˆå§‹åŠ è½½çš„æ•°æ®
                    current_tables, current_queries, current_ground_truth = tables, queries, ground_truth
                
                results, elapsed_time = run_nlctables_experiment(
                    layer=layer,
                    tables=current_tables,
                    queries=current_queries,
                    task_type=task,
                    max_queries=max_queries,
                    max_workers=args.workers,
                    challenging=args.challenging
                )
                
                # ä½¿ç”¨å½“å‰ä»»åŠ¡çš„ground truth
                ground_truth = current_ground_truth
            else:
                results, elapsed_time = run_webtable_santos_experiment(
                    layer=layer,
                    tables=tables,
                    queries=queries,
                    task_type=task,
                    dataset_type=dataset_type,
                    max_queries=max_queries,
                    max_workers=args.workers,
                    challenging=args.challenging
                )
            
            # ä¿å­˜ç»“æœå’Œå¯¹åº”çš„ground truth
            experiment_key = f"{task}_{layer}"
            all_results[experiment_key] = {
                'results': results,
                'elapsed_time': elapsed_time,
                'task': task,
                'layer': layer,
                'ground_truth': ground_truth if dataset_type == 'nlctables' else None  # ä¿å­˜å¯¹åº”çš„ground truth
            }
    
    # è¯„ä¼°æ‰€æœ‰ç»“æœ
    all_metrics = {}
    for exp_key, exp_data in all_results.items():
        results = exp_data['results']
        
        # è¯„ä¼°ç»“æœï¼ˆå¦‚æœæœ‰ground truthï¼‰
        if dataset_type == 'nlctables':
            # ä½¿ç”¨æ¯ä¸ªå®éªŒä¿å­˜çš„å¯¹åº”ground truth
            exp_ground_truth = exp_data.get('ground_truth')
            if exp_ground_truth:
                metrics = evaluate_results(results, exp_ground_truth)
                all_metrics[exp_key] = metrics
        elif ground_truth_path.exists():
            # å…¶ä»–æ•°æ®é›†ä½¿ç”¨æ–‡ä»¶ä¸­çš„ground truth
            with open(ground_truth_path, 'r') as f:
                ground_truth = json.load(f)
            metrics = evaluate_results(results, ground_truth)
            all_metrics[exp_key] = metrics
        
        # æ‰“å°è¯„ä¼°æŒ‡æ ‡
        if exp_key in all_metrics:
            logger.info(f"\nğŸ“ˆ è¯„ä¼°æŒ‡æ ‡ [{exp_key}]:")
            for metric, value in all_metrics[exp_key].items():
                logger.info(f"  {metric}: {value:.3f}")
    
    # ä¿å­˜ç»“æœ
    if args.output:
        output_path = args.output
    else:
        # è‡ªåŠ¨ä¿å­˜åˆ°experiment_resultsæ–‡ä»¶å¤¹
        experiment_dir = Path('experiment_results')
        experiment_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        layer_str = args.layer.replace('+', '_')
        filename = f'unified_results_{dataset_type}_{args.task}_{layer_str}_{timestamp}.json'
        output_path = experiment_dir / filename
    
    # æ„å»ºè¾“å‡ºæ•°æ®
    output_data = {
        'dataset': dataset_type,
        'dataset_type': args.dataset_type,
        'task': args.task,
        'layer': args.layer,
        'workers': args.workers,
        'max_queries': max_queries,
        'challenging': args.challenging,
        'experiments': all_results,
        'metrics': all_metrics if all_metrics else None
    }
    
    with open(output_path, 'w') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ğŸ’¾ Results saved to {output_path}")
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "="*60)
    print(f"ğŸ¯ ç»Ÿä¸€å®éªŒå®Œæˆ")
    print(f"   æ•°æ®é›†: {dataset_type} ({args.dataset_type})")
    print(f"   ä»»åŠ¡: {args.task}")
    print(f"   å±‚çº§: {args.layer}")
    print(f"   å¹¶è¡Œè¿›ç¨‹: {args.workers}")
    print(f"   æŸ¥è¯¢æ•°: {max_queries if max_queries else 'all'}")
    print(f"   æŒ‘æˆ˜æ€§æŸ¥è¯¢: {'å¯ç”¨' if args.challenging else 'ç¦ç”¨'}")
    
    # æ‰“å°æ¯ä¸ªå®éªŒçš„ç»“æœ
    for exp_key, exp_data in all_results.items():
        print(f"\n   ğŸ“Š {exp_key}:")
        print(f"      ç”¨æ—¶: {exp_data['elapsed_time']:.2f}s")
        if exp_key in all_metrics:
            metrics = all_metrics[exp_key]
            print(f"      Hit@1: {metrics.get('hit@1', 0):.3f}")
            print(f"      Hit@3: {metrics.get('hit@3', 0):.3f}")
            print(f"      F1: {metrics.get('f1', 0):.3f}")
    
    print("="*60)
    
    # æ‰“å°ç»Ÿè®¡è¡¨æ ¼
    if all_metrics:
        print_results_table(all_results, all_metrics)
        print()

if __name__ == "__main__":
    main()