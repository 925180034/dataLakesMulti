#!/usr/bin/env python3
"""
æ•°æ®æ¹–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå‘½ä»¤è¡Œç•Œé¢
"""
import asyncio
import json
import sys
from pathlib import Path
from typing import List, Dict, Any
import click
from src.core.multi_agent_workflow import create_workflow, DataLakeDiscoveryWorkflow
from src.core.models import AgentState, TableInfo, ColumnInfo
from src.config.settings import settings
from src.utils.data_parser import parse_tables_data, parse_columns_data


@click.group()
@click.version_option(version=settings.version)
def cli():
    """æ•°æ®æ¹–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ CLI"""
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    settings.create_directories()


@cli.command()
@click.option('--query', '-q', required=True, help='ç”¨æˆ·æŸ¥è¯¢è¯­å¥')
@click.option('--tables', '-t', help='æŸ¥è¯¢è¡¨çš„JSONæ–‡ä»¶è·¯å¾„')
@click.option('--columns', '-c', help='æŸ¥è¯¢åˆ—çš„JSONæ–‡ä»¶è·¯å¾„') 
@click.option('--output', '-o', help='è¾“å‡ºç»“æœåˆ°æ–‡ä»¶')
@click.option('--format', '-f', type=click.Choice(['json', 'markdown', 'table']), default='markdown', help='è¾“å‡ºæ ¼å¼')
@click.option('--all-tables', help='æ‰€æœ‰è¡¨çš„JSONæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºåˆå§‹åŒ–ä¼˜åŒ–å·¥ä½œæµï¼‰')
@click.option('--no-optimize', is_flag=True, help='ç¦ç”¨ä¼˜åŒ–å·¥ä½œæµï¼Œä½¿ç”¨åŸºç¡€ç‰ˆæœ¬')
def discover(query: str, tables: str, columns: str, output: str, format: str, all_tables: str = None, no_optimize: bool = False):
    """æ‰§è¡Œæ•°æ®å‘ç°"""
    try:
        # åŠ è½½è¾“å…¥æ•°æ®
        query_tables = []
        query_columns = []
        
        if tables:
            tables_path = Path(tables)
            if not tables_path.exists():
                click.echo(f"é”™è¯¯: è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {tables}", err=True)
                sys.exit(1)
            
            with open(tables_path) as f:
                tables_data = json.load(f)
                query_tables = parse_tables_data(tables_data)
        
        if columns:
            columns_path = Path(columns)
            if not columns_path.exists():
                click.echo(f"é”™è¯¯: åˆ—æ–‡ä»¶ä¸å­˜åœ¨: {columns}", err=True)
                sys.exit(1)
            
            with open(columns_path) as f:
                columns_data = json.load(f)
                query_columns = parse_columns_data(columns_data)
        
        if not query_tables and not query_columns:
            click.echo("é”™è¯¯: å¿…é¡»æä¾› --tables æˆ– --columns å‚æ•°", err=True)
            sys.exit(1)
        
        # åŠ è½½æ‰€æœ‰è¡¨æ•°æ®ï¼ˆå¦‚æœæä¾›ï¼‰
        all_tables_data = None
        if all_tables:
            if format != 'json':
                click.echo(f"ğŸ“Š åŠ è½½æ‰€æœ‰è¡¨æ•°æ®: {all_tables}")
            all_tables_path = Path(all_tables)
            if not all_tables_path.exists():
                click.echo(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {all_tables}", err=True)
                sys.exit(1)
            
            with open(all_tables_path) as f:
                all_tables_data = json.load(f)
                if format != 'json':
                    click.echo(f"âœ… å·²åŠ è½½ {len(all_tables_data)} ä¸ªè¡¨")
        
        # æ‰§è¡Œå‘ç° - åªåœ¨éJSONæ ¼å¼æ—¶æ˜¾ç¤ºè¿›åº¦
        if format != 'json':
            if no_optimize:
                click.echo("ğŸ” å¼€å§‹æ•°æ®å‘ç°ï¼ˆä½¿ç”¨åŸºç¡€å·¥ä½œæµï¼‰...")
            else:
                click.echo("ğŸš€ å¼€å§‹æ•°æ®å‘ç°ï¼ˆä½¿ç”¨ä¼˜åŒ–å·¥ä½œæµï¼‰...")
        
        result = asyncio.run(discover_data(
            user_query=query,
            query_tables=[t.model_dump() for t in query_tables],
            query_columns=[c.model_dump() for c in query_columns],
            all_tables_data=all_tables_data,
            use_optimized=not no_optimize
        ))
        
        # ç¡®ä¿resultæ˜¯AgentStateå¯¹è±¡
        if isinstance(result, dict):
            from src.core.models import AgentState
            result = AgentState.from_dict(result)
        
        # æ ¼å¼åŒ–è¾“å‡º
        if format == 'json':
            output_text = _format_json_output(result)
        elif format == 'table':
            output_text = _format_table_output(result)
        else:  # markdown
            output_text = _format_markdown_output(result)
        
        # è¾“å‡ºç»“æœ
        if output:
            with open(output, 'w', encoding='utf-8') as f:
                f.write(output_text)
            if format != 'json':  # JSONæ ¼å¼æ—¶é¿å…é¢å¤–è¾“å‡º
                click.echo(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output}")
        else:
            if format == 'json':
                # JSONæ ¼å¼æ—¶åªè¾“å‡ºçº¯JSONï¼Œä¸æ·»åŠ ä»»ä½•å‰ç¼€æˆ–åç¼€
                click.echo(output_text)
            else:
                # éJSONæ ¼å¼æ—¶ç›´æ¥è¾“å‡ºå†…å®¹ï¼ˆè¿›åº¦ä¿¡æ¯å·²åœ¨ä¸Šé¢æ˜¾ç¤ºï¼‰
                click.echo(output_text)
        
        # åªåœ¨éJSONæ ¼å¼æ—¶æ˜¾ç¤ºæ‘˜è¦
        if format != 'json':
            if result.final_results:
                click.echo(f"\nğŸ“Š æ‘˜è¦: æ‰¾åˆ° {len(result.final_results)} ä¸ªåŒ¹é…ç»“æœ")
            else:
                click.echo("\nâŒ æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")
            
    except Exception as e:
        click.echo(f"âŒ å‘ç°å¤±è´¥: {e}", err=True)
        sys.exit(1)


@cli.command()
@click.option('--tables', '-t', required=True, help='è¡¨æ•°æ®JSONæ–‡ä»¶è·¯å¾„')
@click.option('--columns', '-c', help='åˆ—æ•°æ®JSONæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
@click.option('--output', '-o', help='ç´¢å¼•ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
def build_index(tables: str, columns: str, output: str):
    """æ„å»ºWebTableæ•°æ®ç´¢å¼•ï¼ˆæ¨èä½¿ç”¨ï¼‰"""
    try:
        from src.tools.data_indexer import build_webtable_indices
        
        tables_path = Path(tables)
        if not tables_path.exists():
            click.echo(f"é”™è¯¯: è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {tables}", err=True)
            sys.exit(1)
        
        if columns:
            columns_path = Path(columns)
            if not columns_path.exists():
                click.echo(f"é”™è¯¯: åˆ—æ–‡ä»¶ä¸å­˜åœ¨: {columns}", err=True)
                sys.exit(1)
        
        click.echo("ğŸ”§ å¼€å§‹æ„å»ºWebTableæ•°æ®ç´¢å¼•...")
        click.echo(f"ğŸ“Š è¡¨æ•°æ®æ–‡ä»¶: {tables}")
        if columns:
            click.echo(f"ğŸ“Š åˆ—æ•°æ®æ–‡ä»¶: {columns}")
        if output:
            click.echo(f"ğŸ’¾ ç´¢å¼•ä¿å­˜è·¯å¾„: {output}")
        
        # æ„å»ºç´¢å¼•
        result = asyncio.run(build_webtable_indices(
            tables_file=str(tables_path),
            columns_file=str(columns_path) if columns else None,
            save_path=output
        ))
        
        if result['status'] == 'success':
            click.echo("\nâœ… ç´¢å¼•æ„å»ºå®Œæˆ!")
            click.echo(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            click.echo(f"  - å¤„ç†è¡¨æ•°: {result['tables_processed']}")
            click.echo(f"  - ç´¢å¼•è¡¨æ•°: {result['tables_indexed']}")
            click.echo(f"  - å¤„ç†åˆ—æ•°: {result['columns_processed']}")
            click.echo(f"  - ç´¢å¼•åˆ—æ•°: {result['columns_indexed']}")
            click.echo(f"  - ç´¢å¼•è·¯å¾„: {result['index_path']}")
        else:
            click.echo(f"âŒ ç´¢å¼•æ„å»ºå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}", err=True)
            sys.exit(1)
        
    except Exception as e:
        click.echo(f"âŒ ç´¢å¼•æ„å»ºå¤±è´¥: {e}", err=True)
        sys.exit(1)


@cli.command()
@click.option('--tables', '-t', required=True, help='è¡¨æ•°æ®JSONæ–‡ä»¶è·¯å¾„')
def index_tables(tables: str):
    """ä¸ºè¡¨å»ºç«‹ç´¢å¼•ï¼ˆå…¼å®¹æ€§å‘½ä»¤ï¼‰"""
    try:
        tables_path = Path(tables)
        if not tables_path.exists():
            click.echo(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {tables}", err=True)
            sys.exit(1)
        
        with open(tables_path) as f:
            tables_data = json.load(f)
        
        table_infos = [TableInfo(**data) for data in tables_data]
        
        click.echo(f"ğŸ”§ å¼€å§‹ä¸º {len(table_infos)} ä¸ªè¡¨å»ºç«‹ç´¢å¼•...")
        
        workflow = create_workflow()
        asyncio.run(workflow.table_discovery.initialize_table_index(table_infos))
        
        click.echo("âœ… è¡¨ç´¢å¼•å»ºç«‹å®Œæˆ")
        
    except Exception as e:
        click.echo(f"âŒ ç´¢å¼•å»ºç«‹å¤±è´¥: {e}", err=True)
        sys.exit(1)


@cli.command()
@click.option('--columns', '-c', required=True, help='åˆ—æ•°æ®JSONæ–‡ä»¶è·¯å¾„')
def index_columns(columns: str):
    """ä¸ºåˆ—å»ºç«‹ç´¢å¼•ï¼ˆå…¼å®¹æ€§å‘½ä»¤ï¼‰"""
    try:
        columns_path = Path(columns)
        if not columns_path.exists():
            click.echo(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {columns}", err=True)
            sys.exit(1)
        
        with open(columns_path) as f:
            columns_data = json.load(f)
        
        column_infos = [ColumnInfo(**data) for data in columns_data]
        
        click.echo(f"ğŸ”§ å¼€å§‹ä¸º {len(column_infos)} ä¸ªåˆ—å»ºç«‹ç´¢å¼•...")
        
        workflow = create_workflow()
        asyncio.run(workflow.column_discovery.initialize_indices(column_infos))
        
        click.echo("âœ… åˆ—ç´¢å¼•å»ºç«‹å®Œæˆ")
        
    except Exception as e:
        click.echo(f"âŒ ç´¢å¼•å»ºç«‹å¤±è´¥: {e}", err=True)
        sys.exit(1)


@cli.command()
@click.option('--path', '-p', help='ç´¢å¼•è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®è·¯å¾„ï¼‰')
def verify_index(path: str):
    """éªŒè¯ç´¢å¼•æ˜¯å¦æ­£ç¡®æ„å»º"""
    try:
        from src.tools.data_indexer import verify_indices
        
        click.echo("ğŸ” å¼€å§‹éªŒè¯ç´¢å¼•...")
        
        result = asyncio.run(verify_indices(path))
        
        if result['status'] == 'success':
            click.echo("âœ… ç´¢å¼•éªŒè¯æˆåŠŸ!")
            click.echo("ğŸ“Š ç´¢å¼•ç»Ÿè®¡:")
            
            vector_stats = result.get('vector_search', {})
            click.echo(f"  å‘é‡æœç´¢:")
            click.echo(f"    - åˆ—æ•°é‡: {vector_stats.get('column_count', 0)}")
            click.echo(f"    - è¡¨æ•°é‡: {vector_stats.get('table_count', 0)}")
            
            value_stats = result.get('value_search', {})
            click.echo(f"  å€¼æœç´¢:")
            click.echo(f"    - ç´¢å¼•åˆ—æ•°: {value_stats.get('indexed_columns', 0)}")
            
            if vector_stats.get('column_count', 0) == 0 and vector_stats.get('table_count', 0) == 0:
                click.echo("\nâš ï¸  è­¦å‘Š: ç´¢å¼•ä¸ºç©ºï¼Œè¯·å…ˆä½¿ç”¨ build-index å‘½ä»¤æ„å»ºç´¢å¼•")
        else:
            click.echo(f"âŒ ç´¢å¼•éªŒè¯å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}", err=True)
            sys.exit(1)
        
    except Exception as e:
        click.echo(f"âŒ ç´¢å¼•éªŒè¯å¤±è´¥: {e}", err=True)
        sys.exit(1)


@cli.command()
def serve():
    """å¯åŠ¨APIæœåŠ¡"""
    try:
        import uvicorn
        from src.api import app
        
        click.echo(f"ğŸš€ å¯åŠ¨APIæœåŠ¡ (ç«¯å£: 8000)...")
        click.echo(f"ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs")
        
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=8000,
            log_level=settings.logging.level.lower()
        )
        
    except ImportError:
        click.echo("âŒ éœ€è¦å®‰è£… uvicorn: pip install uvicorn", err=True)
        sys.exit(1)
    except Exception as e: 
        click.echo(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}", err=True)
        sys.exit(1)


@cli.command()
def config():
    """æ˜¾ç¤ºå½“å‰é…ç½®"""
    config_info = {
        "é¡¹ç›®åç§°": settings.project_name,
        "ç‰ˆæœ¬": settings.version,
        "è°ƒè¯•æ¨¡å¼": settings.debug,
        "LLMæä¾›å•†": settings.llm.provider,
        "LLMæ¨¡å‹": settings.llm.model_name,
        "å‘é‡æ•°æ®åº“": settings.vector_db.provider,
        "æ•°æ®ç›®å½•": str(settings.data_dir),
        "ç¼“å­˜ç›®å½•": str(settings.cache_dir),
        "æ—¥å¿—ç›®å½•": str(settings.log_dir)
    }
    
    click.echo("âš™ï¸  å½“å‰é…ç½®:")
    for key, value in config_info.items():
        click.echo(f"  {key}: {value}")


@cli.command()
def api_status():
    """æ˜¾ç¤ºAPIå¯†é’¥çŠ¶æ€"""
    try:
        from src.utils.llm_client import llm_client
        
        # æ£€æŸ¥LLMå®¢æˆ·ç«¯æ˜¯å¦æ”¯æŒAPIçŠ¶æ€æŸ¥è¯¢
        if hasattr(llm_client, 'get_api_status'):
            status = llm_client.get_api_status()
            
            click.echo("ğŸ”‘ APIå¯†é’¥çŠ¶æ€:")
            click.echo(f"  æä¾›å•†: {status.get('provider', 'unknown')}")
            click.echo(f"  æ€»å¯†é’¥æ•°: {status.get('total_keys', 0)}")
            click.echo(f"  å¯ç”¨å¯†é’¥æ•°: {status.get('active_keys', 0)}")
            
            # æ˜¾ç¤ºæ¯ä¸ªå¯†é’¥çš„è¯¦ç»†çŠ¶æ€
            if 'keys_status' in status:
                click.echo("\nå¯†é’¥è¯¦æƒ…:")
                for i, key_info in enumerate(status['keys_status'], 1):
                    status_icon = "âœ…" if key_info['is_available'] else "âŒ"
                    cooldown = key_info.get('cooldown_remaining', 0)
                    cooldown_str = f" (å†·å´å‰©ä½™: {cooldown:.0f}s)" if cooldown > 0 else ""
                    
                    click.echo(f"  {i}. {key_info['key_prefix']} {status_icon}{cooldown_str}")
                    click.echo(f"     é”™è¯¯æ¬¡æ•°: {key_info['error_count']}, æ€»è¯·æ±‚: {key_info['total_requests']}")
        else:
            click.echo("âš ï¸  å½“å‰LLMå®¢æˆ·ç«¯ä¸æ”¯æŒAPIå¯†é’¥çŠ¶æ€æŸ¥è¯¢")
            
    except Exception as e:
        click.echo(f"âŒ è·å–APIçŠ¶æ€å¤±è´¥: {e}", err=True)


def _format_json_output(result: AgentState) -> str:
    """æ ¼å¼åŒ–JSONè¾“å‡º"""
    # å®‰å…¨åœ°è·å–ç­–ç•¥å€¼
    strategy_value = None
    if hasattr(result, 'strategy') and result.strategy:
        strategy_value = result.strategy.value if hasattr(result.strategy, 'value') else str(result.strategy)
    
    output_data = {
        "strategy": strategy_value,
        "results_count": len(getattr(result, 'final_results', [])),
        "results": [
            {
                "source_table": r.source_table,
                "target_table": r.target_table,
                "score": r.score,
                "matched_columns": [
                    {
                        "source": m.source_column,
                        "target": m.target_column,
                        "confidence": m.confidence,
                        "match_type": m.match_type
                    }
                    for m in r.matched_columns
                ]
            }
            for r in getattr(result, 'final_results', [])
        ],
        "final_report": getattr(result, 'final_report', ''),
        "errors": getattr(result, 'error_messages', [])
    }
    
    return json.dumps(output_data, ensure_ascii=False, indent=2)


def _format_markdown_output(result: AgentState) -> str:
    """æ ¼å¼åŒ–Markdownè¾“å‡º"""
    lines = ["# æ•°æ®å‘ç°ç»“æœ\n"]
    
    if result.strategy:
        lines.append(f"**ç­–ç•¥**: {result.strategy.value}\n")
    
    if result.final_report:
        lines.append("## åˆ†ææŠ¥å‘Š\n")
        lines.append(result.final_report + "\n")
    
    if result.final_results:
        lines.append("## åŒ¹é…ç»“æœ\n")
        
        for i, match_result in enumerate(result.final_results, 1):
            lines.append(f"### {i}. {match_result.target_table}")
            lines.append(f"- **è¯„åˆ†**: {match_result.score:.1f}")
            lines.append(f"- **åŒ¹é…åˆ—æ•°**: {len(match_result.matched_columns)}")
            
            if match_result.matched_columns:
                lines.append("- **åŒ¹é…è¯¦æƒ…**:")
                for match in match_result.matched_columns[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    lines.append(f"  - {match.source_column} â†’ {match.target_column} "
                               f"(ç½®ä¿¡åº¦: {match.confidence:.3f})")
            lines.append("")
    
    if result.error_messages:
        lines.append("## é”™è¯¯ä¿¡æ¯\n")
        for error in result.error_messages:
            lines.append(f"- {error}")
        lines.append("")
    
    return "\n".join(lines)


def _format_table_output(result: AgentState) -> str:
    """æ ¼å¼åŒ–è¡¨æ ¼è¾“å‡º"""
    if not result.final_results:
        return "æœªæ‰¾åˆ°åŒ¹é…ç»“æœ"
    
    # ç®€å•çš„è¡¨æ ¼æ ¼å¼
    lines = ["æ’å | ç›®æ ‡è¡¨ | è¯„åˆ† | åŒ¹é…åˆ—æ•°"]
    lines.append("----|------|------|--------")
    
    for i, match_result in enumerate(result.final_results, 1):
        lines.append(f"{i:2d}   | {match_result.target_table:20} | "
                    f"{match_result.score:5.1f} | {len(match_result.matched_columns):6d}")
    
    return "\n".join(lines)


if __name__ == '__main__':
    cli()