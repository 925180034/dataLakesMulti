"""
å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
å®Œæ•´å®ç°å¤šAgentååŒ + ä¸‰å±‚åŠ é€Ÿæ¶æ„
"""

import asyncio
import logging
import time
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict
import json

from src.core.models import TableInfo, ColumnInfo, AgentState, TaskStrategy
from src.core.multi_agent_system import (
    IntelligentAgent, AgentRole, AgentMessage,
    PlannerAgent, SearcherAgent, MatcherAgent
)
from src.tools.metadata_filter import MetadataFilter
from src.tools.batch_vector_search import BatchVectorSearch
from src.tools.smart_llm_matcher import SmartLLMMatcher
from src.utils.llm_client import create_llm_client

logger = logging.getLogger(__name__)


class AnalyzerAgent(IntelligentAgent):
    """åˆ†æAgent - è´Ÿè´£ç†è§£è¡¨ç»“æ„å’Œæ•°æ®ç‰¹å¾"""
    
    def __init__(self):
        super().__init__("AnalyzerAgent", AgentRole.ANALYZER)
        self.schema_cache = {}
        self.pattern_cache = {}
    
    async def think(self, task: Dict) -> Dict:
        """åˆ†æè¡¨ç»“æ„ï¼Œè¯†åˆ«æ¨¡å¼"""
        tables = task.get('tables', [])
        query_table = task.get('query_table')
        
        analysis = {
            'table_count': len(tables),
            'has_query_table': query_table is not None,
            'analysis_depth': 'deep' if len(tables) < 100 else 'shallow',
            'use_llm': len(tables) < 20 and self.can_call_llm,
            'patterns': []
        }
        
        # è¯†åˆ«æ•°æ®æ¨¡å¼
        if query_table:
            patterns = self._identify_patterns(query_table)
            analysis['patterns'] = patterns
            analysis['key_columns'] = self._extract_key_columns(query_table)
        
        return analysis
    
    async def act(self, plan: Dict) -> Dict:
        """æ‰§è¡Œåˆ†æ"""
        result = {
            'schema_analysis': {},
            'pattern_matches': {},
            'recommendations': []
        }
        
        # æ·±åº¦åˆ†æ
        if plan.get('analysis_depth') == 'deep':
            if plan.get('use_llm') and self.llm_client:
                # ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æ
                result['llm_insights'] = await self._llm_analyze_schema(plan)
            else:
                # ä½¿ç”¨è§„åˆ™åˆ†æ
                result['rule_insights'] = self._rule_analyze_schema(plan)
        
        # ä½¿ç”¨ä¸‰å±‚åŠ é€Ÿä¼˜åŒ–åˆ†æ
        if self.use_acceleration and self.metadata_filter:
            # Layer 1: å¿«é€Ÿå…ƒæ•°æ®åˆ†æ
            result['metadata_summary'] = await self._fast_metadata_analysis(plan)
        
        return result
    
    def _identify_patterns(self, table: TableInfo) -> List[str]:
        """è¯†åˆ«è¡¨æ¨¡å¼"""
        patterns = []
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»´åº¦è¡¨
        if self._is_dimension_table(table):
            patterns.append('dimension_table')
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯äº‹å®è¡¨
        if self._is_fact_table(table):
            patterns.append('fact_table')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´åºåˆ—
        if self._has_time_series(table):
            patterns.append('time_series')
        
        return patterns
    
    def _extract_key_columns(self, table: TableInfo) -> List[str]:
        """æå–å…³é”®åˆ—"""
        key_columns = []
        
        for col in table.columns:
            col_name = col.column_name.lower()
            # ä¸»é”®æ¨¡å¼
            if any(pattern in col_name for pattern in ['id', 'key', 'code']):
                key_columns.append(col.column_name)
            # å¤–é”®æ¨¡å¼
            elif col_name.endswith('_id') or col_name.endswith('_key'):
                key_columns.append(col.column_name)
        
        return key_columns
    
    def _is_dimension_table(self, table: TableInfo) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç»´åº¦è¡¨"""
        table_name = table.table_name.lower()
        dim_patterns = ['dim_', 'dimension_', 'd_', '_dim']
        return any(pattern in table_name for pattern in dim_patterns)
    
    def _is_fact_table(self, table: TableInfo) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºäº‹å®è¡¨"""
        table_name = table.table_name.lower()
        fact_patterns = ['fact_', 'f_', 'agg_', '_fact']
        return any(pattern in table_name for pattern in fact_patterns)
    
    def _has_time_series(self, table: TableInfo) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´åºåˆ—æ•°æ®"""
        time_columns = ['date', 'time', 'timestamp', 'created_at', 'updated_at']
        column_names = [col.column_name.lower() for col in table.columns]
        return any(tc in col for tc in time_columns for col in column_names)
    
    async def _llm_analyze_schema(self, plan: Dict) -> Dict:
        """ä½¿ç”¨LLMåˆ†æschema"""
        if not self.llm_client:
            return {}
        
        query_table = plan.get('query_table')
        if not query_table:
            return {}
        
        prompt = f"""
        Analyze this table schema and identify:
        1. Table type (dimension, fact, lookup, etc.)
        2. Key columns for joining
        3. Data patterns
        
        Table: {query_table.table_name}
        Columns: {[col.column_name for col in query_table.columns[:10]]}
        
        Return insights as JSON.
        """
        
        try:
            response = await self.llm_client.generate(prompt)
            return {'llm_analysis': response}
        except:
            return {}
    
    def _rule_analyze_schema(self, plan: Dict) -> Dict:
        """åŸºäºè§„åˆ™åˆ†æschema"""
        query_table = plan.get('query_table')
        if not query_table:
            return {}
        
        return {
            'column_count': len(query_table.columns),
            'has_primary_key': any('id' in col.column_name.lower() 
                                  for col in query_table.columns),
            'potential_foreign_keys': [
                col.column_name for col in query_table.columns
                if col.column_name.lower().endswith('_id')
            ]
        }
    
    async def _fast_metadata_analysis(self, plan: Dict) -> Dict:
        """å¿«é€Ÿå…ƒæ•°æ®åˆ†æ"""
        # ä½¿ç”¨Layer 1åŠ é€Ÿ
        return {
            'analysis_time': 'fast',
            'method': 'metadata_filter',
            'cached': True
        }


class AggregatorAgent(IntelligentAgent):
    """èšåˆAgent - è´Ÿè´£æ•´åˆå’Œæ’åºç»“æœ"""
    
    def __init__(self):
        super().__init__("AggregatorAgent", AgentRole.AGGREGATOR)
        self.ranking_strategies = {
            'score': self._rank_by_score,
            'relevance': self._rank_by_relevance,
            'hybrid': self._hybrid_ranking
        }
    
    async def think(self, task: Dict) -> Dict:
        """å†³å®šèšåˆç­–ç•¥"""
        results = task.get('results', [])
        
        # æ ¹æ®ç»“æœæ•°é‡é€‰æ‹©ç­–ç•¥
        if len(results) > 100:
            strategy = 'score'  # å¤§é‡ç»“æœç”¨ç®€å•è¯„åˆ†
        elif len(results) > 20:
            strategy = 'hybrid'  # ä¸­ç­‰æ•°é‡ç”¨æ··åˆç­–ç•¥
        else:
            strategy = 'relevance'  # å°‘é‡ç»“æœç”¨å¤æ‚ç›¸å…³æ€§åˆ†æ
        
        return {
            'ranking_strategy': strategy,
            'top_k': task.get('top_k', 10),
            'merge_duplicates': True,
            'use_llm_rerank': len(results) < 30 and self.can_call_llm
        }
    
    async def act(self, plan: Dict) -> List[Dict]:
        """æ‰§è¡Œèšåˆ"""
        strategy = plan.get('ranking_strategy', 'hybrid')
        results = plan.get('results', [])
        
        # å»é‡
        if plan.get('merge_duplicates'):
            results = self._merge_duplicates(results)
        
        # æ’åº
        if strategy in self.ranking_strategies:
            ranked_results = await self.ranking_strategies[strategy](results, plan)
        else:
            ranked_results = results
        
        # LLMé‡æ’åºï¼ˆå¯é€‰ï¼‰
        if plan.get('use_llm_rerank') and self.llm_client:
            ranked_results = await self._llm_rerank(ranked_results, plan)
        
        # è¿”å›Top-K
        return ranked_results[:plan.get('top_k', 10)]
    
    def _merge_duplicates(self, results: List[Dict]) -> List[Dict]:
        """åˆå¹¶é‡å¤ç»“æœ"""
        seen = {}
        merged = []
        
        for result in results:
            table_name = result.get('table', result.get('table_name'))
            if table_name in seen:
                # åˆå¹¶åˆ†æ•°
                seen[table_name]['score'] = max(
                    seen[table_name].get('score', 0),
                    result.get('score', 0)
                )
                # åˆå¹¶è¯æ®
                if 'evidence' in result:
                    if 'evidence' not in seen[table_name]:
                        seen[table_name]['evidence'] = []
                    seen[table_name]['evidence'].append(result['evidence'])
            else:
                seen[table_name] = result
                merged.append(result)
        
        return merged
    
    async def _rank_by_score(self, results: List[Dict], plan: Dict) -> List[Dict]:
        """æŒ‰åˆ†æ•°æ’åº"""
        return sorted(results, key=lambda x: x.get('score', 0), reverse=True)
    
    async def _rank_by_relevance(self, results: List[Dict], plan: Dict) -> List[Dict]:
        """æŒ‰ç›¸å…³æ€§æ’åº"""
        # å¤æ‚çš„ç›¸å…³æ€§è®¡ç®—
        for result in results:
            relevance = result.get('score', 0) * 0.5
            
            # è€ƒè™‘å¤šä¸ªå› ç´ 
            if result.get('method') == 'llm_verified':
                relevance += 0.3
            if result.get('has_foreign_key'):
                relevance += 0.2
            
            result['relevance'] = relevance
        
        return sorted(results, key=lambda x: x.get('relevance', 0), reverse=True)
    
    async def _hybrid_ranking(self, results: List[Dict], plan: Dict) -> List[Dict]:
        """æ··åˆæ’åºç­–ç•¥"""
        # ç»“åˆåˆ†æ•°å’Œç›¸å…³æ€§
        for result in results:
            score = result.get('score', 0)
            relevance_boost = 0
            
            # æ ¹æ®åŒ¹é…æ–¹æ³•åŠ æƒ
            method = result.get('method', '')
            if 'llm' in method:
                relevance_boost += 0.2
            if 'vector' in method:
                relevance_boost += 0.1
            
            result['final_score'] = score * (1 + relevance_boost)
        
        return sorted(results, key=lambda x: x.get('final_score', 0), reverse=True)
    
    async def _llm_rerank(self, results: List[Dict], plan: Dict) -> List[Dict]:
        """ä½¿ç”¨LLMé‡æ–°æ’åº"""
        if not self.llm_client or not results:
            return results
        
        # å‡†å¤‡é‡æ’åºprompt
        query = plan.get('query', '')
        tables = [r.get('table', r.get('table_name')) for r in results[:10]]
        
        prompt = f"""
        Rerank these tables based on relevance to the query.
        Query: {query}
        Tables: {tables}
        
        Return the table names in order of relevance.
        """
        
        try:
            response = await self.llm_client.generate(prompt)
            # ç®€å•è§£æå¹¶é‡æ’åº
            # ... å®ç°ç»†èŠ‚ ...
            return results
        except:
            return results


class OptimizerAgent(IntelligentAgent):
    """ä¼˜åŒ–Agent - è´Ÿè´£æ€§èƒ½ä¼˜åŒ–å’Œèµ„æºç®¡ç†"""
    
    def __init__(self):
        super().__init__("OptimizerAgent", AgentRole.OPTIMIZER)
        self.performance_stats = defaultdict(list)
        self.optimization_history = []
    
    async def think(self, task: Dict) -> Dict:
        """åˆ†ææ€§èƒ½ç“¶é¢ˆï¼Œåˆ¶å®šä¼˜åŒ–ç­–ç•¥"""
        current_stats = task.get('performance_stats', {})
        
        optimization_plan = {
            'use_cache': True,
            'parallel_execution': False,
            'batch_size': 10,
            'optimization_level': 'balanced'
        }
        
        # æ ¹æ®æ€§èƒ½ç»Ÿè®¡å†³å®šä¼˜åŒ–ç­–ç•¥
        if current_stats.get('avg_latency', 0) > 5:
            # é«˜å»¶è¿Ÿï¼Œéœ€è¦æ¿€è¿›ä¼˜åŒ–
            optimization_plan['optimization_level'] = 'aggressive'
            optimization_plan['parallel_execution'] = True
            optimization_plan['batch_size'] = 20
        elif current_stats.get('memory_usage', 0) > 0.8:
            # å†…å­˜å‹åŠ›ï¼Œéœ€è¦ä¿å®ˆä¼˜åŒ–
            optimization_plan['optimization_level'] = 'conservative'
            optimization_plan['batch_size'] = 5
        
        return optimization_plan
    
    async def act(self, plan: Dict) -> Dict:
        """æ‰§è¡Œä¼˜åŒ–"""
        optimizations = {}
        
        # ç¼“å­˜ä¼˜åŒ–
        if plan.get('use_cache'):
            optimizations['cache_enabled'] = True
            optimizations['cache_ttl'] = 3600
        
        # å¹¶è¡Œä¼˜åŒ–
        if plan.get('parallel_execution'):
            optimizations['max_workers'] = 4
            optimizations['async_mode'] = True
        
        # æ‰¹å¤„ç†ä¼˜åŒ–
        optimizations['batch_size'] = plan.get('batch_size', 10)
        
        # ä¸‰å±‚åŠ é€Ÿä¼˜åŒ–
        if self.use_acceleration:
            optimizations['acceleration_config'] = {
                'layer1_enabled': True,
                'layer2_enabled': True,
                'layer3_enabled': plan.get('optimization_level') != 'conservative'
            }
        
        # è®°å½•ä¼˜åŒ–å†å²
        self.optimization_history.append({
            'timestamp': time.time(),
            'plan': plan,
            'optimizations': optimizations
        })
        
        return optimizations
    
    def get_performance_report(self) -> Dict:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        return {
            'optimization_history': self.optimization_history[-10:],
            'current_stats': dict(self.performance_stats),
            'recommendations': self._generate_recommendations()
        }
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åŸºäºå†å²æ•°æ®ç”Ÿæˆå»ºè®®
        if len(self.optimization_history) > 5:
            recent = self.optimization_history[-5:]
            
            # æ£€æŸ¥æ˜¯å¦é¢‘ç¹ä½¿ç”¨æ¿€è¿›ä¼˜åŒ–
            aggressive_count = sum(1 for r in recent 
                                 if r['plan'].get('optimization_level') == 'aggressive')
            if aggressive_count > 3:
                recommendations.append("Consider scaling up resources")
            
            # æ£€æŸ¥ç¼“å­˜æ•ˆæœ
            cache_enabled = all(r['optimizations'].get('cache_enabled') 
                              for r in recent)
            if not cache_enabled:
                recommendations.append("Enable caching for better performance")
        
        return recommendations


class EnhancedMultiAgentOrchestrator:
    """å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿåè°ƒå™¨"""
    
    def __init__(self):
        self.agents = {}
        self.message_bus = []
        self.shared_tools = {}
        self.performance_monitor = {
            'query_count': 0,
            'total_time': 0,
            'success_rate': 0,
            'agent_stats': defaultdict(lambda: {'calls': 0, 'time': 0})
        }
    
    async def initialize(self, all_tables: List[TableInfo]):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆå¤šAgentç³»ç»Ÿ"""
        logger.info("Initializing Enhanced Multi-Agent System...")
        
        # åˆå§‹åŒ–ä¸‰å±‚åŠ é€Ÿå·¥å…·
        await self._initialize_acceleration_layers(all_tables)
        
        # åˆ›å»ºæ‰€æœ‰Agent
        self.agents = {
            'planner': PlannerAgent(),
            'analyzer': AnalyzerAgent(),
            'searcher': SearcherAgent(),
            'matcher': MatcherAgent(),
            'aggregator': AggregatorAgent(),
            'optimizer': OptimizerAgent()
        }
        
        # åˆå§‹åŒ–æ‰€æœ‰Agent
        for agent in self.agents.values():
            await agent.initialize(self.shared_tools)
        
        logger.info(f"Enhanced Multi-Agent System initialized with {len(self.agents)} agents")
    
    async def _initialize_acceleration_layers(self, all_tables: List[TableInfo]):
        """åˆå§‹åŒ–ä¸‰å±‚åŠ é€Ÿæ¶æ„"""
        # Layer 1: å…ƒæ•°æ®ç­›é€‰
        self.shared_tools['metadata_filter'] = MetadataFilter()
        # build_index is not async, call it directly
        self.shared_tools['metadata_filter'].build_index(all_tables)
        
        # Layer 2: å‘é‡æœç´¢
        from src.tools.vector_search import get_vector_search_engine
        from src.tools.embedding import get_embedding_generator
        
        vector_engine = get_vector_search_engine()
        embedding_gen = get_embedding_generator()
        
        # ä¸ºæ‰€æœ‰è¡¨åˆ›å»ºå‘é‡ç´¢å¼•
        for table in all_tables:
            # åˆ›å»ºè¡¨çš„æ–‡æœ¬è¡¨ç¤º
            table_text = f"{table.table_name} columns: {', '.join([col.column_name for col in table.columns[:10]])}"
            # ç”Ÿæˆå‘é‡åµŒå…¥
            table_embedding = await embedding_gen.generate_text_embedding(table_text)
            await vector_engine.add_table_vector(table, table_embedding)
        
        self.shared_tools['vector_search'] = BatchVectorSearch(vector_engine)
        
        # Layer 3: æ™ºèƒ½LLMåŒ¹é…
        llm_client = create_llm_client()
        self.shared_tools['llm_matcher'] = SmartLLMMatcher(llm_client)
        
        # é¢å¤–ï¼šè¡¨å…ƒæ•°æ®ç¼“å­˜
        self.shared_tools['table_metadata'] = {
            table.table_name: table for table in all_tables
        }
        
        logger.info("Three-layer acceleration initialized for all agents")
    
    async def process_query_with_collaboration(
        self,
        query: str,
        query_table: TableInfo,
        strategy: str = "auto"
    ) -> List[Dict]:
        """å¤„ç†æŸ¥è¯¢ - å®Œæ•´çš„å¤šAgentååŒå·¥ä½œæµ"""
        
        start_time = time.time()
        self.performance_monitor['query_count'] += 1
        
        logger.info(f"Processing query with multi-agent collaboration: {query}")
        
        # Step 1: ä¼˜åŒ–å™¨åˆ†æå½“å‰ç³»ç»ŸçŠ¶æ€
        optimizer = self.agents['optimizer']
        optimization_task = {'performance_stats': self.performance_monitor}
        optimization_plan = await optimizer.think(optimization_task)
        optimizations = await optimizer.act(optimization_plan)
        
        logger.info(f"Optimization level: {optimization_plan.get('optimization_level')}")
        
        # Step 2: è§„åˆ’è€…åˆ¶å®šç­–ç•¥
        planner = self.agents['planner']
        task = {
            'query': query,
            'query_table': query_table,
            'optimizations': optimizations
        }
        plan = await planner.think(task)
        detailed_plan = await planner.act(plan)
        
        # Step 3: åˆ†æè€…ç†è§£æ•°æ®
        analyzer = self.agents['analyzer']
        analysis_task = {
            'tables': list(self.shared_tools['table_metadata'].values()),
            'query_table': query_table,
            **detailed_plan
        }
        analysis_plan = await analyzer.think(analysis_task)
        analysis_result = await analyzer.act(analysis_plan)
        
        # Step 4: æœç´¢è€…æŸ¥æ‰¾å€™é€‰ï¼ˆä½¿ç”¨ä¸‰å±‚åŠ é€Ÿï¼‰
        searcher = self.agents['searcher']
        search_task = {
            **detailed_plan,
            **analysis_result,
            'query_table': query_table,
            'max_candidates': optimizations.get('batch_size', 10) * 10
        }
        search_plan = await searcher.think(search_task)
        candidates = await searcher.act(search_plan)
        
        logger.info(f"Searcher found {len(candidates)} candidates using {search_plan.get('search_method')}")
        
        # Step 5: åŒ¹é…è€…éªŒè¯ï¼ˆä½¿ç”¨Layer 3 LLMï¼‰
        matcher = self.agents['matcher']
        match_task = {
            'candidates': candidates,
            'query_table': query_table,
            'table_metadata': self.shared_tools['table_metadata'],
            **analysis_result
        }
        match_plan = await matcher.think(match_task)
        matches = await matcher.act(match_plan)
        
        logger.info(f"Matcher verified {len(matches)} matches using {match_plan.get('match_strategy')}")
        
        # Step 6: èšåˆè€…æ•´åˆç»“æœ
        aggregator = self.agents['aggregator']
        aggregation_task = {
            'results': matches,
            'query': query,
            'top_k': 10
        }
        aggregation_plan = await aggregator.think(aggregation_task)
        final_results = await aggregator.act(aggregation_plan)
        
        # Step 7: Agenté—´æ¶ˆæ¯å¹¿æ’­ï¼ˆååŒé€šä¿¡ï¼‰
        completion_message = AgentMessage(
            sender="orchestrator",
            receiver="all",
            message_type="query_completed",
            content={
                'query': query,
                'result_count': len(final_results),
                'execution_time': time.time() - start_time
            }
        )
        await self.broadcast_message(completion_message)
        
        # æ›´æ–°æ€§èƒ½ç›‘æ§
        execution_time = time.time() - start_time
        self.performance_monitor['total_time'] += execution_time
        
        logger.info(f"Query completed in {execution_time:.2f}s with {len(final_results)} results")
        
        return final_results
    
    async def broadcast_message(self, message: AgentMessage):
        """å¹¿æ’­æ¶ˆæ¯ç»™æ‰€æœ‰Agent"""
        self.message_bus.append(message)
        
        for agent in self.agents.values():
            if agent.name != message.sender:
                await agent.communicate(message)
    
    def get_detailed_status(self) -> Dict:
        """è·å–è¯¦ç»†ç³»ç»ŸçŠ¶æ€"""
        return {
            'system': {
                'num_agents': len(self.agents),
                'agents': list(self.agents.keys()),
                'message_count': len(self.message_bus)
            },
            'acceleration': {
                'layer1_enabled': self.shared_tools.get('metadata_filter') is not None,
                'layer2_enabled': self.shared_tools.get('vector_search') is not None,
                'layer3_enabled': self.shared_tools.get('llm_matcher') is not None
            },
            'performance': {
                'queries_processed': self.performance_monitor['query_count'],
                'avg_time': (self.performance_monitor['total_time'] / 
                           max(1, self.performance_monitor['query_count'])),
                'agent_stats': dict(self.performance_monitor['agent_stats'])
            },
            'optimizer_report': self.agents['optimizer'].get_performance_report() 
                              if 'optimizer' in self.agents else {}
        }


async def test_enhanced_multi_agent_system():
    """æµ‹è¯•å¢å¼ºç‰ˆå¤šAgentç³»ç»Ÿ"""
    print("="*80)
    print("ğŸ¤– å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæµ‹è¯•")
    print("="*80)
    
    # åŠ è½½çœŸå®æ•°æ®
    import json
    from pathlib import Path
    
    dataset_path = Path("examples/separated_datasets/join_subset/tables.json")
    if dataset_path.exists():
        with open(dataset_path) as f:
            tables_data = json.load(f)[:20]  # ä½¿ç”¨20ä¸ªè¡¨æµ‹è¯•
        
        tables = []
        for td in tables_data:
            table = TableInfo(
                table_name=td['table_name'],
                columns=[
                    ColumnInfo(
                        table_name=td['table_name'],
                        column_name=col.get('column_name', col.get('name', '')),
                        data_type=col.get('data_type', 'unknown'),
                        sample_values=col.get('sample_values', [])[:3]
                    )
                    for col in td.get('columns', [])[:10]
                ]
            )
            tables.append(table)
    else:
        # ä½¿ç”¨æµ‹è¯•æ•°æ®
        tables = [
            TableInfo(
                table_name="users",
                columns=[
                    ColumnInfo(table_name="users", column_name="user_id", data_type="int"),
                    ColumnInfo(table_name="users", column_name="name", data_type="string"),
                    ColumnInfo(table_name="users", column_name="email", data_type="string")
                ]
            ),
            TableInfo(
                table_name="orders",
                columns=[
                    ColumnInfo(table_name="orders", column_name="order_id", data_type="int"),
                    ColumnInfo(table_name="orders", column_name="user_id", data_type="int"),
                    ColumnInfo(table_name="orders", column_name="product_id", data_type="int")
                ]
            ),
            TableInfo(
                table_name="products",
                columns=[
                    ColumnInfo(table_name="products", column_name="product_id", data_type="int"),
                    ColumnInfo(table_name="products", column_name="name", data_type="string"),
                    ColumnInfo(table_name="products", column_name="price", data_type="float")
                ]
            )
        ]
    
    # åˆ›å»ºåè°ƒå™¨
    orchestrator = EnhancedMultiAgentOrchestrator()
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    print(f"\nğŸ“¦ åˆå§‹åŒ–å¤šAgentç³»ç»Ÿ ({len(tables)}ä¸ªè¡¨)...")
    start = time.time()
    await orchestrator.initialize(tables)
    print(f"âœ… åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {time.time()-start:.2f}ç§’")
    
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    status = orchestrator.get_detailed_status()
    print(f"\nğŸ“Š ç³»ç»ŸçŠ¶æ€:")
    print(f"  Agents: {status['system']['agents']}")
    print(f"  ä¸‰å±‚åŠ é€Ÿ:")
    print(f"    - Layer 1 (Metadata): {'âœ…' if status['acceleration']['layer1_enabled'] else 'âŒ'}")
    print(f"    - Layer 2 (Vector): {'âœ…' if status['acceleration']['layer2_enabled'] else 'âŒ'}")
    print(f"    - Layer 3 (LLM): {'âœ…' if status['acceleration']['layer3_enabled'] else 'âŒ'}")
    
    # æµ‹è¯•æŸ¥è¯¢
    if tables:
        query = f"Find tables that can be joined with {tables[0].table_name}"
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {query}")
        
        start = time.time()
        results = await orchestrator.process_query_with_collaboration(
            query,
            tables[0],
            strategy="auto"
        )
        elapsed = time.time() - start
        
        print(f"\nâœ… æŸ¥è¯¢å®Œæˆ!")
        print(f"  è€—æ—¶: {elapsed:.2f}ç§’")
        print(f"  æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
        
        if results:
            print(f"\nğŸ“Š Top 5 ç»“æœ:")
            for i, result in enumerate(results[:5], 1):
                table_name = result.get('table', result.get('table_name', 'unknown'))
                score = result.get('score', 0)
                method = result.get('method', 'unknown')
                print(f"  {i}. {table_name} (åˆ†æ•°: {score:.2f}, æ–¹æ³•: {method})")
    
    # æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€
    final_status = orchestrator.get_detailed_status()
    print(f"\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
    print(f"  æŸ¥è¯¢å¤„ç†æ•°: {final_status['performance']['queries_processed']}")
    print(f"  å¹³å‡æ—¶é—´: {final_status['performance']['avg_time']:.2f}ç§’")
    
    print("\n" + "="*80)
    print("âœ… å¢å¼ºç‰ˆå¤šAgentç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
    print("="*80)


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_enhanced_multi_agent_system())