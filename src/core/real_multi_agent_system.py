"""
çœŸå®çš„å¤šæ™ºèƒ½ä½“æ•°æ®æ¹–å‘ç°ç³»ç»Ÿ
Real Multi-Agent Data Lake Discovery System with Full Implementation
"""

import asyncio
import json
import time
import numpy as np
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass, field, asdict
from pathlib import Path
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import faiss
from sentence_transformers import SentenceTransformer
import torch

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¯¼å…¥å·¥å…·å±‚
from src.tools.metadata_filter import MetadataFilter
from src.tools.vector_search import get_vector_search_engine
from src.tools.smart_llm_matcher import SmartLLMMatcher
from src.tools.embedding import get_embedding_generator
from src.config.settings import Settings
from src.utils.llm_client import GeminiClient

# ===================== æ•°æ®ç»“æ„å®šä¹‰ =====================

@dataclass
class TableInfo:
    """è¡¨ä¿¡æ¯"""
    table_name: str
    columns: List[Dict[str, Any]]
    row_count: Optional[int] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    embedding: Optional[np.ndarray] = None
    
@dataclass
class QueryTask:
    """æŸ¥è¯¢ä»»åŠ¡"""
    query_id: str
    query_table: str
    task_type: str  # 'join' or 'union'
    ground_truth: List[str]
    timestamp: float = field(default_factory=time.time)
    
@dataclass
class MatchResult:
    """åŒ¹é…ç»“æœ"""
    query_table: str
    matched_table: str
    score: float
    match_type: str
    evidence: Dict[str, Any] = field(default_factory=dict)
    agent_used: str = ""
    time_cost: float = 0.0

@dataclass 
class AgentMessage:
    """Agenté—´é€šä¿¡æ¶ˆæ¯"""
    sender: str
    receiver: str
    message_type: str
    content: Any
    priority: int = 0
    timestamp: float = field(default_factory=time.time)

@dataclass
class SystemMetrics:
    """ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    total_queries: int = 0
    successful_queries: int = 0
    failed_queries: int = 0
    avg_response_time: float = 0.0
    throughput: float = 0.0
    precision: float = 0.0
    recall: float = 0.0
    f1_score: float = 0.0
    hit_at_k: Dict[int, float] = field(default_factory=dict)
    mrr: float = 0.0

# ===================== AgentåŸºç±» =====================

class BaseAgent:
    """AgentåŸºç±»"""
    
    def __init__(self, name: str, llm_client=None):
        self.name = name
        self.llm_client = llm_client
        self.message_queue = asyncio.Queue()
        self.stats = {
            'processed': 0,
            'success': 0,
            'failed': 0,
            'avg_time': 0.0
        }
        
    async def receive_message(self, message: AgentMessage):
        """æ¥æ”¶æ¶ˆæ¯"""
        await self.message_queue.put(message)
        
    async def send_message(self, receiver: str, content: Any, 
                          message_type: str = "data"):
        """å‘é€æ¶ˆæ¯ç»™å…¶ä»–Agent"""
        message = AgentMessage(
            sender=self.name,
            receiver=receiver,
            message_type=message_type,
            content=content
        )
        # è¿™é‡Œéœ€è¦é€šè¿‡åè°ƒå™¨è½¬å‘
        return message
        
    async def process(self, task: Any) -> Any:
        """å¤„ç†ä»»åŠ¡ï¼ˆå­ç±»å®ç°ï¼‰"""
        raise NotImplementedError
        
    def update_stats(self, success: bool, time_cost: float):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats['processed'] += 1
        if success:
            self.stats['success'] += 1
        else:
            self.stats['failed'] += 1
        
        # æ›´æ–°å¹³å‡æ—¶é—´
        n = self.stats['processed']
        self.stats['avg_time'] = (
            (self.stats['avg_time'] * (n - 1) + time_cost) / n
        )

# ===================== å…·ä½“Agentå®ç° =====================

class OptimizerAgent(BaseAgent):
    """ç³»ç»Ÿä¼˜åŒ–Agent - åŠ¨æ€è°ƒæ•´ç³»ç»Ÿé…ç½®"""
    
    def __init__(self, llm_client=None):
        super().__init__("OptimizerAgent", llm_client)
        self.current_config = {
            'batch_size': 32,
            'parallel_workers': 4,
            'cache_enabled': True,
            'llm_temperature': 0.1,
            'vector_top_k': 100,
            'metadata_top_k': 1000
        }
        self.performance_history = []
        
    async def process(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®ç³»ç»Ÿæ€§èƒ½åŠ¨æ€ä¼˜åŒ–é…ç½®"""
        start_time = time.time()
        
        # åˆ†æå½“å‰æ€§èƒ½
        if metrics.get('avg_response_time', 0) > 5.0:
            # å“åº”æ—¶é—´è¿‡é•¿ï¼Œå¢åŠ å¹¶è¡Œåº¦
            self.current_config['parallel_workers'] = min(8, 
                self.current_config['parallel_workers'] + 2)
            self.current_config['batch_size'] = min(64,
                self.current_config['batch_size'] * 2)
                
        if metrics.get('memory_usage', 0) > 0.8:
            # å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œå‡å°æ‰¹æ¬¡
            self.current_config['batch_size'] = max(16,
                self.current_config['batch_size'] // 2)
                
        if metrics.get('accuracy', 1.0) < 0.8:
            # å‡†ç¡®ç‡ä½ï¼Œè°ƒæ•´LLMå‚æ•°
            self.current_config['llm_temperature'] = max(0.0,
                self.current_config['llm_temperature'] - 0.05)
            self.current_config['vector_top_k'] = min(200,
                self.current_config['vector_top_k'] + 20)
        
        self.performance_history.append(metrics)
        
        # å¦‚æœæœ‰è¶³å¤Ÿçš„å†å²æ•°æ®ï¼Œä½¿ç”¨è¶‹åŠ¿åˆ†æ
        if len(self.performance_history) > 10:
            self._analyze_trends()
        
        time_cost = time.time() - start_time
        self.update_stats(True, time_cost)
        
        logger.info(f"OptimizerAgent updated config: {self.current_config}")
        return self.current_config
        
    def _analyze_trends(self):
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        recent = self.performance_history[-5:]
        avg_recent_time = np.mean([m.get('avg_response_time', 0) for m in recent])
        
        older = self.performance_history[-10:-5]
        avg_older_time = np.mean([m.get('avg_response_time', 0) for m in older])
        
        if avg_recent_time > avg_older_time * 1.2:
            # æ€§èƒ½æ¶åŒ–ï¼Œéœ€è¦æ›´æ¿€è¿›çš„ä¼˜åŒ–
            logger.warning("Performance degradation detected, applying aggressive optimization")
            self.current_config['cache_enabled'] = True
            self.current_config['parallel_workers'] = 8


class PlannerAgent(BaseAgent):
    """ç­–ç•¥è§„åˆ’Agent - åˆ†ææŸ¥è¯¢æ„å›¾å¹¶åˆ¶å®šæ‰§è¡Œç­–ç•¥"""
    
    def __init__(self, llm_client=None):
        super().__init__("PlannerAgent", llm_client)
        self.strategies = {
            'join': self._join_strategy,
            'union': self._union_strategy, 
            'complex': self._complex_strategy
        }
        
    async def process(self, query_task: QueryTask) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢å¹¶åˆ¶å®šç­–ç•¥"""
        start_time = time.time()
        
        # åˆ†ææŸ¥è¯¢ç±»å‹
        task_type = query_task.task_type.lower()
        
        # é€‰æ‹©ç­–ç•¥
        if task_type in self.strategies:
            strategy = await self.strategies[task_type](query_task)
        else:
            # å¤æ‚æŸ¥è¯¢ï¼Œä½¿ç”¨LLMåˆ†æ
            strategy = await self._analyze_with_llm(query_task)
        
        # å†³å®šéœ€è¦çš„Agentå’Œæ‰§è¡Œé¡ºåº
        execution_plan = {
            'task_type': task_type,
            'strategy': strategy,
            'required_agents': self._determine_required_agents(strategy),
            'parallel_possible': self._check_parallel_possibility(strategy),
            'estimated_time': self._estimate_execution_time(strategy)
        }
        
        time_cost = time.time() - start_time
        self.update_stats(True, time_cost)
        
        logger.info(f"PlannerAgent created plan for {query_task.query_id}: {execution_plan['strategy']['name']}")
        return execution_plan
        
    async def _join_strategy(self, query_task: QueryTask) -> Dict[str, Any]:
        """JOINç­–ç•¥ - å¯»æ‰¾å¯è¿æ¥çš„è¡¨"""
        return {
            'name': 'bottom_up_join',
            'description': 'Find tables with foreign key relationships',
            'steps': [
                'analyze_key_columns',
                'metadata_filter_by_keys',
                'vector_search_similar_structure',
                'llm_verify_join_conditions'
            ],
            'focus': 'foreign_keys_and_references'
        }
        
    async def _union_strategy(self, query_task: QueryTask) -> Dict[str, Any]:
        """UNIONç­–ç•¥ - å¯»æ‰¾ç»“æ„ç›¸ä¼¼çš„è¡¨"""
        return {
            'name': 'top_down_union',
            'description': 'Find tables with similar schema',
            'steps': [
                'analyze_table_structure',
                'vector_search_by_schema',
                'metadata_filter_by_types',
                'llm_verify_compatibility'
            ],
            'focus': 'schema_similarity'
        }
        
    async def _complex_strategy(self, query_task: QueryTask) -> Dict[str, Any]:
        """å¤æ‚ç­–ç•¥ - æ··åˆæ–¹æ³•"""
        return {
            'name': 'hybrid_complex',
            'description': 'Multi-dimensional analysis',
            'steps': [
                'deep_table_analysis',
                'parallel_search_all_methods',
                'intelligent_matching',
                'comprehensive_verification'
            ],
            'focus': 'comprehensive'
        }
        
    async def _analyze_with_llm(self, query_task: QueryTask) -> Dict[str, Any]:
        """ä½¿ç”¨LLMåˆ†æå¤æ‚æŸ¥è¯¢"""
        if self.llm_client:
            prompt = f"""
            Analyze this data discovery task:
            Query Table: {query_task.query_table}
            Task Type: {query_task.task_type}
            
            Suggest the best strategy and required steps.
            """
            # å®é™…LLMè°ƒç”¨
            response = await self.llm_client.generate(prompt)
            # è§£æå“åº”å¹¶è¿”å›ç­–ç•¥
        
        return await self._complex_strategy(query_task)
        
    def _determine_required_agents(self, strategy: Dict[str, Any]) -> List[str]:
        """ç¡®å®šéœ€è¦çš„Agent"""
        agents = ['AnalyzerAgent', 'SearcherAgent']
        
        if 'llm' in str(strategy.get('steps', [])).lower():
            agents.append('MatcherAgent')
        
        agents.append('AggregatorAgent')
        return agents
        
    def _check_parallel_possibility(self, strategy: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å¹¶è¡Œæ‰§è¡Œ"""
        parallel_steps = ['parallel_search', 'batch_processing']
        return any(step in str(strategy.get('steps', [])) for step in parallel_steps)
        
    def _estimate_execution_time(self, strategy: Dict[str, Any]) -> float:
        """ä¼°ç®—æ‰§è¡Œæ—¶é—´"""
        base_time = 0.5
        if 'llm' in str(strategy).lower():
            base_time += 2.0
        if 'vector_search' in str(strategy).lower():
            base_time += 0.5
        return base_time


class AnalyzerAgent(BaseAgent):
    """æ•°æ®åˆ†æAgent - æ·±åº¦ç†è§£è¡¨ç»“æ„"""
    
    def __init__(self, metadata_filter: MetadataFilter, llm_client=None):
        super().__init__("AnalyzerAgent", llm_client)
        self.metadata_filter = metadata_filter
        
    async def process(self, table_info: TableInfo) -> Dict[str, Any]:
        """åˆ†æè¡¨ç»“æ„å’Œç‰¹å¾"""
        start_time = time.time()
        
        analysis = {
            'table_name': table_info.table_name,
            'column_count': len(table_info.columns),
            'column_types': {},
            'key_columns': [],
            'patterns': [],
            'table_type': 'unknown'
        }
        
        # åˆ†æåˆ—ç±»å‹åˆ†å¸ƒ
        for col in table_info.columns:
            col_type = col.get('type', 'unknown')
            analysis['column_types'][col_type] = analysis['column_types'].get(col_type, 0) + 1
            
            # è¯†åˆ«å…³é”®åˆ—
            col_name = col.get('name', '').lower()
            if any(key in col_name for key in ['_id', '_key', '_code', '_fk']):
                analysis['key_columns'].append(col['name'])
                
        # è¯†åˆ«è¡¨ç±»å‹
        table_name = table_info.table_name.lower()
        if any(dim in table_name for dim in ['dim_', 'd_', 'dimension']):
            analysis['table_type'] = 'dimension'
            analysis['patterns'].append('dimension_table')
        elif any(fact in table_name for fact in ['fact_', 'f_', 'agg_']):
            analysis['table_type'] = 'fact'
            analysis['patterns'].append('fact_table')
        elif any(lookup in table_name for lookup in ['lookup', 'ref_', 'code_']):
            analysis['table_type'] = 'lookup'
            analysis['patterns'].append('lookup_table')
            
        # å¤æ‚è¡¨ä½¿ç”¨LLMæ·±åº¦åˆ†æ
        if len(table_info.columns) > 20 and self.llm_client:
            deep_analysis = await self._deep_llm_analysis(table_info)
            analysis['deep_insights'] = deep_analysis
            
        time_cost = time.time() - start_time
        self.update_stats(True, time_cost)
        
        logger.debug(f"AnalyzerAgent analyzed {table_info.table_name}: {analysis['table_type']}")
        return analysis
        
    async def _deep_llm_analysis(self, table_info: TableInfo) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æ"""
        if not self.llm_client:
            return {}
            
        prompt = f"""
        Analyze this table structure:
        Table: {table_info.table_name}
        Columns: {[col['name'] for col in table_info.columns[:20]]}
        
        Identify:
        1. Business domain
        2. Key relationships
        3. Data patterns
        """
        
        try:
            response = await self.llm_client.generate(prompt)
            return {'llm_insights': response}
        except Exception as e:
            logger.error(f"LLM analysis failed: {e}")
            return {}


class SearcherAgent(BaseAgent):
    """å€™é€‰æœç´¢Agent - é«˜æ•ˆæŸ¥æ‰¾å€™é€‰è¡¨"""
    
    def __init__(self, metadata_filter: MetadataFilter, 
                 vector_search, llm_client=None):
        super().__init__("SearcherAgent", llm_client)
        self.metadata_filter = metadata_filter
        self.vector_search = vector_search
        
    async def process(self, search_request: Dict[str, Any]) -> List[Tuple[str, float]]:
        """æ‰§è¡Œå¤šå±‚æœç´¢"""
        start_time = time.time()
        
        query_table = search_request['query_table']
        strategy = search_request.get('strategy', {})
        analysis = search_request.get('analysis', {})
        
        candidates = []
        
        # Layer 1: å…ƒæ•°æ®ç­›é€‰
        if 'metadata' in strategy.get('name', '').lower() or True:
            metadata_candidates = await self._metadata_search(
                query_table, analysis
            )
            candidates.extend(metadata_candidates)
            logger.info(f"Metadata filter found {len(metadata_candidates)} candidates")
            
        # Layer 2: å‘é‡æœç´¢
        if 'vector' in strategy.get('name', '').lower() or True:
            vector_candidates = await self._vector_search(
                query_table, 
                top_k=search_request.get('top_k', 100)
            )
            candidates.extend(vector_candidates)
            logger.info(f"Vector search found {len(vector_candidates)} candidates")
            
        # åˆå¹¶å’Œå»é‡
        unique_candidates = self._merge_candidates(candidates)
        
        # æ ¹æ®ç­–ç•¥æ’åº
        sorted_candidates = self._rank_candidates(
            unique_candidates, strategy
        )
        
        time_cost = time.time() - start_time
        self.update_stats(True, time_cost)
        
        logger.info(f"SearcherAgent found {len(sorted_candidates)} unique candidates")
        return sorted_candidates[:search_request.get('max_candidates', 100)]
        
    async def _metadata_search(self, query_table: TableInfo, 
                              analysis: Dict[str, Any]) -> List[Tuple[str, float]]:
        """å…ƒæ•°æ®æœç´¢"""
        try:
            # ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤å™¨
            results = self.metadata_filter.filter_tables(
                query_table,
                column_count_threshold=2,
                type_match_weight=0.4,
                name_similarity_weight=0.3
            )
            return [(r['table_name'], r['score']) for r in results[:1000]]
        except Exception as e:
            logger.error(f"Metadata search failed: {e}")
            return []
            
    async def _vector_search(self, query_table: TableInfo, 
                            top_k: int = 100) -> List[Tuple[str, float]]:
        """å‘é‡æœç´¢"""
        try:
            # ç¡®ä¿è¡¨æœ‰åµŒå…¥å‘é‡
            if query_table.embedding is None:
                # ç”ŸæˆåµŒå…¥
                embedding_gen = get_embedding_generator()
                query_table.embedding = embedding_gen.generate_table_embedding(query_table)
                
            # æ‰§è¡Œå‘é‡æœç´¢
            results = self.vector_search.search(
                query_table.embedding,
                top_k=top_k
            )
            return [(r['table_name'], r['score']) for r in results]
        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            return []
            
    def _merge_candidates(self, candidates: List[Tuple[str, float]]) -> List[Tuple[str, float]]:
        """åˆå¹¶å’Œå»é‡å€™é€‰"""
        candidate_dict = {}
        for table_name, score in candidates:
            if table_name in candidate_dict:
                # å–æœ€é«˜åˆ†
                candidate_dict[table_name] = max(candidate_dict[table_name], score)
            else:
                candidate_dict[table_name] = score
        
        return list(candidate_dict.items())
        
    def _rank_candidates(self, candidates: List[Tuple[str, float]], 
                        strategy: Dict[str, Any]) -> List[Tuple[str, float]]:
        """æ ¹æ®ç­–ç•¥å¯¹å€™é€‰æ’åº"""
        # ç®€å•æŒ‰åˆ†æ•°æ’åº
        return sorted(candidates, key=lambda x: x[1], reverse=True)


class MatcherAgent(BaseAgent):
    """ç²¾ç¡®åŒ¹é…Agent - éªŒè¯å€™é€‰åŒ¹é…"""
    
    def __init__(self, llm_matcher: SmartLLMMatcher, llm_client=None):
        super().__init__("MatcherAgent", llm_client)
        self.llm_matcher = llm_matcher
        
    async def process(self, match_request: Dict[str, Any]) -> List[MatchResult]:
        """ç²¾ç¡®åŒ¹é…éªŒè¯"""
        start_time = time.time()
        
        query_table = match_request['query_table']
        candidates = match_request['candidates']
        task_type = match_request.get('task_type', 'join')
        
        matches = []
        
        # æ‰¹é‡å¤„ç†ç­–ç•¥
        batch_size = match_request.get('batch_size', 10)
        
        for i in range(0, len(candidates), batch_size):
            batch = candidates[i:i+batch_size]
            
            # å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
            batch_results = await self._process_batch(
                query_table, batch, task_type
            )
            matches.extend(batch_results)
            
        # è¿‡æ»¤é«˜åˆ†åŒ¹é…
        high_quality_matches = [
            m for m in matches if m.score > 0.7
        ]
        
        time_cost = time.time() - start_time
        self.update_stats(len(high_quality_matches) > 0, time_cost)
        
        logger.info(f"MatcherAgent verified {len(high_quality_matches)}/{len(candidates)} matches")
        return high_quality_matches
        
    async def _process_batch(self, query_table: TableInfo, 
                            candidates: List[Tuple[str, float]], 
                            task_type: str) -> List[MatchResult]:
        """æ‰¹é‡å¤„ç†å€™é€‰"""
        results = []
        
        # ä½¿ç”¨æ™ºèƒ½LLMåŒ¹é…å™¨
        for candidate_name, candidate_score in candidates:
            # è¿™é‡Œåº”è¯¥è·å–å®Œæ•´çš„candidateè¡¨ä¿¡æ¯
            # ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä»æ•°æ®åº“åŠ è½½
            candidate_table = TableInfo(
                table_name=candidate_name,
                columns=[]  # éœ€è¦å®é™…æ•°æ®
            )
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦LLMéªŒè¯
            if self._needs_llm_verification(query_table, candidate_table, candidate_score):
                match_result = await self._llm_verify(
                    query_table, candidate_table, task_type
                )
            else:
                # è§„åˆ™éªŒè¯
                match_result = self._rule_verify(
                    query_table, candidate_table, task_type, candidate_score
                )
                
            if match_result:
                results.append(match_result)
                
        return results
        
    def _needs_llm_verification(self, query_table: TableInfo, 
                               candidate_table: TableInfo, 
                               score: float) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦LLMéªŒè¯"""
        # é«˜åˆ†ç›´æ¥é€šè¿‡
        if score > 0.95:
            return False
        # ä½åˆ†éœ€è¦éªŒè¯
        if score < 0.5:
            return False
        # ä¸­ç­‰åˆ†æ•°éœ€è¦LLMéªŒè¯
        return True
        
    async def _llm_verify(self, query_table: TableInfo, 
                         candidate_table: TableInfo, 
                         task_type: str) -> Optional[MatchResult]:
        """LLMéªŒè¯"""
        try:
            result = await self.llm_matcher.match_tables(
                query_table, [candidate_table], task_type
            )
            if result and len(result) > 0:
                return MatchResult(
                    query_table=query_table.table_name,
                    matched_table=candidate_table.table_name,
                    score=result[0].get('score', 0.0),
                    match_type=task_type,
                    evidence=result[0].get('evidence', {}),
                    agent_used='MatcherAgent_LLM'
                )
        except Exception as e:
            logger.error(f"LLM verification failed: {e}")
            
        return None
        
    def _rule_verify(self, query_table: TableInfo, 
                    candidate_table: TableInfo, 
                    task_type: str, 
                    score: float) -> MatchResult:
        """è§„åˆ™éªŒè¯"""
        return MatchResult(
            query_table=query_table.table_name,
            matched_table=candidate_table.table_name,
            score=score,
            match_type=task_type,
            evidence={'method': 'rule_based'},
            agent_used='MatcherAgent_Rule'
        )


class AggregatorAgent(BaseAgent):
    """ç»“æœèšåˆAgent - æ•´åˆå’Œæ’åºç»“æœ"""
    
    def __init__(self, llm_client=None):
        super().__init__("AggregatorAgent", llm_client)
        
    async def process(self, aggregation_request: Dict[str, Any]) -> List[MatchResult]:
        """èšåˆå’Œæ’åºç»“æœ"""
        start_time = time.time()
        
        all_matches = aggregation_request.get('matches', [])
        top_k = aggregation_request.get('top_k', 10)
        
        # å»é‡
        unique_matches = self._deduplicate(all_matches)
        
        # æ’åºç­–ç•¥
        if len(unique_matches) > 100:
            # ç®€å•æ’åº
            sorted_matches = sorted(
                unique_matches, 
                key=lambda x: x.score, 
                reverse=True
            )
        elif len(unique_matches) > 20:
            # æ··åˆæ’åº
            sorted_matches = self._hybrid_sort(unique_matches)
        else:
            # å¤æ‚æ’åºï¼ˆå¯èƒ½ä½¿ç”¨LLMé‡æ’ï¼‰
            sorted_matches = await self._complex_sort(unique_matches)
            
        # æ·»åŠ æ’åå’Œè§£é‡Š
        final_results = []
        for i, match in enumerate(sorted_matches[:top_k]):
            match.evidence['rank'] = i + 1
            match.evidence['explanation'] = self._generate_explanation(match)
            final_results.append(match)
            
        time_cost = time.time() - start_time
        self.update_stats(True, time_cost)
        
        logger.info(f"AggregatorAgent produced {len(final_results)} final results")
        return final_results
        
    def _deduplicate(self, matches: List[MatchResult]) -> List[MatchResult]:
        """å»é‡"""
        seen = set()
        unique = []
        for match in matches:
            key = (match.query_table, match.matched_table)
            if key not in seen:
                seen.add(key)
                unique.append(match)
            else:
                # ä¿ç•™åˆ†æ•°æ›´é«˜çš„
                for i, existing in enumerate(unique):
                    if (existing.query_table, existing.matched_table) == key:
                        if match.score > existing.score:
                            unique[i] = match
                        break
        return unique
        
    def _hybrid_sort(self, matches: List[MatchResult]) -> List[MatchResult]:
        """æ··åˆæ’åº"""
        # ç»¼åˆè€ƒè™‘åˆ†æ•°å’Œå…¶ä»–å› ç´ 
        def sort_key(match):
            score = match.score
            # å¦‚æœæœ‰LLMéªŒè¯ï¼ŒåŠ æƒ
            if 'LLM' in match.agent_used:
                score *= 1.1
            return score
            
        return sorted(matches, key=sort_key, reverse=True)
        
    async def _complex_sort(self, matches: List[MatchResult]) -> List[MatchResult]:
        """å¤æ‚æ’åºï¼Œå¯èƒ½ä½¿ç”¨LLM"""
        # å…ˆæŒ‰åˆ†æ•°æ’åº
        sorted_matches = sorted(matches, key=lambda x: x.score, reverse=True)
        
        # å¦‚æœæœ‰LLMå®¢æˆ·ç«¯ï¼Œå¯ä»¥é‡æ’topç»“æœ
        if self.llm_client and len(sorted_matches) > 5:
            # è¿™é‡Œå¯ä»¥å®ç°LLMé‡æ’é€»è¾‘
            pass
            
        return sorted_matches
        
    def _generate_explanation(self, match: MatchResult) -> str:
        """ç”ŸæˆåŒ¹é…è§£é‡Š"""
        explanation = f"Table '{match.matched_table}' matches with score {match.score:.3f}"
        
        if match.evidence.get('method') == 'rule_based':
            explanation += " (rule-based verification)"
        elif 'LLM' in match.agent_used:
            explanation += " (LLM-verified)"
            
        return explanation


# ===================== åè°ƒå™¨ =====================

class MultiAgentOrchestrator:
    """å¤šAgentç³»ç»Ÿåè°ƒå™¨"""
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–åè°ƒå™¨"""
        # åŠ è½½é…ç½®
        import yaml
        if config_path and Path(config_path).exists():
            with open(config_path, 'r') as f:
                config_data = yaml.safe_load(f)
            self.settings = Settings(**config_data)
        else:
            self.settings = Settings()
        
        # åˆ›å»ºLLMå®¢æˆ·ç«¯é…ç½®
        llm_config = {
            "model_name": self.settings.llm.model_name,
            "temperature": self.settings.llm.temperature,
            "max_tokens": self.settings.llm.max_tokens
        }
        self.llm_client = GeminiClient(llm_config)
        
        # åˆå§‹åŒ–å·¥å…·å±‚
        self.metadata_filter = MetadataFilter()
        self.vector_search = get_vector_search_engine()
        self.embedding_gen = get_embedding_generator()
        self.llm_matcher = SmartLLMMatcher(self.llm_client)
        
        # åˆå§‹åŒ–Agents
        self.agents = {
            'optimizer': OptimizerAgent(self.llm_client),
            'planner': PlannerAgent(self.llm_client),
            'analyzer': AnalyzerAgent(self.metadata_filter, self.llm_client),
            'searcher': SearcherAgent(
                self.metadata_filter, 
                self.vector_search, 
                self.llm_client
            ),
            'matcher': MatcherAgent(self.llm_matcher, self.llm_client),
            'aggregator': AggregatorAgent(self.llm_client)
        }
        
        # æ¶ˆæ¯æ€»çº¿
        self.message_bus = asyncio.Queue()
        
        # ç³»ç»ŸæŒ‡æ ‡
        self.system_metrics = SystemMetrics()
        
        # æ•°æ®ç¼“å­˜
        self.table_cache = {}
        self.embedding_cache = {}
        
        logger.info("MultiAgentOrchestrator initialized successfully")
        
    async def load_data(self, tables_path: str):
        """åŠ è½½æ•°æ®é›†"""
        logger.info(f"Loading data from {tables_path}")
        
        with open(tables_path, 'r') as f:
            tables_data = json.load(f)
            
        # è½¬æ¢ä¸ºTableInfoå¯¹è±¡
        for table_data in tables_data:
            table_info = TableInfo(
                table_name=table_data['table_name'],
                columns=table_data['columns'],
                row_count=table_data.get('row_count'),
                metadata=table_data.get('metadata', {})
            )
            self.table_cache[table_info.table_name] = table_info
            
        logger.info(f"Loaded {len(self.table_cache)} tables")
        
        # é¢„è®¡ç®—åµŒå…¥ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
        await self._precompute_embeddings()
        
    async def _precompute_embeddings(self):
        """é¢„è®¡ç®—æ‰€æœ‰è¡¨çš„åµŒå…¥å‘é‡"""
        logger.info("Precomputing embeddings...")
        
        # æ‰¹é‡å¹¶è¡Œç”ŸæˆåµŒå…¥
        batch_size = 100
        tables = list(self.table_cache.values())
        
        for i in range(0, len(tables), batch_size):
            batch = tables[i:i+batch_size]
            
            # å¹¶è¡Œç”Ÿæˆ
            tasks = []
            for table in batch:
                if table.table_name not in self.embedding_cache:
                    tasks.append(self._generate_embedding(table))
                    
            if tasks:
                embeddings = await asyncio.gather(*tasks)
                for table, embedding in zip(batch, embeddings):
                    if embedding is not None:
                        self.embedding_cache[table.table_name] = embedding
                        table.embedding = embedding
                        
        # æ„å»ºå‘é‡ç´¢å¼•
        await self._build_vector_index()
        
        logger.info(f"Computed {len(self.embedding_cache)} embeddings")
        
    async def _generate_embedding(self, table: TableInfo) -> Optional[np.ndarray]:
        """ç”Ÿæˆè¡¨åµŒå…¥"""
        try:
            return self.embedding_gen.generate_table_embedding(table)
        except Exception as e:
            logger.error(f"Failed to generate embedding for {table.table_name}: {e}")
            return None
            
    async def _build_vector_index(self):
        """æ„å»ºå‘é‡ç´¢å¼•"""
        logger.info("Building vector index...")
        
        # æ”¶é›†æ‰€æœ‰åµŒå…¥
        embeddings = []
        table_names = []
        
        for table_name, embedding in self.embedding_cache.items():
            if embedding is not None:
                embeddings.append(embedding)
                table_names.append(table_name)
                
        if embeddings:
            # æ„å»ºFAISSç´¢å¼•
            embeddings_array = np.array(embeddings).astype('float32')
            
            # ç¡®ä¿å‘é‡æœç´¢å¼•æ“å·²åˆå§‹åŒ–ç´¢å¼•
            if hasattr(self.vector_search, 'build_index'):
                self.vector_search.build_index(embeddings_array, table_names)
            
        logger.info(f"Built vector index with {len(embeddings)} vectors")
        
    async def process_query(self, query_task: QueryTask) -> List[MatchResult]:
        """å¤„ç†å•ä¸ªæŸ¥è¯¢ä»»åŠ¡"""
        start_time = time.time()
        
        try:
            # è·å–æŸ¥è¯¢è¡¨ä¿¡æ¯
            query_table = self.table_cache.get(query_task.query_table)
            if not query_table:
                logger.error(f"Query table {query_task.query_table} not found")
                return []
                
            # 1. ä¼˜åŒ–å™¨é…ç½®
            current_metrics = {
                'avg_response_time': self.system_metrics.avg_response_time,
                'accuracy': self.system_metrics.f1_score,
                'memory_usage': 0.5  # ç®€åŒ–å¤„ç†
            }
            config = await self.agents['optimizer'].process(current_metrics)
            
            # 2. è§„åˆ’å™¨åˆ¶å®šç­–ç•¥
            execution_plan = await self.agents['planner'].process(query_task)
            
            # 3. åˆ†æå™¨ç†è§£æ•°æ®
            analysis = await self.agents['analyzer'].process(query_table)
            
            # 4. æœç´¢å™¨æŸ¥æ‰¾å€™é€‰
            search_request = {
                'query_table': query_table,
                'strategy': execution_plan['strategy'],
                'analysis': analysis,
                'top_k': config.get('vector_top_k', 100),
                'max_candidates': config.get('metadata_top_k', 1000)
            }
            candidates = await self.agents['searcher'].process(search_request)
            
            # 5. åŒ¹é…å™¨éªŒè¯
            match_request = {
                'query_table': query_table,
                'candidates': candidates,
                'task_type': query_task.task_type,
                'batch_size': config.get('batch_size', 32)
            }
            matches = await self.agents['matcher'].process(match_request)
            
            # 6. èšåˆå™¨æ•´åˆç»“æœ
            aggregation_request = {
                'matches': matches,
                'top_k': 10
            }
            final_results = await self.agents['aggregator'].process(aggregation_request)
            
            # æ›´æ–°ç³»ç»ŸæŒ‡æ ‡
            query_time = time.time() - start_time
            self._update_metrics(query_task, final_results, query_time)
            
            logger.info(f"Processed query {query_task.query_id} in {query_time:.2f}s")
            return final_results
            
        except Exception as e:
            logger.error(f"Error processing query {query_task.query_id}: {e}")
            self.system_metrics.failed_queries += 1
            return []
            
    async def process_batch(self, query_tasks: List[QueryTask], 
                          parallel_workers: int = 4) -> Dict[str, List[MatchResult]]:
        """æ‰¹é‡å¤„ç†æŸ¥è¯¢ï¼ˆå¹¶è¡Œï¼‰"""
        logger.info(f"Processing batch of {len(query_tasks)} queries with {parallel_workers} workers")
        
        results = {}
        
        # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
        task_queue = asyncio.Queue()
        for task in query_tasks:
            await task_queue.put(task)
            
        # åˆ›å»ºå·¥ä½œåç¨‹
        async def worker():
            while not task_queue.empty():
                try:
                    task = await task_queue.get()
                    task_results = await self.process_query(task)
                    results[task.query_id] = task_results
                except Exception as e:
                    logger.error(f"Worker error: {e}")
                    
        # å¹¶è¡Œæ‰§è¡Œ
        workers = [worker() for _ in range(parallel_workers)]
        await asyncio.gather(*workers)
        
        return results
        
    def _update_metrics(self, query_task: QueryTask, 
                       results: List[MatchResult], 
                       query_time: float):
        """æ›´æ–°ç³»ç»ŸæŒ‡æ ‡"""
        self.system_metrics.total_queries += 1
        
        if results:
            self.system_metrics.successful_queries += 1
        else:
            self.system_metrics.failed_queries += 1
            
        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        n = self.system_metrics.total_queries
        self.system_metrics.avg_response_time = (
            (self.system_metrics.avg_response_time * (n - 1) + query_time) / n
        )
        
        # è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡
        if query_task.ground_truth:
            predicted = [r.matched_table for r in results]
            self._calculate_precision_recall(predicted, query_task.ground_truth)
            self._calculate_hit_at_k(predicted, query_task.ground_truth)
            self._calculate_mrr(predicted, query_task.ground_truth)
            
    def _calculate_precision_recall(self, predicted: List[str], 
                                   ground_truth: List[str]):
        """è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡"""
        if not predicted:
            return
            
        true_positives = len(set(predicted) & set(ground_truth))
        
        if predicted:
            precision = true_positives / len(predicted)
        else:
            precision = 0.0
            
        if ground_truth:
            recall = true_positives / len(ground_truth)
        else:
            recall = 0.0
            
        # æ›´æ–°ç³»ç»ŸæŒ‡æ ‡ï¼ˆç§»åŠ¨å¹³å‡ï¼‰
        n = self.system_metrics.successful_queries
        if n > 0:
            self.system_metrics.precision = (
                (self.system_metrics.precision * (n - 1) + precision) / n
            )
            self.system_metrics.recall = (
                (self.system_metrics.recall * (n - 1) + recall) / n
            )
            
            # F1åˆ†æ•°
            if self.system_metrics.precision + self.system_metrics.recall > 0:
                self.system_metrics.f1_score = (
                    2 * self.system_metrics.precision * self.system_metrics.recall /
                    (self.system_metrics.precision + self.system_metrics.recall)
                )
                
    def _calculate_hit_at_k(self, predicted: List[str], 
                           ground_truth: List[str]):
        """è®¡ç®—Hit@K"""
        for k in [1, 3, 5, 10]:
            if len(predicted) >= k:
                hit = 1 if any(p in ground_truth for p in predicted[:k]) else 0
                
                # æ›´æ–°ç§»åŠ¨å¹³å‡
                n = self.system_metrics.successful_queries
                if n > 0:
                    current = self.system_metrics.hit_at_k.get(k, 0.0)
                    self.system_metrics.hit_at_k[k] = (
                        (current * (n - 1) + hit) / n
                    )
                    
    def _calculate_mrr(self, predicted: List[str], ground_truth: List[str]):
        """è®¡ç®—MRR (Mean Reciprocal Rank)"""
        rr = 0.0
        for i, p in enumerate(predicted):
            if p in ground_truth:
                rr = 1.0 / (i + 1)
                break
                
        # æ›´æ–°ç§»åŠ¨å¹³å‡
        n = self.system_metrics.successful_queries
        if n > 0:
            self.system_metrics.mrr = (
                (self.system_metrics.mrr * (n - 1) + rr) / n
            )
            
    def get_metrics(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸæŒ‡æ ‡"""
        return asdict(self.system_metrics)
        
    def get_agent_stats(self) -> Dict[str, Dict[str, Any]]:
        """è·å–å„Agentç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        for name, agent in self.agents.items():
            stats[name] = agent.stats
        return stats


# ===================== ä¸»å‡½æ•° =====================

async def main():
    """ä¸»å‡½æ•° - è¿è¡Œå®Œæ•´çš„å¤šAgentç³»ç»Ÿæµ‹è¯•"""
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºåè°ƒå™¨
    orchestrator = MultiAgentOrchestrator('config_optimized.yml')
    
    # åŠ è½½å®Œæ•´æ•°æ®é›†
    await orchestrator.load_data('examples/final_complete_tables.json')
    
    # åŠ è½½ground truth
    with open('examples/final_complete_ground_truth.json', 'r') as f:
        ground_truth_data = json.load(f)
        
    # é€‰æ‹©100ä¸ªæŸ¥è¯¢è¿›è¡Œæµ‹è¯•ï¼ˆ50 JOIN + 50 UNIONï¼‰
    query_tasks = []
    
    # JOINæŸ¥è¯¢
    join_queries = [gt for gt in ground_truth_data if gt['type'] == 'join'][:50]
    for i, gt in enumerate(join_queries):
        task = QueryTask(
            query_id=f"join_{i}",
            query_table=gt['query_table'],
            task_type='join',
            ground_truth=gt['ground_truth']
        )
        query_tasks.append(task)
        
    # UNIONæŸ¥è¯¢
    union_queries = [gt for gt in ground_truth_data if gt['type'] == 'union'][:50]
    for i, gt in enumerate(union_queries):
        task = QueryTask(
            query_id=f"union_{i}",
            query_table=gt['query_table'],
            task_type='union',
            ground_truth=gt['ground_truth']
        )
        query_tasks.append(task)
        
    logger.info(f"Created {len(query_tasks)} query tasks")
    
    # æ‰¹é‡å¤„ç†ï¼ˆå¹¶è¡Œï¼‰
    start_time = time.time()
    results = await orchestrator.process_batch(query_tasks, parallel_workers=4)
    total_time = time.time() - start_time
    
    # è·å–ç³»ç»ŸæŒ‡æ ‡
    metrics = orchestrator.get_metrics()
    agent_stats = orchestrator.get_agent_stats()
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    print("MULTI-AGENT SYSTEM EVALUATION RESULTS")
    print("="*60)
    
    print(f"\nğŸ“Š Overall Performance:")
    print(f"  Total Queries: {metrics['total_queries']}")
    print(f"  Successful: {metrics['successful_queries']}")
    print(f"  Failed: {metrics['failed_queries']}")
    print(f"  Total Time: {total_time:.2f}s")
    print(f"  Avg Response Time: {metrics['avg_response_time']:.3f}s")
    print(f"  Throughput: {metrics['total_queries']/total_time:.2f} QPS")
    
    print(f"\nğŸ¯ Accuracy Metrics:")
    print(f"  Precision: {metrics['precision']:.3f}")
    print(f"  Recall: {metrics['recall']:.3f}")
    print(f"  F1-Score: {metrics['f1_score']:.3f}")
    print(f"  MRR: {metrics['mrr']:.3f}")
    
    print(f"\nğŸ“ˆ Hit@K Metrics:")
    for k, hit_rate in sorted(metrics['hit_at_k'].items()):
        print(f"  Hit@{k}: {hit_rate:.3f}")
        
    print(f"\nğŸ¤– Agent Performance:")
    for agent_name, stats in agent_stats.items():
        print(f"  {agent_name}:")
        print(f"    Processed: {stats['processed']}")
        print(f"    Success: {stats['success']}")
        print(f"    Avg Time: {stats['avg_time']:.3f}s")
        
    # ä¿å­˜ç»“æœ
    output_file = f"experiment_results/multi_agent_test_{int(time.time())}.json"
    with open(output_file, 'w') as f:
        json.dump({
            'metrics': metrics,
            'agent_stats': agent_stats,
            'total_time': total_time,
            'query_count': len(query_tasks),
            'results_sample': {
                k: [asdict(r) for r in v[:3]] 
                for k, v in list(results.items())[:5]
            }
        }, f, indent=2, default=str)
        
    print(f"\nğŸ’¾ Results saved to: {output_file}")
    

if __name__ == "__main__":
    asyncio.run(main())