"""
VectorSearchTool - Wrapper for Layer 2 vector similarity search
"""
import time
import asyncio
from typing import List, Dict, Any, Tuple
import logging
import numpy as np
from src.tools.vector_search import FAISSVectorSearch
from src.core.models import TableInfo, ColumnInfo
from src.tools.embedding import get_embedding_generator


class VectorSearchTool:
    """
    Wrapper for vector search to work with new agent architecture
    """
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.vector_engine = FAISSVectorSearch(dimension=384)  # Match all-MiniLM-L6-v2 embedding dimension
        self.embedding_model = get_embedding_generator()
        self._initialized = False
        self._precomputed_index = None
        self._precomputed_embeddings = None
        self._table_names_list = []  # ä¿å­˜è¡¨åé¡ºåº
        
    def initialize(self, tables: List[TableInfo]):
        """Initialize the vector index"""
        if not self._initialized:
            # é¦–å…ˆå°è¯•åŠ è½½é¢„è®¡ç®—çš„ç´¢å¼•
            if self._load_precomputed_index(tables):
                self._initialized = True
                return
            # å¦‚æœæ²¡æœ‰é¢„è®¡ç®—ç´¢å¼•ï¼Œæ„å»ºæ–°çš„
            asyncio.run(self._build_index(tables))
            self._initialized = True
            
    def _load_precomputed_index(self, tables: List[TableInfo]) -> bool:
        """åŠ è½½é¢„è®¡ç®—çš„FAISSç´¢å¼•"""
        import os
        import pickle
        import faiss
        
        index_file = os.getenv('USE_PERSISTENT_INDEX')
        embeddings_file = os.getenv('USE_PRECOMPUTED_EMBEDDINGS')
        
        if index_file and embeddings_file and os.path.exists(index_file) and os.path.exists(embeddings_file):
            try:
                # åŠ è½½é¢„è®¡ç®—çš„FAISSç´¢å¼•
                with open(index_file, 'rb') as f:
                    self._precomputed_index = pickle.load(f)
                with open(embeddings_file, 'rb') as f:
                    self._precomputed_embeddings = pickle.load(f)
                
                # æ„å»ºè¡¨ååˆ—è¡¨ï¼ˆä¿æŒé¡ºåºï¼‰
                self._table_names_list = [t.table_name for t in tables]
                
                self.logger.info(f"âœ… åŠ è½½é¢„è®¡ç®—FAISSç´¢å¼•: {self._precomputed_index.ntotal} ä¸ªå‘é‡")
                return True
            except Exception as e:
                self.logger.warning(f"åŠ è½½é¢„è®¡ç®—ç´¢å¼•å¤±è´¥: {e}")
                return False
        return False
    
    async def _build_index(self, tables: List[TableInfo]):
        """Build vector index for all tables"""
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦æœ‰é¢„è®¡ç®—çš„åµŒå…¥
        import os
        import pickle
        
        precomputed_file = os.getenv('USE_PRECOMPUTED_EMBEDDINGS')
        precomputed_embeddings = {}
        
        if precomputed_file and os.path.exists(precomputed_file):
            try:
                with open(precomputed_file, 'rb') as f:
                    precomputed_embeddings = pickle.load(f)
                self.logger.info(f"ğŸ“¥ åŠ è½½é¢„è®¡ç®—åµŒå…¥: {len(precomputed_embeddings)} ä¸ªå‘é‡")
            except Exception as e:
                self.logger.warning(f"é¢„è®¡ç®—åµŒå…¥åŠ è½½å¤±è´¥: {e}")
        
        for table in tables:
            table_name = table.table_name
            
            # ä¼˜å…ˆä½¿ç”¨é¢„è®¡ç®—çš„åµŒå…¥
            if table_name in precomputed_embeddings:
                embedding = precomputed_embeddings[table_name].tolist()
                self.logger.debug(f"âœ… ä½¿ç”¨é¢„è®¡ç®—åµŒå…¥: {table_name}")
            else:
                # é™çº§åˆ°å®æ—¶è®¡ç®—
                table_text = self._table_to_text(table)
                embedding = await self.embedding_model.generate_text_embedding(table_text)
                self.logger.debug(f"ğŸ”„ å®æ—¶è®¡ç®—åµŒå…¥: {table_name}")
            
            # Add to index
            await self.vector_engine.add_table_vector(table, embedding)
            
        used_precomputed = sum(1 for t in tables if t.table_name in precomputed_embeddings)
        self.logger.info(f"Built vector index for {len(tables)} tables "
                        f"({used_precomputed} é¢„è®¡ç®—, {len(tables)-used_precomputed} å®æ—¶è®¡ç®—)")
        
    def search(self, query_table: Dict[str, Any], 
               all_tables: List[Dict[str, Any]], 
               top_k: int = 50) -> List[Tuple[str, float]]:
        """
        Search for similar tables using vector similarity
        
        Args:
            query_table: The query table dictionary
            all_tables: List of all candidate table dictionaries
            top_k: Number of top results to return
            
        Returns:
            List of (table_name, score) tuples
        """
        start_time = time.time()
        
        # Initialize if needed
        if not self._initialized and all_tables:
            table_infos = [self._dict_to_table_info(t) for t in all_tables]
            self.initialize(table_infos)
        
        # å¦‚æœä½¿ç”¨é¢„è®¡ç®—ç´¢å¼•ï¼Œç›´æ¥æœç´¢
        if self._precomputed_index and self._precomputed_embeddings:
            return self._search_with_precomputed_index(query_table, top_k, start_time)
        
        # Create query embedding
        if isinstance(query_table, dict):
            query_table_info = self._dict_to_table_info(query_table)
        else:
            query_table_info = query_table
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨é¢„è®¡ç®—çš„æŸ¥è¯¢åµŒå…¥
        import os
        import pickle
        
        query_embedding = None
        precomputed_file = os.getenv('USE_PRECOMPUTED_EMBEDDINGS')
        
        if precomputed_file and os.path.exists(precomputed_file):
            try:
                with open(precomputed_file, 'rb') as f:
                    precomputed_embeddings = pickle.load(f)
                query_table_name = query_table_info.table_name
                
                if query_table_name in precomputed_embeddings:
                    query_embedding = precomputed_embeddings[query_table_name].tolist()
                    self.logger.debug(f"âœ… ä½¿ç”¨é¢„è®¡ç®—æŸ¥è¯¢åµŒå…¥: {query_table_name}")
            except Exception as e:
                self.logger.warning(f"æŸ¥è¯¢åµŒå…¥åŠ è½½å¤±è´¥: {e}")
        
        # å¦‚æœæ²¡æœ‰é¢„è®¡ç®—çš„åµŒå…¥ï¼Œåˆ™å®æ—¶è®¡ç®—
        if query_embedding is None:
            query_text = self._table_to_text(query_table_info)
            query_embedding = asyncio.run(
                self.embedding_model.generate_text_embedding(query_text)
            )
            self.logger.debug(f"ğŸ”„ å®æ—¶è®¡ç®—æŸ¥è¯¢åµŒå…¥: {query_table_info.table_name}")
        
        # Search similar tables
        results = asyncio.run(
            self.vector_engine.search_similar_tables(
                query_embedding,
                k=top_k,
                threshold=0.3  # Lower threshold for more candidates
            )
        )
        
        # Convert to expected format
        candidates = []
        for result in results:
            candidates.append((result.item_id, result.score))
        
        # Log performance
        elapsed_ms = (time.time() - start_time) * 1000
        self.logger.debug(f"Vector search completed in {elapsed_ms:.1f}ms")
        if elapsed_ms > 50:
            self.logger.warning(f"Vector search took {elapsed_ms:.1f}ms (target: 10-50ms)")
        
        return candidates
    
    def _search_with_precomputed_index(self, query_table: Dict[str, Any], 
                                      top_k: int, start_time: float) -> List[Tuple[str, float]]:
        """ä½¿ç”¨é¢„è®¡ç®—ç´¢å¼•è¿›è¡Œæœç´¢"""
        import numpy as np
        
        # è·å–æŸ¥è¯¢è¡¨å
        query_table_name = query_table.get('table_name', query_table.get('name', ''))
        
        # è·å–æŸ¥è¯¢å‘é‡
        if query_table_name in self._precomputed_embeddings:
            query_vector = np.array(self._precomputed_embeddings[query_table_name]).astype('float32')
        else:
            # å¦‚æœæ²¡æœ‰é¢„è®¡ç®—çš„æŸ¥è¯¢å‘é‡ï¼Œå®æ—¶è®¡ç®—
            query_text = self._table_to_text_dict(query_table)
            query_vector = np.array(self.embedding_model.generate_text_embedding_sync(query_text)).astype('float32')
        
        # æœç´¢
        query_vector = query_vector.reshape(1, -1)
        distances, indices = self._precomputed_index.search(query_vector, min(top_k, self._precomputed_index.ntotal))
        
        # æ„å»ºç»“æœ
        results = []
        for idx, dist in zip(indices[0], distances[0]):
            if idx < len(self._table_names_list):
                table_name = self._table_names_list[idx]
                # è½¬æ¢è·ç¦»ä¸ºç›¸ä¼¼åº¦åˆ†æ•° (0-1)
                score = 1.0 / (1.0 + dist)  # ç®€å•çš„è·ç¦»åˆ°ç›¸ä¼¼åº¦è½¬æ¢
                results.append((table_name, score))
        
        elapsed = (time.time() - start_time) * 1000
        self.logger.info(f"Vector search with precomputed index took {elapsed:.1f}ms")
        
        return results
    
    def _table_to_text_dict(self, table: Dict[str, Any]) -> str:
        """å°†è¡¨å­—å…¸è½¬æ¢ä¸ºæ–‡æœ¬è¡¨ç¤º"""
        parts = [f"Table: {table.get('table_name', table.get('name', ''))}"]  
        
        for col in table.get('columns', [])[:20]:  # é™åˆ¶å‰20åˆ—
            col_name = col.get('column_name', col.get('name', ''))
            col_type = col.get('data_type', col.get('type', 'unknown'))
            parts.append(f"Column: {col_name} ({col_type})")
            
            samples = col.get('sample_values', [])
            if samples:
                samples_str = ', '.join(str(v) for v in samples[:3])
                parts.append(f"  Samples: {samples_str}")
        
        return '\n'.join(parts)
    
    def _table_to_text(self, table: TableInfo) -> str:
        """Convert table to text representation for embedding"""
        parts = [f"Table: {table.table_name}"]
        
        for col in table.columns[:20]:  # Limit to first 20 columns
            parts.append(f"Column: {col.column_name} ({col.data_type})")
            if col.sample_values:
                samples = ', '.join(str(v) for v in col.sample_values[:3])
                parts.append(f"  Samples: {samples}")
        
        return '\n'.join(parts)
    
    def _dict_to_table_info(self, table_dict: Dict[str, Any]) -> TableInfo:
        """Convert table dictionary to TableInfo object"""
        columns = []
        for col_dict in table_dict.get('columns', []):
            col = ColumnInfo(
                table_name=table_dict.get('table_name', ''),
                column_name=col_dict.get('column_name', col_dict.get('name', '')),
                data_type=col_dict.get('data_type', col_dict.get('type', 'unknown')),
                sample_values=col_dict.get('sample_values', [])
            )
            columns.append(col)
        
        return TableInfo(
            table_name=table_dict.get('table_name', ''),
            columns=columns,
            row_count=table_dict.get('row_count', 0),
            file_path=table_dict.get('file_path', '')
        )