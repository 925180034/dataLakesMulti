#!/usr/bin/env python
"""
ä½¿ç”¨çœŸå®æ•°æ®é›†è¯„ä¼°ä¼˜åŒ–å·¥ä½œæµï¼Œè¾“å‡ºæ ‡å‡†è¯„ä»·æŒ‡æ ‡
"""

import asyncio
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Set, Tuple
from collections import defaultdict

from src.core.workflow import discover_data
from src.core.models import TableInfo
from src.utils.data_parser import parse_tables_data


def load_ground_truth(file_path: str) -> Dict[str, Set[str]]:
    """åŠ è½½ground truthæ•°æ®"""
    with open(file_path) as f:
        ground_truth_data = json.load(f)
    
    # ç»„ç»‡ground truthä¸ºæŸ¥è¯¢è¡¨åˆ°å€™é€‰è¡¨çš„æ˜ å°„
    ground_truth = defaultdict(set)
    for item in ground_truth_data:
        query_table = item['query_table']
        candidate_table = item['candidate_table']
        ground_truth[query_table].add(candidate_table)
    
    return dict(ground_truth)


def load_queries(queries_file: str, tables_file: str) -> List[Dict[str, Any]]:
    """åŠ è½½æŸ¥è¯¢æ•°æ®"""
    with open(queries_file) as f:
        queries_data = json.load(f)
    
    # åŠ è½½æ‰€æœ‰è¡¨æ•°æ®ä»¥è·å–è¡¨ç»“æ„
    with open(tables_file) as f:
        all_tables_data = json.load(f)
    
    # åˆ›å»ºè¡¨ååˆ°è¡¨æ•°æ®çš„æ˜ å°„
    table_map = {table['table_name']: table for table in all_tables_data}
    
    # æå–å”¯ä¸€çš„æŸ¥è¯¢è¡¨
    unique_query_tables = set()
    for query in queries_data:
        unique_query_tables.add(query['query_table'])
    
    # åˆ›å»ºæŸ¥è¯¢åˆ—è¡¨
    queries = []
    for table_name in unique_query_tables:
        if table_name in table_map:
            queries.append({
                'table_name': table_name,
                'table_data': table_map[table_name]
            })
    
    return queries


def calculate_metrics(predictions: Dict[str, Set[str]], ground_truth: Dict[str, Set[str]]) -> Dict[str, float]:
    """è®¡ç®—è¯„ä»·æŒ‡æ ‡ï¼šPrecision, Recall, F1"""
    true_positives = 0
    false_positives = 0
    false_negatives = 0
    
    all_query_tables = set(predictions.keys()) | set(ground_truth.keys())
    
    for query_table in all_query_tables:
        pred_set = predictions.get(query_table, set())
        true_set = ground_truth.get(query_table, set())
        
        # è®¡ç®—äº¤é›†ï¼ˆTrue Positivesï¼‰
        tp = len(pred_set & true_set)
        true_positives += tp
        
        # è®¡ç®—False Positivesï¼ˆé¢„æµ‹äº†ä½†ä¸åœ¨ground truthä¸­ï¼‰
        fp = len(pred_set - true_set)
        false_positives += fp
        
        # è®¡ç®—False Negativesï¼ˆåœ¨ground truthä¸­ä½†æ²¡æœ‰é¢„æµ‹ï¼‰
        fn = len(true_set - pred_set)
        false_negatives += fn
    
    # è®¡ç®—æŒ‡æ ‡
    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    return {
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'true_positives': true_positives,
        'false_positives': false_positives,
        'false_negatives': false_negatives
    }


async def evaluate_workflow(
    queries: List[Dict[str, Any]],
    all_tables_data: List[Dict[str, Any]],
    ground_truth: Dict[str, Set[str]],
    use_optimized: bool = True,
    top_k: int = 10
) -> Dict[str, Any]:
    """è¯„ä¼°å·¥ä½œæµæ€§èƒ½"""
    predictions = defaultdict(set)
    total_time = 0
    query_times = []
    
    print(f"\n{'='*60}")
    print(f"è¯„ä¼° {'ä¼˜åŒ–' if use_optimized else 'åŸºç¡€'} å·¥ä½œæµ")
    print(f"{'='*60}")
    print(f"æŸ¥è¯¢æ•°é‡: {len(queries)}")
    print(f"Top-K: {top_k}")
    
    # å¯¹æ¯ä¸ªæŸ¥è¯¢è¿›è¡Œé¢„æµ‹
    for i, query_info in enumerate(queries):
        table_name = query_info['table_name']
        table_data = query_info['table_data']
        
        print(f"\rå¤„ç†æŸ¥è¯¢ {i+1}/{len(queries)}: {table_name}", end='', flush=True)
        
        start_time = time.time()
        
        try:
            # æ‰§è¡Œæ•°æ®å‘ç°
            result = await discover_data(
                user_query=f"Find joinable tables for {table_name}",
                query_tables=[table_data],
                all_tables_data=all_tables_data if use_optimized and i == 0 else None,  # åªåœ¨ç¬¬ä¸€æ¬¡åˆå§‹åŒ–
                use_optimized=use_optimized
            )
            
            # ç¡®ä¿resultæ˜¯AgentStateå¯¹è±¡
            if isinstance(result, dict):
                from src.core.models import AgentState
                result = AgentState(**result)
            
            # æå–é¢„æµ‹ç»“æœ
            if hasattr(result, 'table_matches') and result.table_matches:
                # æŒ‰åˆ†æ•°æ’åºå¹¶å–top-k
                sorted_matches = sorted(result.table_matches, key=lambda x: x.score, reverse=True)
                for match in sorted_matches[:top_k]:
                    predictions[table_name].add(match.target_table)
            
        except Exception as e:
            print(f"\né”™è¯¯å¤„ç†æŸ¥è¯¢ {table_name}: {e}")
            continue
        
        end_time = time.time()
        query_time = end_time - start_time
        query_times.append(query_time)
        total_time += query_time
    
    print("\n")
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_metrics(predictions, ground_truth)
    
    # è®¡ç®—æ—¶é—´ç»Ÿè®¡
    avg_time = sum(query_times) / len(query_times) if query_times else 0
    
    return {
        'metrics': metrics,
        'timing': {
            'total_time': total_time,
            'average_time': avg_time,
            'query_count': len(queries)
        },
        'predictions': dict(predictions)
    }


async def main():
    """ä¸»è¯„ä¼°å‡½æ•°"""
    print("ğŸš€ æ•°æ®æ¹–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¯„ä¼°")
    print("="*60)
    
    # æ–‡ä»¶è·¯å¾„
    tables_file = Path("examples/final_subset_tables.json")
    queries_file = Path("examples/final_subset_queries.json")
    ground_truth_file = Path("examples/final_subset_ground_truth.json")
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    for file_path in [tables_file, queries_file, ground_truth_file]:
        if not file_path.exists():
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
            return
    
    # åŠ è½½æ•°æ®
    print("ğŸ“Š åŠ è½½æ•°æ®...")
    with open(tables_file) as f:
        all_tables_data = json.load(f)
    
    queries = load_queries(queries_file, tables_file)
    ground_truth = load_ground_truth(ground_truth_file)
    
    print(f"âœ… å·²åŠ è½½:")
    print(f"   - {len(all_tables_data)} ä¸ªè¡¨")
    print(f"   - {len(queries)} ä¸ªæŸ¥è¯¢")
    print(f"   - {len(ground_truth)} ä¸ªground truthæ¡ç›®")
    
    # è¯„ä¼°åŸºç¡€å·¥ä½œæµ
    print("\n" + "="*60)
    print("ğŸ“Š è¯„ä¼°åŸºç¡€å·¥ä½œæµ")
    print("="*60)
    basic_results = await evaluate_workflow(
        queries[:10],  # ä½¿ç”¨å‰10ä¸ªæŸ¥è¯¢è¿›è¡Œæµ‹è¯•
        all_tables_data,
        ground_truth,
        use_optimized=False,
        top_k=10
    )
    
    # è¯„ä¼°ä¼˜åŒ–å·¥ä½œæµ
    print("\n" + "="*60)
    print("ğŸš€ è¯„ä¼°ä¼˜åŒ–å·¥ä½œæµ")
    print("="*60)
    optimized_results = await evaluate_workflow(
        queries[:10],  # ä½¿ç”¨ç›¸åŒçš„æŸ¥è¯¢
        all_tables_data,
        ground_truth,
        use_optimized=True,
        top_k=10
    )
    
    # è¾“å‡ºç»“æœå¯¹æ¯”
    print("\n" + "="*60)
    print("ğŸ“Š è¯„ä¼°ç»“æœå¯¹æ¯”")
    print("="*60)
    
    print("\nåŸºç¡€å·¥ä½œæµ:")
    print(f"  Precision: {basic_results['metrics']['precision']:.3f}")
    print(f"  Recall: {basic_results['metrics']['recall']:.3f}")
    print(f"  F1-Score: {basic_results['metrics']['f1']:.3f}")
    print(f"  å¹³å‡æŸ¥è¯¢æ—¶é—´: {basic_results['timing']['average_time']:.2f}ç§’")
    
    print("\nä¼˜åŒ–å·¥ä½œæµ:")
    print(f"  Precision: {optimized_results['metrics']['precision']:.3f}")
    print(f"  Recall: {optimized_results['metrics']['recall']:.3f}")
    print(f"  F1-Score: {optimized_results['metrics']['f1']:.3f}")
    print(f"  å¹³å‡æŸ¥è¯¢æ—¶é—´: {optimized_results['timing']['average_time']:.2f}ç§’")
    
    # è®¡ç®—æå‡
    speedup = basic_results['timing']['average_time'] / optimized_results['timing']['average_time']
    print(f"\næ€§èƒ½æå‡: {speedup:.1f}x")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    results = {
        'basic_workflow': basic_results,
        'optimized_workflow': optimized_results,
        'comparison': {
            'speedup': speedup,
            'precision_diff': optimized_results['metrics']['precision'] - basic_results['metrics']['precision'],
            'recall_diff': optimized_results['metrics']['recall'] - basic_results['metrics']['recall'],
            'f1_diff': optimized_results['metrics']['f1'] - basic_results['metrics']['f1']
        }
    }
    
    with open('evaluation_results.json', 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print("\nâœ… è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° evaluation_results.json")


if __name__ == "__main__":
    asyncio.run(main())