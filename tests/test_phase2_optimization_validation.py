"""
Phase 2 ä¼˜åŒ–éªŒè¯æµ‹è¯• - ç»¼åˆæ€§èƒ½è¯„ä¼°
éªŒè¯æ‰€æœ‰ä¼˜åŒ–ç»„ä»¶çš„é›†æˆæ•ˆæœå’Œæ™ºèƒ½è·¯ç”±ç³»ç»Ÿ
"""

import pytest
import asyncio
import time
import logging
import random
import numpy as np
from typing import List, Dict, Any, Tuple
from src.core.models import ColumnInfo, TableInfo
from src.config.settings import settings
from src.tools.performance_profiler import get_performance_profiler
from src.tools.adaptive_config_system import get_adaptive_config_engine
from src.tools.intelligent_component_router import (
    get_intelligent_component_router, QueryContext, ComponentType, RouteStrategy
)
from src.tools.optimized_pipeline import create_optimized_pipeline, OptimizedPipelineConfig
from src.tools.optimized_vectorized_calculator import create_optimized_vectorized_calculator, OptimizedVectorizedConfig

logger = logging.getLogger(__name__)


class Phase2OptimizationValidator:
    """Phase 2 ä¼˜åŒ–éªŒè¯å™¨"""
    
    def __init__(self):
        self.results = {}
        self.test_data = {}
        
        # æ€§èƒ½ç›®æ ‡ï¼ˆåŸºäºæ¶æ„å‡çº§è®¡åˆ’ï¼‰
        self.optimization_targets = {
            'overall_speedup': 2.0,              # æ•´ä½“2xåŠ é€Ÿç›®æ ‡
            'large_matrix_speedup': 1.8,         # å¤§çŸ©é˜µ1.8xåŠ é€Ÿç›®æ ‡
            'intelligent_routing_efficiency': 0.9, # æ™ºèƒ½è·¯ç”±90%æ•ˆç‡ç›®æ ‡
            'adaptive_config_responsiveness': 0.8, # è‡ªé€‚åº”é…ç½®80%å“åº”æ€§ç›®æ ‡
            'system_stability': 0.95             # ç³»ç»Ÿç¨³å®šæ€§95%ç›®æ ‡
        }
    
    async def run_comprehensive_validation(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆä¼˜åŒ–éªŒè¯"""
        logger.info("å¼€å§‹Phase 2ä¼˜åŒ–ç»¼åˆéªŒè¯")
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        await self._prepare_comprehensive_test_data()
        
        # 1. åŸºå‡†æ€§èƒ½æµ‹è¯•ï¼ˆæ— ä¼˜åŒ–ï¼‰
        baseline_results = await self._benchmark_baseline_performance()
        
        # 2. ä¼˜åŒ–å‘é‡åŒ–è®¡ç®—å™¨éªŒè¯
        optimized_vectorized_results = await self._validate_optimized_vectorized_calculator()
        
        # 3. æ™ºèƒ½è·¯ç”±ç³»ç»ŸéªŒè¯
        intelligent_routing_results = await self._validate_intelligent_routing_system()
        
        # 4. è‡ªé€‚åº”é…ç½®ç³»ç»ŸéªŒè¯
        adaptive_config_results = await self._validate_adaptive_config_system()
        
        # 5. ç«¯åˆ°ç«¯é›†æˆéªŒè¯
        end_to_end_results = await self._validate_end_to_end_integration()
        
        # 6. ç³»ç»Ÿç¨³å®šæ€§å’Œé²æ£’æ€§æµ‹è¯•
        stability_results = await self._validate_system_stability()
        
        # æ•´åˆç»“æœ
        self.results = {
            "baseline_performance": baseline_results,
            "optimized_vectorized": optimized_vectorized_results,
            "intelligent_routing": intelligent_routing_results,
            "adaptive_config": adaptive_config_results,
            "end_to_end_integration": end_to_end_results,
            "system_stability": stability_results,
            "optimization_targets": self.optimization_targets,
            "comprehensive_analysis": self._generate_comprehensive_analysis()
        }
        
        logger.info("Phase 2ä¼˜åŒ–ç»¼åˆéªŒè¯å®Œæˆ")
        return self.results
    
    async def _prepare_comprehensive_test_data(self):
        """å‡†å¤‡ç»¼åˆæµ‹è¯•æ•°æ®"""
        logger.info("å‡†å¤‡ç»¼åˆæµ‹è¯•æ•°æ®...")
        
        # åˆ›å»ºå¤šæ ·åŒ–çš„æµ‹è¯•åœºæ™¯
        self.test_data = {
            "micro": await self._create_scenario_dataset(50, "micro"),      # å¾®å°æ•°æ®é›†
            "small": await self._create_scenario_dataset(200, "small"),     # å°æ•°æ®é›†
            "medium": await self._create_scenario_dataset(800, "medium"),   # ä¸­ç­‰æ•°æ®é›†
            "large": await self._create_scenario_dataset(2000, "large"),    # å¤§æ•°æ®é›†
            "stress": await self._create_scenario_dataset(5000, "stress")   # å‹åŠ›æµ‹è¯•æ•°æ®é›†
        }
        
        logger.info(f"ç»¼åˆæµ‹è¯•æ•°æ®å‡†å¤‡å®Œæˆ: {len(self.test_data)} ä¸ªåœºæ™¯")
    
    async def _create_scenario_dataset(self, table_count: int, scenario_name: str) -> Dict[str, Any]:
        """åˆ›å»ºåœºæ™¯åŒ–æµ‹è¯•æ•°æ®é›†"""
        tables = []
        all_columns = []
        
        # æ ¹æ®åœºæ™¯è°ƒæ•´æ•°æ®ç‰¹å¾
        if scenario_name == "micro":
            # å¾®å°æ•°æ®é›†ï¼šç®€å•ç»“æ„ï¼Œå¿«é€Ÿå¤„ç†
            column_patterns = [['id', 'name'], ['user_id', 'value']]
        elif scenario_name == "small":
            # å°æ•°æ®é›†ï¼šä¸­ç­‰å¤æ‚åº¦
            column_patterns = [
                ['id', 'name', 'email'],
                ['user_id', 'username', 'created_at'],
                ['product_id', 'title', 'price']
            ]
        elif scenario_name == "medium":
            # ä¸­ç­‰æ•°æ®é›†ï¼šå¤æ‚ç»“æ„ï¼Œå¤šæ ·åŒ–åˆ—å
            column_patterns = [
                ['customer_id', 'customer_name', 'email', 'phone', 'address'],
                ['order_id', 'customer_id', 'product_id', 'quantity', 'order_date', 'status'],
                ['product_id', 'product_name', 'description', 'price', 'category', 'stock'],
                ['transaction_id', 'account_id', 'amount', 'currency', 'transaction_date'],
            ]
        elif scenario_name == "large":
            # å¤§æ•°æ®é›†ï¼šé«˜å¤æ‚åº¦ï¼Œæ·±å±‚åµŒå¥—
            column_patterns = [
                ['user_id', 'username', 'email', 'first_name', 'last_name', 'birth_date', 'gender', 'country'],
                ['session_id', 'user_id', 'start_time', 'end_time', 'page_views', 'actions', 'device', 'browser'],
                ['event_id', 'session_id', 'event_type', 'timestamp', 'properties', 'source', 'medium'],
                ['order_id', 'user_id', 'total_amount', 'tax', 'shipping', 'discount', 'payment_method', 'status']
            ]
        else:  # stress
            # å‹åŠ›æµ‹è¯•ï¼šæé«˜å¤æ‚åº¦ï¼Œå¤§é‡åˆ—
            column_patterns = [
                [f'field_{i}' for i in range(20)],  # 20åˆ—çš„å®½è¡¨
                [f'metric_{i}' for i in range(15)], # 15åˆ—çš„æŒ‡æ ‡è¡¨
                [f'dim_{i}' for i in range(25)]     # 25åˆ—çš„ç»´åº¦è¡¨
            ]
        
        for i in range(table_count):
            # éšæœºé€‰æ‹©åˆ—æ¨¡å¼
            if random.random() < 0.7:  # 70%æ¦‚ç‡ä½¿ç”¨é¢„å®šä¹‰æ¨¡å¼
                base_pattern = random.choice(column_patterns)
                column_names = base_pattern.copy()
                # æ·»åŠ ä¸€äº›éšæœºåˆ—
                for _ in range(random.randint(0, 3)):
                    column_names.append(f"extra_col_{random.randint(1, 100)}")
            else:
                # å®Œå…¨éšæœºåˆ—å
                column_count = random.randint(5, 15)
                column_names = [f"random_col_{j}_{random.choice(['data', 'info', 'value'])}" 
                               for j in range(column_count)]
            
            table_name = f"{scenario_name}_table_{i}"
            columns = []
            
            for column_name in column_names:
                data_type = random.choice(["int", "varchar", "float", "datetime", "boolean", "text"])
                # ç”Ÿæˆæ›´çœŸå®çš„æ ·æœ¬å€¼
                if data_type == "int":
                    sample_values = [str(random.randint(1, 10000)) for _ in range(3)]
                elif data_type == "varchar" or data_type == "text":
                    sample_values = [f"sample_{random.choice(['alpha', 'beta', 'gamma'])}" for _ in range(3)]
                elif data_type == "float":
                    sample_values = [f"{random.uniform(0, 1000):.2f}" for _ in range(3)]
                elif data_type == "datetime":
                    sample_values = ["2024-01-01", "2024-06-15", "2024-12-31"]
                else:  # boolean
                    sample_values = ["true", "false", "true"]
                
                column = ColumnInfo(
                    table_name=table_name,
                    column_name=column_name,
                    data_type=data_type,
                    sample_values=sample_values
                )
                columns.append(column)
                all_columns.append(column)
            
            table = TableInfo(
                table_name=table_name,
                columns=columns,
                row_count=random.randint(1000, 1000000)
            )
            tables.append(table)
        
        return {
            "scenario": scenario_name,
            "tables": tables,
            "columns": all_columns,
            "table_count": table_count,
            "column_count": len(all_columns)
        }
    
    async def _benchmark_baseline_performance(self) -> Dict[str, Any]:
        """åŸºå‡†æ€§èƒ½æµ‹è¯•ï¼ˆæ— ä¼˜åŒ–ï¼‰"""
        logger.info("å¼€å§‹åŸºå‡†æ€§èƒ½æµ‹è¯•...")
        
        # åˆ›å»ºæ— ä¼˜åŒ–çš„ç®€å•ç®¡é“
        baseline_results = {}
        
        for scenario_name, dataset in self.test_data.items():
            logger.info(f"åŸºå‡†æµ‹è¯• - {scenario_name} åœºæ™¯")
            
            # é€‰æ‹©æµ‹è¯•æ ·æœ¬
            query_columns = random.sample(dataset["columns"], min(10, len(dataset["columns"])))
            
            # ç®€å•ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆåŸºå‡†ï¼‰
            processing_times = []
            
            for query_column in query_columns:
                start_time = time.time()
                
                # æ¨¡æ‹Ÿç®€å•çš„ç›¸ä¼¼åº¦è®¡ç®—
                results = []
                for candidate in dataset["columns"][:100]:  # é™åˆ¶å€™é€‰æ•°é‡
                    if candidate != query_column:
                        # ç®€å•å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
                        similarity = self._simple_jaccard_similarity(
                            query_column.column_name, candidate.column_name
                        )
                        if similarity > 0.3:
                            results.append((candidate, similarity))
                
                results.sort(key=lambda x: x[1], reverse=True)
                processing_time = time.time() - start_time
                processing_times.append(processing_time)
            
            avg_processing_time = sum(processing_times) / len(processing_times)
            
            baseline_results[scenario_name] = {
                "avg_processing_time": avg_processing_time,
                "total_queries": len(query_columns),
                "data_size": dataset["column_count"],
                "method": "baseline_simple"
            }
            
            logger.info(f"åŸºå‡† {scenario_name}: å¹³å‡å¤„ç†æ—¶é—´={avg_processing_time:.3f}s")
        
        return baseline_results
    
    async def _validate_optimized_vectorized_calculator(self) -> Dict[str, Any]:
        """éªŒè¯ä¼˜åŒ–å‘é‡åŒ–è®¡ç®—å™¨"""
        logger.info("å¼€å§‹ä¼˜åŒ–å‘é‡åŒ–è®¡ç®—å™¨éªŒè¯...")
        
        # åˆ›å»ºä¼˜åŒ–è®¡ç®—å™¨
        optimized_config = OptimizedVectorizedConfig(
            enable_chunking=True,
            chunk_size_mb=64,
            enable_adaptive_algorithm=True,
            memory_pool_size_mb=256
        )
        
        optimized_calculator = create_optimized_vectorized_calculator(optimized_config)
        results = {}
        
        # æµ‹è¯•ä¸åŒè§„æ¨¡çš„çŸ©é˜µè®¡ç®—
        test_cases = [
            (100, 100, "small_matrix"),
            (500, 500, "medium_matrix"),
            (1000, 1000, "large_matrix"),
            (2000, 2000, "xlarge_matrix"),
            (3000, 1000, "asymmetric_matrix")
        ]
        
        for rows, cols, case_name in test_cases:
            logger.info(f"æµ‹è¯•ä¼˜åŒ–å‘é‡åŒ– - {case_name} ({rows}x{cols})")
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            vectors1 = np.random.rand(rows, 384).astype(np.float32)
            vectors2 = np.random.rand(cols, 384).astype(np.float32)
            
            # ä¼˜åŒ–è®¡ç®—
            start_time = time.time()
            optimized_result = optimized_calculator.optimized_cosine_similarity(vectors1, vectors2)
            optimized_time = time.time() - start_time
            
            # ä¼ ç»Ÿè®¡ç®—å¯¹æ¯”
            start_time = time.time()
            traditional_result = optimized_calculator._direct_cosine_similarity(vectors1, vectors2)
            traditional_time = time.time() - start_time
            
            # è®¡ç®—æŒ‡æ ‡
            speedup = traditional_time / optimized_time if optimized_time > 0 else 0
            accuracy = np.corrcoef(optimized_result.flatten(), traditional_result.flatten())[0, 1]
            
            results[case_name] = {
                "matrix_size": f"{rows}x{cols}",
                "optimized_time": optimized_time,
                "traditional_time": traditional_time,
                "speedup": speedup,
                "accuracy": accuracy,
                "memory_mb": (vectors1.nbytes + vectors2.nbytes) / (1024 * 1024),
                "algorithm_used": "adaptive_optimized"
            }
            
            logger.info(f"ä¼˜åŒ–å‘é‡åŒ– {case_name}: åŠ é€Ÿæ¯”={speedup:.1f}x, å‡†ç¡®åº¦={accuracy:.3f}")
        
        # è·å–ä¼˜åŒ–ç»Ÿè®¡
        results["optimization_stats"] = optimized_calculator.get_optimization_stats()
        
        return results
    
    async def _validate_intelligent_routing_system(self) -> Dict[str, Any]:
        """éªŒè¯æ™ºèƒ½è·¯ç”±ç³»ç»Ÿ"""
        logger.info("å¼€å§‹æ™ºèƒ½è·¯ç”±ç³»ç»ŸéªŒè¯...")
        
        intelligent_router = get_intelligent_component_router()
        results = {}
        
        # æµ‹è¯•ä¸åŒåœºæ™¯ä¸‹çš„è·¯ç”±å†³ç­–
        for scenario_name, dataset in self.test_data.items():
            logger.info(f"æµ‹è¯•æ™ºèƒ½è·¯ç”± - {scenario_name} åœºæ™¯")
            
            # åˆ›å»ºæŸ¥è¯¢ä¸Šä¸‹æ–‡
            query_context = QueryContext(
                query_type="column_search",
                data_size=dataset["column_count"],
                complexity_hint=scenario_name,
                user_priority="balanced"
            )
            
            # æµ‹è¯•ä¸åŒç­–ç•¥
            strategy_results = {}
            
            for strategy in [RouteStrategy.PERFORMANCE_OPTIMIZED, RouteStrategy.RESOURCE_CONSERVING, 
                           RouteStrategy.BALANCED, RouteStrategy.ADAPTIVE]:
                
                # è®¾ç½®è·¯ç”±ç­–ç•¥
                intelligent_router.current_strategy = strategy
                
                # åˆ¶å®šè·¯ç”±å†³ç­–
                start_time = time.time()
                routing_decision = await intelligent_router.route_query(query_context)
                decision_time = time.time() - start_time
                
                strategy_results[strategy.value] = {
                    "selected_components": [comp.value for comp in routing_decision.selected_components],
                    "processing_strategy": routing_decision.processing_strategy,
                    "estimated_performance": routing_decision.estimated_performance,
                    "reasoning": routing_decision.reasoning,
                    "decision_time": decision_time,
                    "component_count": len(routing_decision.selected_components)
                }
            
            results[scenario_name] = strategy_results
        
        # è·å–è·¯ç”±åˆ†æ
        results["routing_analytics"] = intelligent_router.get_routing_analytics()
        
        return results
    
    async def _validate_adaptive_config_system(self) -> Dict[str, Any]:
        """éªŒè¯è‡ªé€‚åº”é…ç½®ç³»ç»Ÿ"""
        logger.info("å¼€å§‹è‡ªé€‚åº”é…ç½®ç³»ç»ŸéªŒè¯...")
        
        adaptive_engine = get_adaptive_config_engine()
        results = {}
        
        # å¯åŠ¨ç›‘æ§
        adaptive_engine.start_monitoring()
        
        # ç­‰å¾…æ”¶é›†ä¸€äº›æŒ‡æ ‡
        await asyncio.sleep(2)
        
        # è·å–ç³»ç»ŸçŠ¶æ€
        system_status = adaptive_engine.get_system_status()
        results["initial_system_status"] = system_status
        
        # è·å–ä¼˜åŒ–å»ºè®®
        recommendations = adaptive_engine.get_optimization_recommendations()
        results["optimization_recommendations"] = recommendations
        
        # æ¨¡æ‹Ÿè´Ÿè½½å˜åŒ–å’Œé…ç½®è°ƒæ•´
        load_simulation_results = []
        
        for load_level in ["low", "medium", "high"]:
            logger.info(f"æ¨¡æ‹Ÿ {load_level} è´Ÿè½½åœºæ™¯")
            
            # æ¨¡æ‹Ÿä¸åŒè´Ÿè½½ä¸‹çš„ç³»ç»Ÿè¡Œä¸º
            if load_level == "high":
                # é«˜è´Ÿè½½ï¼šæ‰§è¡Œå¤§é‡è®¡ç®—
                for _ in range(5):
                    vectors = np.random.rand(1000, 384)
                    np.dot(vectors, vectors.T)
            
            await asyncio.sleep(1)  # ç­‰å¾…æŒ‡æ ‡æ›´æ–°
            
            current_status = adaptive_engine.get_system_status()
            current_recommendations = adaptive_engine.get_optimization_recommendations()
            
            load_simulation_results.append({
                "load_level": load_level,
                "system_status": current_status,
                "recommendations": current_recommendations,
                "recommendations_count": len(current_recommendations)
            })
        
        results["load_simulation"] = load_simulation_results
        
        # åœæ­¢ç›‘æ§
        adaptive_engine.stop_monitoring()
        
        return results
    
    async def _validate_end_to_end_integration(self) -> Dict[str, Any]:
        """éªŒè¯ç«¯åˆ°ç«¯é›†æˆ"""
        logger.info("å¼€å§‹ç«¯åˆ°ç«¯é›†æˆéªŒè¯...")
        
        # åˆ›å»ºä¼˜åŒ–ç®¡é“
        optimized_config = OptimizedPipelineConfig(
            enable_smart_routing=True,
            fast_path_threshold=50,
            component_warmup=True,
            lazy_initialization=True
        )
        
        optimized_pipeline = create_optimized_pipeline(optimized_config)
        results = {}
        
        for scenario_name, dataset in self.test_data.items():
            logger.info(f"ç«¯åˆ°ç«¯æµ‹è¯• - {scenario_name} åœºæ™¯")
            
            # é€‰æ‹©æµ‹è¯•æ ·æœ¬
            query_columns = random.sample(dataset["columns"], min(5, len(dataset["columns"])))
            candidate_columns = dataset["columns"]
            
            # ä¼˜åŒ–ç®¡é“æµ‹è¯•
            optimized_times = []
            optimized_results_count = 0
            
            for query_column in query_columns:
                start_time = time.time()
                results_list = await optimized_pipeline.enhanced_column_search(
                    query_column, candidate_columns, k=10
                )
                processing_time = time.time() - start_time
                optimized_times.append(processing_time)
                optimized_results_count += len(results_list)
            
            avg_optimized_time = sum(optimized_times) / len(optimized_times)
            
            # ä¸åŸºå‡†å¯¹æ¯”
            baseline_time = self.results.get("baseline_performance", {}).get(scenario_name, {}).get("avg_processing_time", 1.0)
            speedup = baseline_time / avg_optimized_time if avg_optimized_time > 0 else 0
            
            results[scenario_name] = {
                "avg_processing_time": avg_optimized_time,
                "baseline_time": baseline_time,
                "speedup": speedup,
                "results_count": optimized_results_count,
                "queries_tested": len(query_columns),
                "optimization_report": optimized_pipeline.get_optimization_report()
            }
            
            logger.info(f"ç«¯åˆ°ç«¯ {scenario_name}: åŠ é€Ÿæ¯”={speedup:.1f}x, å¤„ç†æ—¶é—´={avg_optimized_time:.3f}s")
        
        return results
    
    async def _validate_system_stability(self) -> Dict[str, Any]:
        """éªŒè¯ç³»ç»Ÿç¨³å®šæ€§"""
        logger.info("å¼€å§‹ç³»ç»Ÿç¨³å®šæ€§éªŒè¯...")
        
        results = {}
        
        # å‹åŠ›æµ‹è¯•
        stress_results = await self._stress_test()
        results["stress_test"] = stress_results
        
        # å†…å­˜æ³„æ¼æµ‹è¯•
        memory_test_results = await self._memory_leak_test()
        results["memory_leak_test"] = memory_test_results
        
        # é”™è¯¯æ¢å¤æµ‹è¯•
        error_recovery_results = await self._error_recovery_test()
        results["error_recovery_test"] = error_recovery_results
        
        return results
    
    async def _stress_test(self) -> Dict[str, Any]:
        """å‹åŠ›æµ‹è¯•"""
        logger.info("æ‰§è¡Œå‹åŠ›æµ‹è¯•...")
        
        # ä½¿ç”¨å¤§æ•°æ®é›†è¿›è¡Œè¿ç»­æµ‹è¯•
        dataset = self.test_data["stress"]
        optimized_pipeline = create_optimized_pipeline()
        
        start_time = time.time()
        successful_queries = 0
        failed_queries = 0
        processing_times = []
        
        # è¿ç»­æ‰§è¡Œ100æ¬¡æŸ¥è¯¢
        for i in range(100):
            try:
                query_column = random.choice(dataset["columns"])
                candidate_columns = random.sample(dataset["columns"], min(500, len(dataset["columns"])))
                
                query_start = time.time()
                results_list = await optimized_pipeline.enhanced_column_search(
                    query_column, candidate_columns, k=5
                )
                query_time = time.time() - query_start
                
                processing_times.append(query_time)
                successful_queries += 1
                
                if i % 20 == 0:
                    logger.info(f"å‹åŠ›æµ‹è¯•è¿›åº¦: {i}/100, æˆåŠŸç‡: {successful_queries/(i+1):.2%}")
                
            except Exception as e:
                failed_queries += 1
                logger.warning(f"å‹åŠ›æµ‹è¯•æŸ¥è¯¢å¤±è´¥: {e}")
        
        total_time = time.time() - start_time
        success_rate = successful_queries / (successful_queries + failed_queries)
        avg_query_time = sum(processing_times) / len(processing_times) if processing_times else 0
        throughput = successful_queries / total_time
        
        return {
            "total_queries": successful_queries + failed_queries,
            "successful_queries": successful_queries,
            "failed_queries": failed_queries,
            "success_rate": success_rate,
            "avg_query_time": avg_query_time,
            "throughput_qps": throughput,
            "total_duration": total_time,
            "stability_score": success_rate * (1 if avg_query_time < 2.0 else 0.8)
        }
    
    async def _memory_leak_test(self) -> Dict[str, Any]:
        """å†…å­˜æ³„æ¼æµ‹è¯•"""
        logger.info("æ‰§è¡Œå†…å­˜æ³„æ¼æµ‹è¯•...")
        
        import psutil
        process = psutil.Process()
        
        initial_memory = process.memory_info().rss / (1024 * 1024)  # MB
        memory_samples = [initial_memory]
        
        optimized_calculator = create_optimized_vectorized_calculator()
        
        # é‡å¤æ‰§è¡Œå†…å­˜å¯†é›†æ“ä½œ
        for i in range(50):
            # åˆ›å»ºå¤§çŸ©é˜µå¹¶è®¡ç®—
            vectors1 = np.random.rand(500, 384).astype(np.float32)
            vectors2 = np.random.rand(500, 384).astype(np.float32)
            
            result = optimized_calculator.optimized_cosine_similarity(vectors1, vectors2)
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            del vectors1, vectors2, result
            
            # æ¯10æ¬¡é‡‡æ ·å†…å­˜
            if i % 10 == 0:
                current_memory = process.memory_info().rss / (1024 * 1024)
                memory_samples.append(current_memory)
        
        # æ¸…ç†èµ„æº
        optimized_calculator.cleanup()
        
        # æœ€ç»ˆå†…å­˜
        final_memory = process.memory_info().rss / (1024 * 1024)
        memory_samples.append(final_memory)
        
        # åˆ†æå†…å­˜è¶‹åŠ¿
        memory_growth = final_memory - initial_memory
        max_memory = max(memory_samples)
        memory_stability = 1.0 - (memory_growth / initial_memory) if memory_growth > 0 else 1.0
        
        return {
            "initial_memory_mb": initial_memory,
            "final_memory_mb": final_memory,
            "max_memory_mb": max_memory,
            "memory_growth_mb": memory_growth,
            "memory_samples": memory_samples,
            "memory_stability_score": max(0.0, memory_stability),
            "leak_detected": memory_growth > initial_memory * 0.2  # è¶…è¿‡20%è®¤ä¸ºæœ‰æ³„æ¼
        }
    
    async def _error_recovery_test(self) -> Dict[str, Any]:
        """é”™è¯¯æ¢å¤æµ‹è¯•"""
        logger.info("æ‰§è¡Œé”™è¯¯æ¢å¤æµ‹è¯•...")
        
        recovery_results = []
        
        # æµ‹è¯•å„ç§é”™è¯¯åœºæ™¯
        error_scenarios = [
            ("empty_data", lambda: []),
            ("invalid_vectors", lambda: np.array([])),
            ("memory_pressure", lambda: np.random.rand(10000, 10000)),  # å·¨å¤§çŸ©é˜µ
            ("null_input", lambda: None)
        ]
        
        optimized_calculator = create_optimized_vectorized_calculator()
        
        for scenario_name, error_generator in error_scenarios:
            try:
                logger.info(f"æµ‹è¯•é”™è¯¯æ¢å¤åœºæ™¯: {scenario_name}")
                
                # ç”Ÿæˆé”™è¯¯æ¡ä»¶
                error_data = error_generator()
                
                start_time = time.time()
                
                if scenario_name == "empty_data":
                    # ç©ºæ•°æ®æµ‹è¯•
                    result = optimized_calculator.optimized_cosine_similarity(
                        np.array([]).reshape(0, 384), np.array([]).reshape(0, 384)
                    )
                elif scenario_name == "memory_pressure":
                    # å†…å­˜å‹åŠ›æµ‹è¯•ï¼ˆåº”è¯¥ä¼˜é›…é™çº§ï¼‰
                    vectors1 = np.random.rand(100, 384).astype(np.float32)
                    vectors2 = np.random.rand(100, 384).astype(np.float32)
                    result = optimized_calculator.optimized_cosine_similarity(vectors1, vectors2)
                else:
                    # å…¶ä»–é”™è¯¯åœºæ™¯
                    vectors1 = np.random.rand(10, 384).astype(np.float32)
                    vectors2 = np.random.rand(10, 384).astype(np.float32)
                    result = optimized_calculator.optimized_cosine_similarity(vectors1, vectors2)
                
                recovery_time = time.time() - start_time
                
                recovery_results.append({
                    "scenario": scenario_name,
                    "recovery_successful": True,
                    "recovery_time": recovery_time,
                    "error_message": None
                })
                
            except Exception as e:
                recovery_results.append({
                    "scenario": scenario_name,
                    "recovery_successful": False,
                    "recovery_time": None,
                    "error_message": str(e)
                })
        
        # è®¡ç®—æ€»ä½“æ¢å¤èƒ½åŠ›
        successful_recoveries = sum(1 for r in recovery_results if r["recovery_successful"])
        recovery_rate = successful_recoveries / len(recovery_results)
        
        return {
            "recovery_scenarios": recovery_results,
            "total_scenarios": len(recovery_results),
            "successful_recoveries": successful_recoveries,
            "recovery_rate": recovery_rate,
            "overall_resilience_score": recovery_rate
        }
    
    def _simple_jaccard_similarity(self, str1: str, str2: str) -> float:
        """ç®€å•Jaccardç›¸ä¼¼åº¦è®¡ç®—"""
        if not str1 or not str2:
            return 0.0
        
        set1 = set(str1.lower())
        set2 = set(str2.lower())
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        
        return intersection / union if union > 0 else 0.0
    
    def _generate_comprehensive_analysis(self) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        analysis = {
            "test_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "optimization_achievements": {},
            "target_achievement_status": {},
            "performance_improvements": {},
            "recommendations": []
        }
        
        # åˆ†æä¼˜åŒ–æˆæœ
        if "end_to_end_integration" in self.results:
            e2e_results = self.results["end_to_end_integration"]
            speedups = [result.get("speedup", 1.0) for result in e2e_results.values() if isinstance(result, dict)]
            if speedups:
                avg_speedup = sum(speedups) / len(speedups)
                analysis["optimization_achievements"]["overall_speedup"] = avg_speedup
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
                target_met = avg_speedup >= self.optimization_targets["overall_speedup"]
                analysis["target_achievement_status"]["overall_speedup"] = {
                    "achieved": avg_speedup,
                    "target": self.optimization_targets["overall_speedup"],
                    "met": target_met,
                    "improvement_ratio": avg_speedup / self.optimization_targets["overall_speedup"]
                }
        
        # åˆ†æå¤§çŸ©é˜µæ€§èƒ½
        if "optimized_vectorized" in self.results:
            vectorized_results = self.results["optimized_vectorized"]
            large_matrix_speedups = []
            for case_name, result in vectorized_results.items():
                if isinstance(result, dict) and "large" in case_name:
                    large_matrix_speedups.append(result.get("speedup", 1.0))
            
            if large_matrix_speedups:
                avg_large_speedup = sum(large_matrix_speedups) / len(large_matrix_speedups)
                target_met = avg_large_speedup >= self.optimization_targets["large_matrix_speedup"]
                analysis["target_achievement_status"]["large_matrix_speedup"] = {
                    "achieved": avg_large_speedup,
                    "target": self.optimization_targets["large_matrix_speedup"],
                    "met": target_met
                }
        
        # åˆ†æç³»ç»Ÿç¨³å®šæ€§
        if "system_stability" in self.results:
            stability_results = self.results["system_stability"]
            if "stress_test" in stability_results:
                stability_score = stability_results["stress_test"].get("stability_score", 0)
                target_met = stability_score >= self.optimization_targets["system_stability"]
                analysis["target_achievement_status"]["system_stability"] = {
                    "achieved": stability_score,
                    "target": self.optimization_targets["system_stability"],
                    "met": target_met
                }
        
        # ç”Ÿæˆå»ºè®®
        for target_name, status in analysis["target_achievement_status"].items():
            if not status.get("met", False):
                analysis["recommendations"].append({
                    "category": target_name,
                    "message": f"{target_name} æœªè¾¾åˆ°ç›®æ ‡ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–",
                    "priority": "high" if status.get("improvement_ratio", 0) < 0.8 else "medium"
                })
        
        return analysis


@pytest.mark.asyncio
async def test_phase2_optimization_validation():
    """Phase 2 ä¼˜åŒ–éªŒè¯æµ‹è¯•"""
    validator = Phase2OptimizationValidator()
    results = await validator.run_comprehensive_validation()
    
    # éªŒè¯åŸºæœ¬ç»“æœå­˜åœ¨
    assert "baseline_performance" in results
    assert "optimized_vectorized" in results
    assert "intelligent_routing" in results
    assert "end_to_end_integration" in results
    
    # æ‰“å°è¯¦ç»†ç»“æœ
    print("\n" + "="*90)
    print("Phase 2 ä¼˜åŒ–éªŒè¯ç»¼åˆæŠ¥å‘Š")
    print("="*90)
    
    # ä¼˜åŒ–æˆæœæ€»ç»“
    analysis = results.get("comprehensive_analysis", {})
    achievements = analysis.get("optimization_achievements", {})
    target_status = analysis.get("target_achievement_status", {})
    
    print("\nğŸ“Š ä¼˜åŒ–æˆæœæ€»ç»“:")
    for metric, value in achievements.items():
        print(f"  {metric}: {value:.2f}x")
    
    print("\nğŸ¯ ç›®æ ‡è¾¾æˆæƒ…å†µ:")
    for target, status in target_status.items():
        achieved = status.get("achieved", 0)
        target_val = status.get("target", 1)
        met = status.get("met", False)
        status_icon = "âœ…" if met else "âŒ"
        print(f"  {target}: {achieved:.2f} / {target_val:.2f} {status_icon}")
    
    # ç«¯åˆ°ç«¯æ€§èƒ½å¯¹æ¯”
    print("\nâš¡ ç«¯åˆ°ç«¯æ€§èƒ½æå‡:")
    e2e_results = results.get("end_to_end_integration", {})
    for scenario, result in e2e_results.items():
        if isinstance(result, dict):
            speedup = result.get("speedup", 1.0)
            processing_time = result.get("avg_processing_time", 0)
            print(f"  {scenario}: {speedup:.1f}x åŠ é€Ÿ, {processing_time:.3f}s å¤„ç†æ—¶é—´")
    
    # ç³»ç»Ÿç¨³å®šæ€§
    print("\nğŸ›¡ï¸ ç³»ç»Ÿç¨³å®šæ€§:")
    stability_results = results.get("system_stability", {})
    if "stress_test" in stability_results:
        stress_test = stability_results["stress_test"]
        success_rate = stress_test.get("success_rate", 0)
        throughput = stress_test.get("throughput_qps", 0)
        print(f"  å‹åŠ›æµ‹è¯•æˆåŠŸç‡: {success_rate:.1%}")
        print(f"  ååé‡: {throughput:.1f} QPS")
    
    if "memory_leak_test" in stability_results:
        memory_test = stability_results["memory_leak_test"]
        memory_growth = memory_test.get("memory_growth_mb", 0)
        leak_detected = memory_test.get("leak_detected", False)
        leak_status = "âŒ æ£€æµ‹åˆ°æ³„æ¼" if leak_detected else "âœ… æ— æ³„æ¼"
        print(f"  å†…å­˜å¢é•¿: {memory_growth:.1f}MB {leak_status}")
    
    # ä¼˜åŒ–å»ºè®®
    recommendations = analysis.get("recommendations", [])
    if recommendations:
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for rec in recommendations:
            priority = rec.get("priority", "medium")
            message = rec.get("message", "")
            priority_icon = "ğŸ”´" if priority == "high" else "ğŸŸ¡"
            print(f"  {priority_icon} {message}")
    else:
        print("\nâœ¨ æ‰€æœ‰ä¼˜åŒ–ç›®æ ‡å·²è¾¾æˆï¼Œç³»ç»Ÿæ€§èƒ½ä¼˜å¼‚ï¼")
    
    print("\n" + "="*90)
    
    return results


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    import asyncio
    asyncio.run(test_phase2_optimization_validation())