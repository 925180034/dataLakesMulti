#!/usr/bin/env python3
"""
WebTableæ•°æ®é›†æµ‹è¯•è„šæœ¬
"""

import json
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.absolute()))

from src.core.workflow import discover_data
from src.core.models import AgentState, TaskStrategy, ColumnInfo, TableInfo


def load_sample_data():
    """åŠ è½½æ ·æœ¬æ•°æ®"""
    
    # åŠ è½½è¡¨æ•°æ®
    with open("examples/webtable_join_tables.json", 'r', encoding='utf-8') as f:
        tables_data = json.load(f)
    
    # åŠ è½½æŸ¥è¯¢æ•°æ®
    with open("examples/webtable_join_queries.json", 'r', encoding='utf-8') as f:
        queries_data = json.load(f)
    
    # åŠ è½½çœŸå®åŒ¹é…æ•°æ®
    with open("examples/webtable_join_ground_truth.json", 'r', encoding='utf-8') as f:
        ground_truth_data = json.load(f)
    
    return tables_data, queries_data, ground_truth_data


async def test_join_scenario():
    """æµ‹è¯•Joinåœºæ™¯"""
    print("=== WebTable Joinåœºæ™¯æµ‹è¯• ===")
    
    # åŠ è½½æ•°æ®
    tables_data, queries_data, ground_truth_data = load_sample_data()
    
    print(f"åŠ è½½äº† {len(tables_data)} ä¸ªè¡¨")
    print(f"åŠ è½½äº† {len(queries_data)} ä¸ªæŸ¥è¯¢")
    print(f"åŠ è½½äº† {len(ground_truth_data)} ä¸ªçœŸå®åŒ¹é…")
    
    # è½¬æ¢è¡¨æ•°æ®æ ¼å¼
    tables = []
    for table_data in tables_data[:10]:  # ä½¿ç”¨å‰10ä¸ªè¡¨è¿›è¡Œæµ‹è¯•
        table_info = TableInfo(**table_data)
        tables.append(table_info)
    
    # æ‰¾åˆ°ä¸€ä¸ªå­˜åœ¨äºæˆ‘ä»¬æ•°æ®é›†ä¸­çš„æŸ¥è¯¢
    available_table_names = [table.table_name for table in tables]
    print(f"å¯ç”¨è¡¨: {available_table_names[:5]}...")
    
    # æ‰¾åˆ°åŒ¹é…çš„æŸ¥è¯¢
    test_query = None
    for query in queries_data:
        query_table_name = query["query_table"].replace('.csv', '')
        if query_table_name in available_table_names:
            test_query = query
            break
    
    if not test_query:
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æµ‹è¯•æŸ¥è¯¢")
        return
    
    print(f"\\næµ‹è¯•æŸ¥è¯¢: {test_query}")
    
    # æ„å»ºçŠ¶æ€
    try:
        # æ„å»ºæŸ¥è¯¢åˆ—
        query_table_name = test_query["query_table"].replace('.csv', '')
        query_column_name = test_query["query_column"]
        
        # å¯»æ‰¾æŸ¥è¯¢è¡¨
        query_table = None
        for table in tables:
            if table.table_name == query_table_name:
                query_table = table
                break
        
        if not query_table:
            print(f"âŒ æœªæ‰¾åˆ°æŸ¥è¯¢è¡¨: {query_table_name}")
            return
        
        # å¯»æ‰¾æŸ¥è¯¢åˆ—
        query_column = query_table.get_column(query_column_name)
        if not query_column:
            print(f"âŒ æœªæ‰¾åˆ°æŸ¥è¯¢åˆ—: {query_column_name}")
            return
        
        print(f"âœ… æ‰¾åˆ°æŸ¥è¯¢åˆ—: {query_column.full_name}")
        print(f"   æ•°æ®ç±»å‹: {query_column.data_type}")
        print(f"   æ ·æœ¬å€¼: {query_column.sample_values[:3]}")
        
        # æ‰§è¡Œå‘ç°
        print("\\nğŸ” å¼€å§‹æ•°æ®å‘ç°...")
        
        # discover_dataæœŸæœ›å­—ç¬¦ä¸²å‚æ•°ï¼Œä¸æ˜¯AgentStateå¯¹è±¡
        user_query = f"find columns similar to {query_column.full_name}"
        
        # è½¬æ¢ä¸ºdiscover_dataæœŸæœ›çš„æ ¼å¼
        query_columns_data = []
        query_columns_data.append({
            "table_name": query_column.table_name,
            "column_name": query_column.column_name,
            "data_type": query_column.data_type,
            "sample_values": query_column.sample_values
        })
        
        candidate_tables_data = []
        for table in tables:
            table_dict = {
                "table_name": table.table_name,
                "columns": []
            }
            for col in table.columns:
                table_dict["columns"].append({
                    "table_name": col.table_name,
                    "column_name": col.column_name,
                    "data_type": col.data_type,
                    "sample_values": col.sample_values
                })
            candidate_tables_data.append(table_dict)
        
        result_state = await discover_data(
            user_query=user_query,
            query_tables=None,
            query_columns=query_columns_data,
            candidate_tables=candidate_tables_data
        )
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\\nğŸ“Š å‘ç°ç»“æœ:")
        print(f"ç­–ç•¥: {result_state.strategy}")
        print(f"åŒ¹é…æ•°é‡: {len(result_state.column_matches)}")
        
        for i, match in enumerate(result_state.column_matches[:3]):
            print(f"  {i+1}. {match.target_column} (ç½®ä¿¡åº¦: {match.confidence:.3f})")
            print(f"     åŸå› : {match.reason}")
        
        # ä¸çœŸå®åŒ¹é…å¯¹æ¯”
        actual_matches = []
        for gt in ground_truth_data:
            if (gt["query_table"] == test_query["query_table"] and 
                gt["query_column"] == test_query["query_column"]):
                actual_matches.append(f"{gt['candidate_table'].replace('.csv', '')}.{gt['candidate_column']}")
        
        print(f"\\nğŸ¯ çœŸå®åŒ¹é… ({len(actual_matches)} ä¸ª):")
        for match in actual_matches[:3]:
            print(f"  - {match}")
        
        # è®¡ç®—å‡†ç¡®ç‡
        found_matches = [match.target_column for match in result_state.column_matches]
        correct_matches = set(found_matches) & set(actual_matches)
        
        if found_matches:
            precision = len(correct_matches) / len(found_matches)
            print(f"\\nğŸ“ˆ å‡†ç¡®ç‡: {precision:.3f} ({len(correct_matches)}/{len(found_matches)})")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def main():
    """ä¸»å‡½æ•°"""
    await test_join_scenario()


if __name__ == "__main__":
    asyncio.run(main())