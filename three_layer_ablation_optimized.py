#!/usr/bin/env python
"""
ä¼˜åŒ–ç‰ˆä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒè„šæœ¬
åŸºäºrun_ultimate_optimized.pyçš„ä¼˜åŒ–ç­–ç•¥
æµ‹è¯•L1ï¼ˆå…ƒæ•°æ®è¿‡æ»¤ï¼‰ã€L2ï¼ˆå‘é‡æœç´¢ï¼‰ã€L3ï¼ˆLLMéªŒè¯ï¼‰å„å±‚çš„è´¡çŒ®
ä¸»è¦ä¼˜åŒ–ï¼š
1. æ‰¹å¤„ç†çº§åˆ«èµ„æºå…±äº«
2. è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†
3. æŒä¹…åŒ–ç¼“å­˜ç³»ç»Ÿ
4. é¢„è®¡ç®—å‘é‡ç´¢å¼•
5. å…¨å±€å•ä¾‹å‡å°‘åˆå§‹åŒ–
"""
import os
import sys
import json
import time
import hashlib
import logging
import pickle
import yaml
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Tuple, Optional
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# é¦–å…ˆå¯¼å…¥é…ç½®æ¨¡å—ï¼Œè‡ªåŠ¨å¯ç”¨ç¦»çº¿æ¨¡å¼
from src import config  # è¿™ä¼šè‡ªåŠ¨è®¾ç½®ç¦»çº¿æ¨¡å¼

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ================== å…¨å±€é…ç½® ==================
# é™ä½è¡¨åæƒé‡
os.environ['TABLE_NAME_WEIGHT'] = '0.05'
# ä½¿ç”¨SMDå¢å¼ºè¿‡æ»¤å™¨
os.environ['USE_SMD_ENHANCED'] = 'true'
# å›ºå®šhashç§å­
os.environ['PYTHONHASHSEED'] = '0'
# ç¦ç”¨tokenizerså¹¶è¡Œä»¥é¿å…forkè­¦å‘Š
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# å¯é…ç½®çš„æœ€å¤§é¢„æµ‹æ•°é‡ï¼ˆæ”¯æŒ@Kè®¡ç®—ï¼ŒKæœ€å¤§ä¸º10ï¼Œè®¾ç½®ä¸º20ç•™æœ‰ä½™é‡ï¼‰
MAX_PREDICTIONS = int(os.environ.get('MAX_PREDICTIONS', '20'))
logger.info(f"ğŸ“Š MAX_PREDICTIONS set to {MAX_PREDICTIONS} (supports up to @{MAX_PREDICTIONS//2} evaluation)")


def load_task_config(task_type: str, dataset_type: str = None) -> Dict[str, Any]:
    """
    ä»ä»»åŠ¡ç‰¹å®šçš„é…ç½®æ–‡ä»¶åŠ è½½é…ç½®
    ä¼˜å…ˆçº§ï¼š
    0. TEMP_CONFIGç¯å¢ƒå˜é‡æŒ‡å®šçš„ä¸´æ—¶é…ç½®æ–‡ä»¶ï¼ˆå‚æ•°ä¼˜åŒ–ä¸“ç”¨ - æœ€é«˜ä¼˜å…ˆçº§ï¼‰
    1. config_{task}_universal.yml (é€šç”¨ä»»åŠ¡é…ç½®)
    2. config_{dataset}_{task}.yml (æ•°æ®é›†+ä»»åŠ¡ç‰¹å®šé…ç½®)
    3. config_{task}_optimized.yml (ä»»åŠ¡ç‰¹å®šä¼˜åŒ–é…ç½®)
    4. config_optimized.yml (é€šç”¨ä¼˜åŒ–é…ç½®)
    5. é»˜è®¤é…ç½®
    
    Args:
        task_type: 'join' æˆ– 'union'
        dataset_type: 'nlctables', 'opendata', 'webtable' (å¯é€‰ï¼Œç”¨äºæ—¥å¿—)
    
    Returns:
        ä»»åŠ¡ç‰¹å®šçš„é…ç½®å­—å…¸
    """
    import os
    
    # æ£€æŸ¥å‚æ•°ä¼˜åŒ–ä¸´æ—¶é…ç½®æ–‡ä»¶ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    temp_config_file = os.environ.get('TEMP_CONFIG')
    if temp_config_file and Path(temp_config_file).exists():
        try:
            with open(temp_config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # æå–ä»»åŠ¡é…ç½®
            if 'task_configs' in config and task_type in config['task_configs']:
                task_config = config['task_configs'][task_type]
                
                # æ‰å¹³åŒ–é…ç½®ï¼Œæå–å…³é”®å‚æ•°
                flat_config = {
                    'llm_confidence_threshold': task_config.get('llm_matcher', {}).get('confidence_threshold', 0.05 if task_type == 'join' else 0.03),
                    'aggregator_max_results': task_config.get('aggregator', {}).get('max_results', 20 if task_type == 'join' else 30),
                    'llm_concurrency': 3,
                    'metadata_threshold': task_config.get('metadata_filter', {}).get('column_similarity_threshold', 0.25 if task_type == 'join' else 0.15),
                    'vector_threshold': task_config.get('vector_search', {}).get('similarity_threshold', 0.35 if task_type == 'join' else 0.25),
                    'min_column_overlap': task_config.get('metadata_filter', {}).get('min_column_overlap', 2 if task_type == 'join' else 1),
                    'vector_top_k': task_config.get('vector_search', {}).get('top_k', 60 if task_type == 'join' else 100),
                    'enable_llm': task_config.get('llm_matcher', {}).get('enable_llm', True),
                    # å±‚ç»„åˆç­–ç•¥ï¼ˆå…³é”®ï¼ï¼‰
                    'layer_combination': task_config.get('layer_combination', 'weighted_union' if task_type == 'join' else 'union'),
                    # JOINç‰¹å®šé…ç½®
                    'use_column_types': task_config.get('metadata_filter', {}).get('use_column_types', task_type == 'join'),
                    'use_value_overlap': task_config.get('metadata_filter', {}).get('use_value_overlap', task_type == 'join'),
                    'focus_on_join_keys': task_config.get('llm_matcher', {}).get('focus_on_join_keys', task_type == 'join'),
                    # UNIONç‰¹å®šé…ç½®
                    'allow_subset_matching': task_config.get('metadata_filter', {}).get('allow_subset_matching', task_type == 'union'),
                    'allow_type_coercion': task_config.get('metadata_filter', {}).get('allow_type_coercion', task_type == 'union'),
                    'allow_self_matches': task_config.get('metadata_filter', {}).get('allow_self_match', task_type == 'union'),
                    'focus_on_compatibility': task_config.get('llm_matcher', {}).get('focus_on_compatibility', task_type == 'union'),
                    'check_semantic_similarity': task_config.get('llm_matcher', {}).get('check_semantic_compatibility', task_type == 'union'),
                    'allow_partial_matches': task_config.get('llm_matcher', {}).get('allow_partial_matches', task_type == 'union'),
                    # å…¶ä»–ä¼˜åŒ–é…ç½®
                    'cache_enabled': config.get('optimization_config', {}).get('cache_enabled', True),
                    'parallel_processing': config.get('optimization_config', {}).get('parallel_processing', True),
                    'max_workers': config.get('optimization_config', {}).get('max_workers', 8),
                    # æƒé‡é…ç½® - ä»aggregatorä¸­æå–
                    'metadata_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('metadata_score', 0.30 if task_type == 'join' else 0.20),
                    'vector_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('vector_score', 0.40 if task_type == 'join' else 0.50),
                    'llm_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('llm_score', 0.30),
                    # å€¼ç›¸ä¼¼æ€§æƒé‡
                    'value_similarity_weight': task_config.get('llm_matcher', {}).get('value_similarity_weight', 0.5 if task_type == 'join' else 0.6),
                    # è¯­ä¹‰åŒ¹é…ï¼ˆUNIONç‰¹æœ‰ï¼‰
                    'semantic_matching': task_config.get('llm_matcher', {}).get('check_semantic_compatibility', task_type == 'union')
                }
                
                logger.info(f"âœ… åŠ è½½ä¸´æ—¶ä¼˜åŒ–é…ç½®ä» {temp_config_file}")
                logger.info(f"   å±‚ç»„åˆç­–ç•¥={flat_config.get('layer_combination')}")
                logger.info(f"   é˜ˆå€¼: meta={flat_config['metadata_threshold']:.3f}, vec={flat_config['vector_threshold']:.3f}, llm={flat_config['llm_confidence_threshold']:.3f}")
                logger.info(f"   æƒé‡: L1={flat_config['metadata_weight']:.2f}, L2={flat_config['vector_weight']:.2f}, L3={flat_config['llm_weight']:.2f}")
                return flat_config
                    
        except Exception as e:
            logger.warning(f"åŠ è½½ä¸´æ—¶é…ç½®å¤±è´¥: {e}ï¼Œå›é€€åˆ°é»˜è®¤é…ç½®")
    
    # é¦–å…ˆå°è¯•åŠ è½½é€šç”¨ä»»åŠ¡é…ç½®ï¼ˆç¬¬äºŒä¼˜å…ˆçº§ï¼‰
    universal_config_path = Path(f'config_{task_type}_universal.yml')
    if universal_config_path.exists():
        try:
            with open(universal_config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # æå–ä»»åŠ¡é…ç½®
            if 'task_configs' in config and task_type in config['task_configs']:
                task_config = config['task_configs'][task_type]
                
                # æ‰å¹³åŒ–é…ç½®ï¼Œæå–å…³é”®å‚æ•°
                flat_config = {
                    'llm_confidence_threshold': task_config.get('llm_matcher', {}).get('confidence_threshold', 0.05 if task_type == 'join' else 0.03),
                    'aggregator_max_results': task_config.get('aggregator', {}).get('max_results', 20 if task_type == 'join' else 30),
                    'llm_concurrency': 3,
                    'metadata_threshold': task_config.get('metadata_filter', {}).get('column_similarity_threshold', 0.25 if task_type == 'join' else 0.15),
                    'vector_threshold': task_config.get('vector_search', {}).get('similarity_threshold', 0.35 if task_type == 'join' else 0.25),
                    'min_column_overlap': task_config.get('metadata_filter', {}).get('min_column_overlap', 2 if task_type == 'join' else 1),
                    'vector_top_k': task_config.get('vector_search', {}).get('top_k', 60 if task_type == 'join' else 100),
                    'enable_llm': task_config.get('llm_matcher', {}).get('enable_llm', True),
                    # å±‚ç»„åˆç­–ç•¥ï¼ˆå…³é”®ï¼ï¼‰
                    'layer_combination': task_config.get('layer_combination', 'weighted_union' if task_type == 'join' else 'union'),
                    # JOINç‰¹å®šé…ç½®
                    'use_column_types': task_config.get('metadata_filter', {}).get('use_column_types', task_type == 'join'),
                    'use_value_overlap': task_config.get('metadata_filter', {}).get('use_value_overlap', task_type == 'join'),
                    'focus_on_join_keys': task_config.get('llm_matcher', {}).get('focus_on_join_keys', task_type == 'join'),
                    # UNIONç‰¹å®šé…ç½®
                    'allow_subset_matching': task_config.get('metadata_filter', {}).get('allow_subset_matching', task_type == 'union'),
                    'allow_type_coercion': task_config.get('metadata_filter', {}).get('allow_type_coercion', task_type == 'union'),
                    'allow_self_matches': task_config.get('metadata_filter', {}).get('allow_self_match', task_type == 'union'),
                    'focus_on_compatibility': task_config.get('llm_matcher', {}).get('focus_on_compatibility', task_type == 'union'),
                    'check_semantic_similarity': task_config.get('llm_matcher', {}).get('check_semantic_compatibility', task_type == 'union'),
                    'allow_partial_matches': task_config.get('llm_matcher', {}).get('allow_partial_matches', task_type == 'union'),
                    # å…¶ä»–ä¼˜åŒ–é…ç½®
                    'cache_enabled': config.get('optimization_config', {}).get('cache_enabled', True),
                    'parallel_processing': config.get('optimization_config', {}).get('parallel_processing', True),
                    'max_workers': config.get('optimization_config', {}).get('max_workers', 8),
                    # æƒé‡é…ç½® - ä»aggregatorä¸­æå–
                    'metadata_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('metadata_score', 0.30 if task_type == 'join' else 0.20),
                    'vector_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('vector_score', 0.40 if task_type == 'join' else 0.50),
                    'llm_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('llm_score', 0.30),
                    # å€¼ç›¸ä¼¼æ€§æƒé‡
                    'value_similarity_weight': task_config.get('llm_matcher', {}).get('value_similarity_weight', 0.5 if task_type == 'join' else 0.6),
                    # è¯­ä¹‰åŒ¹é…ï¼ˆUNIONç‰¹æœ‰ï¼‰
                    'semantic_matching': task_config.get('llm_matcher', {}).get('check_semantic_compatibility', task_type == 'union')
                }
                
                # è·å–è‡ªé€‚åº”è°ƒæ•´å› å­ï¼ˆå¦‚æœæœ‰æ•°æ®é›†ç±»å‹ï¼‰
                adaptive_factors = task_config.get('optimization_config', {}).get('adaptive_adjustment', {}).get('factors', {})
                if dataset_type and adaptive_factors.get('enable'):
                    # æ ¹æ®æ•°æ®é›†ç±»å‹åº”ç”¨è°ƒæ•´å› å­
                    adjustment_factor = 1.0
                    if dataset_type == 'nlctables':
                        adjustment_factor = adaptive_factors.get('high_quality_data', 1.2) if task_type == 'join' else adaptive_factors.get('clean_data', 1.1)
                    elif dataset_type == 'webtable':
                        adjustment_factor = adaptive_factors.get('noisy_data', 0.8) if task_type == 'join' else adaptive_factors.get('high_diversity', 0.8)
                    elif dataset_type == 'opendata':
                        adjustment_factor = adaptive_factors.get('medium_quality', 1.0) if task_type == 'join' else adaptive_factors.get('has_self_matches', 0.9)
                    
                    # åº”ç”¨è°ƒæ•´å› å­åˆ°é˜ˆå€¼
                    if adjustment_factor != 1.0:
                        flat_config['metadata_threshold'] *= adjustment_factor
                        flat_config['vector_threshold'] *= adjustment_factor
                        flat_config['llm_confidence_threshold'] *= adjustment_factor
                        logger.info(f"  ğŸ“Š åº”ç”¨{dataset_type}è‡ªé€‚åº”å› å­: {adjustment_factor:.1f}")
                
                logger.info(f"âœ… åŠ è½½{task_type.upper()}é€šç”¨é…ç½®ä»config_{task_type}_universal.yml")
                logger.info(f"   å±‚ç»„åˆç­–ç•¥={flat_config.get('layer_combination')}")
                logger.info(f"   LLMé˜ˆå€¼={flat_config['llm_confidence_threshold']:.3f}, å…ƒæ•°æ®é˜ˆå€¼={flat_config['metadata_threshold']:.2f}")
                logger.info(f"   å‘é‡é˜ˆå€¼={flat_config['vector_threshold']:.2f}, æœ€å¤§ç»“æœ={flat_config['aggregator_max_results']}")
                logger.info(f"   æƒé‡åˆ†é…: å…ƒæ•°æ®={flat_config['metadata_weight']:.1f}, å‘é‡={flat_config['vector_weight']:.1f}, LLM={flat_config['llm_weight']:.1f}")
                if dataset_type:
                    logger.info(f"   æ•°æ®é›†: {dataset_type}")
                return flat_config
                    
        except Exception as e:
            logger.warning(f"åŠ è½½{task_type}é€šç”¨é…ç½®å¤±è´¥: {e}ï¼Œå°è¯•å…¶ä»–é…ç½®")
    
    # å¦‚æœé€šç”¨é…ç½®ä¸å­˜åœ¨ï¼Œå°è¯•æ•°æ®é›†ç‰¹å®šé…ç½®
    if dataset_type:
        dataset_task_config_path = Path(f'config_{dataset_type}_{task_type}.yml')
        if dataset_task_config_path.exists():
            try:
                with open(dataset_task_config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                
                # æå–ä»»åŠ¡é…ç½®ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
                if 'task_configs' in config and task_type in config['task_configs']:
                    task_config = config['task_configs'][task_type]
                    
                    # æ‰å¹³åŒ–é…ç½®
                    flat_config = {
                        'llm_confidence_threshold': task_config.get('llm_matcher', {}).get('confidence_threshold', 0.10 if task_type == 'join' else 0.05),
                        'aggregator_max_results': task_config.get('aggregator', {}).get('max_results', 20 if task_type == 'join' else 30),
                        'llm_concurrency': 3,
                        'metadata_threshold': task_config.get('metadata_filter', {}).get('column_similarity_threshold', 0.35 if task_type == 'join' else 0.20),
                        'vector_threshold': task_config.get('vector_search', {}).get('similarity_threshold', 0.40 if task_type == 'join' else 0.35),
                        'min_column_overlap': task_config.get('metadata_filter', {}).get('min_column_overlap', 2 if task_type == 'join' else 1),
                        'vector_top_k': task_config.get('vector_search', {}).get('top_k', 50 if task_type == 'join' else 60),
                        'enable_llm': task_config.get('llm_matcher', {}).get('enable_llm', True),
                        'layer_combination': task_config.get('layer_combination', 'intersection'),
                        'use_column_types': task_config.get('metadata_filter', {}).get('use_column_types', task_type == 'join'),
                        'use_value_overlap': task_config.get('metadata_filter', {}).get('use_value_overlap', task_type == 'join'),
                        'focus_on_join_keys': task_config.get('llm_matcher', {}).get('focus_on_join_keys', task_type == 'join'),
                        'allow_subset_matching': task_config.get('metadata_filter', {}).get('allow_subset_matching', task_type == 'union'),
                        'allow_type_coercion': task_config.get('metadata_filter', {}).get('allow_type_coercion', task_type == 'union'),
                        'allow_self_matches': task_config.get('llm_matcher', {}).get('allow_self_matches', task_type == 'union'),
                        'focus_on_compatibility': task_config.get('llm_matcher', {}).get('focus_on_compatibility', task_type == 'union'),
                        'check_semantic_similarity': task_config.get('llm_matcher', {}).get('check_semantic_similarity', task_type == 'union'),
                        'allow_partial_matches': task_config.get('llm_matcher', {}).get('allow_partial_matches', task_type == 'union'),
                        'cache_enabled': config.get('optimization_config', {}).get('cache_enabled', True),
                        'parallel_processing': config.get('optimization_config', {}).get('parallel_processing', True),
                        'max_workers': config.get('optimization_config', {}).get('max_workers', 4),
                        'metadata_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('metadata_score', 0.25 if task_type == 'join' else 0.20),
                        'vector_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('vector_score', 0.35 if task_type == 'join' else 0.40),
                        'llm_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('llm_score', 0.40),
                        'value_similarity_weight': task_config.get('llm_matcher', {}).get('value_similarity_weight', 0.5)
                    }
                    
                    logger.info(f"âœ… åŠ è½½{dataset_type.upper()} {task_type.upper()}é…ç½®ä»config_{dataset_type}_{task_type}.yml")
                    logger.info(f"   å±‚ç»„åˆç­–ç•¥={flat_config.get('layer_combination')}")
                    logger.info(f"   LLMé˜ˆå€¼={flat_config['llm_confidence_threshold']:.3f}, å…ƒæ•°æ®é˜ˆå€¼={flat_config['metadata_threshold']:.2f}")
                    return flat_config
                    
            except Exception as e:
                logger.warning(f"åŠ è½½{dataset_type} {task_type}ç‰¹å®šé…ç½®å¤±è´¥: {e}ï¼Œå°è¯•ä»»åŠ¡é…ç½®")
    
    # å°è¯•åŠ è½½ä»»åŠ¡ç‰¹å®šçš„é…ç½®æ–‡ä»¶
    task_config_path = Path(f'config_{task_type}_optimized.yml')
    if task_config_path.exists():
        try:
            with open(task_config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # æå–ä»»åŠ¡é…ç½®ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
            if 'task_configs' in config and task_type in config['task_configs']:
                task_config = config['task_configs'][task_type]
                
                flat_config = {
                    'llm_confidence_threshold': task_config.get('llm_matcher', {}).get('confidence_threshold', 0.10 if task_type == 'join' else 0.05),
                    'aggregator_max_results': task_config.get('aggregator', {}).get('max_results', 20 if task_type == 'join' else 30),
                    'llm_concurrency': 3,
                    'metadata_threshold': task_config.get('metadata_filter', {}).get('column_similarity_threshold', 0.35 if task_type == 'join' else 0.20),
                    'vector_threshold': task_config.get('vector_search', {}).get('similarity_threshold', 0.40 if task_type == 'join' else 0.35),
                    'min_column_overlap': task_config.get('metadata_filter', {}).get('min_column_overlap', 2 if task_type == 'join' else 1),
                    'vector_top_k': task_config.get('vector_search', {}).get('top_k', 50 if task_type == 'join' else 60),
                    'enable_llm': task_config.get('llm_matcher', {}).get('enable_llm', True),
                    'layer_combination': 'intersection',
                    'use_column_types': task_config.get('metadata_filter', {}).get('use_column_types', task_type == 'join'),
                    'use_value_overlap': task_config.get('metadata_filter', {}).get('use_value_overlap', task_type == 'join'),
                    'focus_on_join_keys': task_config.get('llm_matcher', {}).get('focus_on_join_keys', task_type == 'join'),
                    'allow_subset_matching': task_config.get('metadata_filter', {}).get('allow_subset_matching', task_type == 'union'),
                    'allow_type_coercion': task_config.get('metadata_filter', {}).get('allow_type_coercion', task_type == 'union'),
                    'allow_self_matches': task_config.get('llm_matcher', {}).get('allow_self_matches', task_type == 'union'),
                    'focus_on_compatibility': task_config.get('llm_matcher', {}).get('focus_on_compatibility', task_type == 'union'),
                    'check_semantic_similarity': task_config.get('llm_matcher', {}).get('check_semantic_similarity', task_type == 'union'),
                    'allow_partial_matches': task_config.get('llm_matcher', {}).get('allow_partial_matches', task_type == 'union'),
                    'cache_enabled': config.get('optimization_config', {}).get('cache_enabled', True),
                    'parallel_processing': config.get('optimization_config', {}).get('parallel_processing', True),
                    'max_workers': config.get('optimization_config', {}).get('max_workers', 4),
                    'metadata_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('metadata_score', 0.25 if task_type == 'join' else 0.20),
                    'vector_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('vector_score', 0.35 if task_type == 'join' else 0.40),
                    'llm_weight': task_config.get('aggregator', {}).get('ranking_weights', {}).get('llm_score', 0.40)
                }
                
                logger.info(f"âœ… åŠ è½½{task_type.upper()}ä»»åŠ¡ç‰¹å®šé…ç½®ä»config_{task_type}_optimized.yml")
                return flat_config
                
        except Exception as e:
            logger.warning(f"åŠ è½½{task_type}ç‰¹å®šé…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    
    # ä½¿ç”¨é»˜è®¤é…ç½®
    logger.warning(f"æ‰€æœ‰é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤{task_type}é…ç½®")
    if task_type == 'join':
        return {
            'llm_confidence_threshold': 0.10,
            'aggregator_max_results': 500,
            'llm_concurrency': 3,
            'metadata_threshold': 0.40,
            'vector_threshold': 0.45,
            'min_column_overlap': 3,
            'vector_top_k': 100,
            'layer_combination': 'intersection'
        }
    else:  # union
        return {
            'llm_confidence_threshold': 0.30,
            'aggregator_max_results': 200,
            'llm_concurrency': 3,
            'metadata_threshold': 0.25,
            'vector_threshold': 0.25,
            'min_column_overlap': 1,
            'vector_top_k': 150,
            'include_query_variants': True,
            'allow_prefix_match': True,
            'layer_combination': 'intersection'
        }


# ================== ç¼“å­˜ç®¡ç†å™¨ ==================
class CacheManager:
    """ç»Ÿä¸€çš„ç¼“å­˜ç®¡ç†å™¨ï¼Œæä¾›å†…å­˜å’Œç£ç›˜åŒå±‚ç¼“å­˜"""
    
    def __init__(self, cache_dir: str = "cache/experiment_cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.memory_cache = {}  # å†…å­˜ç¼“å­˜
        self.stats = {
            'hits': 0,
            'misses': 0,
            'saves': 0
        }
        logger.info(f"âœ… ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–: {self.cache_dir}")
    
    def _get_cache_key(self, operation: str, query: Dict, params: Dict = None) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = {
            'op': operation,
            'query': query.get('query_table', '') if isinstance(query, dict) else str(query),
            'params': params or {}
        }
        key_str = json.dumps(key_data, sort_keys=True)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, operation: str, query: Dict, params: Dict = None) -> Optional[Any]:
        """è·å–ç¼“å­˜ç»“æœ"""
        cache_key = self._get_cache_key(operation, query, params)
        
        # å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache:
            self.stats['hits'] += 1
            return self.memory_cache[cache_key]
        
        # æ£€æŸ¥ç£ç›˜ç¼“å­˜
        cache_file = self.cache_dir / f"{operation}_{cache_key}.pkl"
        if cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    result = pickle.load(f)
                    self.memory_cache[cache_key] = result  # åŠ è½½åˆ°å†…å­˜
                    self.stats['hits'] += 1
                    return result
            except:
                pass
        
        self.stats['misses'] += 1
        return None
    
    def set(self, operation: str, query: Dict, result: Any, params: Dict = None):
        """ä¿å­˜ç¼“å­˜ç»“æœ"""
        cache_key = self._get_cache_key(operation, query, params)
        
        # ä¿å­˜åˆ°å†…å­˜ç¼“å­˜
        self.memory_cache[cache_key] = result
        
        # ä¿å­˜åˆ°ç£ç›˜ç¼“å­˜
        cache_file = self.cache_dir / f"{operation}_{cache_key}.pkl"
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
            self.stats['saves'] += 1
        except Exception as e:
            logger.warning(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def get_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total = self.stats['hits'] + self.stats['misses']
        hit_rate = self.stats['hits'] / total if total > 0 else 0
        return {
            'hits': self.stats['hits'],
            'misses': self.stats['misses'],
            'saves': self.stats['saves'],
            'hit_rate': f"{hit_rate:.1%}",
            'memory_items': len(self.memory_cache)
        }
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.memory_cache.clear()
        for cache_file in self.cache_dir.glob("*.pkl"):
            cache_file.unlink()
        logger.info("ç¼“å­˜å·²æ¸…ç©º")


# å…¨å±€ç¼“å­˜ç®¡ç†å™¨
cache_manager = None

def init_cache_manager(dataset_name: str = '', task_type: str = '', dataset_type: str = ''):
    """åˆå§‹åŒ–å…¨å±€ç¼“å­˜ç®¡ç†å™¨"""
    global cache_manager
    if cache_manager is None:
        cache_dir = f"cache/experiment_cache/{dataset_name}_{task_type}_{dataset_type}".strip('_')
        cache_manager = CacheManager(cache_dir)
    return cache_manager


def load_dataset(task_type: str, dataset_type: str = 'subset', dataset_name: str = None) -> tuple:
    """åŠ è½½æ•°æ®é›†ï¼ˆæ”¯æŒå¤šç§æ•°æ®é›†æ ¼å¼ï¼‰
    
    Args:
        task_type: 'join' æˆ– 'union'
        dataset_type: 'subset', 'true_subset', 'complete', 'full' ç­‰
        dataset_name: 'nlctables', 'opendata', 'webtable' æˆ– None
    """
    # å¦‚æœdataset_nameæœªæŒ‡å®šï¼Œå°è¯•ä»dataset_typeè§£æ
    if dataset_name is None:
        if 'nlctables' in dataset_type.lower():
            dataset_name = 'nlctables'
        elif 'opendata' in dataset_type.lower():
            dataset_name = 'opendata'
        elif 'webtable' in dataset_type.lower():
            dataset_name = 'webtable'
    
    # ç‰¹æ®Šå¤„ç†NLCTables adapterï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if dataset_name == 'nlctables':
        try:
            from nlctables_adapter import NLCTablesAdapter
            adapter = NLCTablesAdapter()
            
            # è§£æsubsetç±»å‹
            if 'complete' in dataset_type:
                subset_type = 'complete'
            else:
                subset_type = 'subset'
            
            # ä½¿ç”¨é€‚é…å™¨åŠ è½½æ•°æ®
            tables, queries, ground_truth = adapter.load_nlctables_dataset(task_type, subset_type)
            
            logger.info(f"ğŸ“Š Loaded NLCTables dataset via adapter: {len(tables)} tables, {len(queries)} queries")
            return tables, queries, ground_truth
        except ImportError:
            # å¦‚æœé€‚é…å™¨ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ ‡å‡†è·¯å¾„
            pass
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªå®šä¹‰è·¯å¾„
    if '/' in dataset_type or dataset_type.startswith('examples'):
        # ç›´æ¥ä½¿ç”¨æä¾›çš„è·¯å¾„
        base_dir = Path(dataset_type)
    else:
        # æ„å»ºæ ‡å‡†è·¯å¾„æ ¼å¼
        # æ–°æ ¼å¼ï¼šexamples/{dataset_name}/{task}_{dataset_type}/
        if dataset_name:
            # è§„èŒƒåŒ–dataset_type
            if dataset_type in ['complete', 'full']:
                subset_str = 'complete'
            elif dataset_type in ['subset', 'true_subset']:
                subset_str = 'subset'
            else:
                subset_str = dataset_type
            
            base_dir = Path(f'examples/{dataset_name}/{task_type}_{subset_str}')
            
            # å¦‚æœæ–°æ ¼å¼ä¸å­˜åœ¨ï¼Œå°è¯•æ—§æ ¼å¼
            if not base_dir.exists():
                logger.info(f"æ–°æ ¼å¼è·¯å¾„ä¸å­˜åœ¨: {base_dir}, å°è¯•æ—§æ ¼å¼...")
                # æ—§æ ¼å¼ï¼šexamples/separated_datasets/{task}_{subset}/
                if dataset_type == 'complete' or dataset_type == 'full':
                    base_dir = Path(f'examples/separated_datasets/{task_type}')
                elif dataset_type == 'true_subset':
                    base_dir = Path(f'examples/separated_datasets/{task_type}_true_subset')
                elif dataset_type == 'subset':
                    base_dir = Path(f'examples/separated_datasets/{task_type}_subset')
                else:
                    base_dir = Path(f'examples/separated_datasets/{task_type}_{dataset_type}')
        else:
            # å…¼å®¹æ—§æ ¼å¼
            if dataset_type == 'complete' or dataset_type == 'full':
                base_dir = Path(f'examples/separated_datasets/{task_type}')
            elif dataset_type == 'true_subset':
                base_dir = Path(f'examples/separated_datasets/{task_type}_true_subset')
            elif dataset_type == 'subset':
                base_dir = Path(f'examples/separated_datasets/{task_type}_subset')
            else:
                base_dir = Path(f'examples/separated_datasets/{task_type}_{dataset_type}')
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not base_dir.exists():
        raise FileNotFoundError(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {base_dir}")
    
    # åŠ è½½æ–‡ä»¶
    with open(base_dir / 'tables.json', 'r') as f:
        tables = json.load(f)
    with open(base_dir / 'queries.json', 'r') as f:
        queries = json.load(f)
    with open(base_dir / 'ground_truth.json', 'r') as f:
        ground_truth = json.load(f)
    
    # ç¡®ä¿æ‰€æœ‰è¡¨æœ‰nameå­—æ®µ
    for t in tables:
        if 'name' not in t and 'table_name' in t:
            t['name'] = t['table_name']
    
    logger.info(f"ğŸ“Š Loaded dataset from {base_dir}: {len(tables)} tables, {len(queries)} queries")
    return tables, queries, ground_truth


def convert_ground_truth_format(ground_truth_list: List[Dict], task_type: str = None) -> Dict[str, List[str]]:
    """å°†ground truthè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
    
    Args:
        ground_truth_list: ground truthåˆ—è¡¨
        task_type: ä»»åŠ¡ç±»å‹ ('join' æˆ– 'union')ï¼Œå¦‚æœä¸ºNoneåˆ™æ ¹æ®å†…å®¹æ¨æ–­
    """
    query_to_candidates = {}
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»åŠ¡ç±»å‹ï¼Œå°è¯•æ¨æ–­
    if task_type is None:
        # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªåŒ¹é…çš„æƒ…å†µæ¥æ¨æ–­æ˜¯å¦ä¸ºUNIONä»»åŠ¡
        has_self_match = any(
            item.get('query_table', '') == item.get('candidate_table', '')
            for item in ground_truth_list
            if item.get('query_table') and item.get('candidate_table')
        )
        # å¦‚æœæœ‰è‡ªåŒ¹é…ï¼Œå¾ˆå¯èƒ½æ˜¯UNIONä»»åŠ¡
        task_type = 'union' if has_self_match else 'join'
    
    for item in ground_truth_list:
        query_table = item.get('query_table', '')
        
        # å¤„ç†ä¸¤ç§æ ¼å¼ï¼š
        # æ ¼å¼1: {'query_table': 'xxx', 'candidate_table': 'yyy'} (åŸæ ¼å¼)
        # æ ¼å¼2: {'query_table': 'xxx', 'ground_truth': ['yyy', 'zzz']} (NLCTablesæ ¼å¼)
        
        if 'ground_truth' in item and isinstance(item['ground_truth'], list):
            # NLCTablesæ ¼å¼ï¼šç›´æ¥ä½¿ç”¨ground_truthåˆ—è¡¨
            if query_table:
                candidates = item['ground_truth']
                # å¯¹äºJOINä»»åŠ¡ï¼Œè¿‡æ»¤è‡ªåŒ¹é…ï¼›å¯¹äºUNIONä»»åŠ¡ï¼Œä¿ç•™è‡ªåŒ¹é…
                if task_type == 'union':
                    query_to_candidates[query_table] = candidates
                else:  # join
                    query_to_candidates[query_table] = [c for c in candidates if c != query_table]
        
        elif 'candidate_table' in item:
            # åŸå§‹æ ¼å¼ï¼šé€ä¸ªæ·»åŠ å€™é€‰è¡¨
            candidate_table = item.get('candidate_table', '')
            if query_table and candidate_table:
                # å¯¹äºJOINä»»åŠ¡ï¼Œè¿‡æ»¤è‡ªåŒ¹é…ï¼›å¯¹äºUNIONä»»åŠ¡ï¼Œä¿ç•™è‡ªåŒ¹é…
                if task_type == 'union' or query_table != candidate_table:
                    if query_table not in query_to_candidates:
                        query_to_candidates[query_table] = []
                    query_to_candidates[query_table].append(candidate_table)
    
    return query_to_candidates


def initialize_shared_resources_l1(tables: List[Dict], dataset_type: str, task_type: str = None) -> Dict:
    """åˆå§‹åŒ–L1å±‚å…±äº«èµ„æºï¼ˆæ”¯æŒä»»åŠ¡ç‰¹å®šé…ç½®ï¼‰"""
    logger.info("ğŸš€ åˆå§‹åŒ–L1å±‚å…±äº«èµ„æº...")
    
    from src.tools.smd_enhanced_metadata_filter import SMDEnhancedMetadataFilter
    
    # å¯¹äºOpenDataï¼Œç¡®ä¿è¡¨æœ‰nameå­—æ®µï¼ˆå…¼å®¹æ€§ï¼‰
    if dataset_type == 'opendata':
        for t in tables:
            if 'name' not in t and 'table_name' in t:
                t['name'] = t['table_name']
    
    # å¦‚æœæä¾›äº†ä»»åŠ¡ç±»å‹ï¼ŒåŠ è½½ä»»åŠ¡ç‰¹å®šé…ç½®
    task_config = {}
    if task_type:
        task_config = load_task_config(task_type)
        logger.info(f"  ğŸ“‹ L1ä½¿ç”¨{task_type.upper()}é…ç½®: é˜ˆå€¼={task_config.get('metadata_threshold', 0.30):.2f}")
    
    # åˆå§‹åŒ–å…ƒæ•°æ®è¿‡æ»¤å™¨å¹¶é¢„æ„å»ºç´¢å¼•
    metadata_filter = SMDEnhancedMetadataFilter()
    
    # é¢„æ„å»ºSMDç´¢å¼•ï¼ˆåªæ„å»ºä¸€æ¬¡ï¼Œæ‰€æœ‰æŸ¥è¯¢å…±äº«ï¼‰
    logger.info(f"ğŸ“Š é¢„æ„å»ºSMDç´¢å¼•ï¼ˆ{len(tables)}ä¸ªè¡¨ï¼‰...")
    metadata_filter.build_index(tables)
    
    # åºåˆ—åŒ–ç´¢å¼•ä»¥ä¾¿åœ¨è¿›ç¨‹é—´å…±äº«
    smd_index_serialized = pickle.dumps(metadata_filter)
    logger.info(f"âœ… SMDç´¢å¼•æ„å»ºå®Œæˆï¼Œå¤§å°: {len(smd_index_serialized) / 1024:.1f}KB")
    
    config = {
        'layer': 'L1',
        'table_count': len(tables),
        'dataset_type': dataset_type,
        'filter_initialized': True,
        'smd_index': smd_index_serialized,  # æ·»åŠ åºåˆ—åŒ–çš„ç´¢å¼•
        'task_config': task_config  # æ·»åŠ ä»»åŠ¡é…ç½®
    }
    
    logger.info("âœ… L1å±‚èµ„æºåˆå§‹åŒ–å®Œæˆ")
    return config


def initialize_shared_resources_l2(tables: List[Dict], dataset_type: str, task_type: str = None) -> Dict:
    """åˆå§‹åŒ–L1+L2å±‚å…±äº«èµ„æºï¼ˆæ”¯æŒä»»åŠ¡ç‰¹å®šé…ç½®ï¼‰"""
    logger.info("ğŸš€ åˆå§‹åŒ–L1+L2å±‚å…±äº«èµ„æº...")
    
    # å¦‚æœæä¾›äº†ä»»åŠ¡ç±»å‹ï¼ŒåŠ è½½ä»»åŠ¡ç‰¹å®šé…ç½®
    task_config = {}
    if task_type:
        task_config = load_task_config(task_type, dataset_type)  # ä¼ é€’dataset_type
        logger.info(f"  ğŸ“‹ L2ä½¿ç”¨{task_type.upper()}é…ç½®: å‘é‡é˜ˆå€¼={task_config.get('vector_threshold', 0.30):.2f}, top_k={task_config.get('vector_top_k', 100)}")
        logger.info(f"  ğŸ“‹ å±‚ç»„åˆç­–ç•¥: {task_config.get('layer_combination', 'intersection')}")
    
    # å¯¹äºOpenDataï¼Œç¡®ä¿è¡¨æœ‰nameå­—æ®µï¼ˆå…¼å®¹æ€§ï¼‰
    if dataset_type == 'opendata':
        for t in tables:
            if 'name' not in t and 'table_name' in t:
                t['name'] = t['table_name']
    
    # é¢„è®¡ç®—å‘é‡ç´¢å¼•
    cache_dir = Path("cache") / dataset_type
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    index_file = cache_dir / f"vector_index_{len(tables)}.pkl"
    embeddings_file = cache_dir / f"table_embeddings_{len(tables)}.pkl"
    
    if not (index_file.exists() and embeddings_file.exists()):
        logger.info("âš™ï¸ ç”Ÿæˆæ–°çš„å‘é‡ç´¢å¼•...")
        from precompute_embeddings import precompute_all_embeddings
        precompute_all_embeddings(tables, dataset_type)
    
    config = {
        'layer': 'L1+L2',
        'table_count': len(tables),
        'dataset_type': dataset_type,
        'vector_index_path': str(index_file),
        'embeddings_path': str(embeddings_file),
        'filter_initialized': True,
        'vector_initialized': True,
        'task_config': task_config,  # æ·»åŠ ä»»åŠ¡é…ç½®
        'optimization_config': task_config  # ä¹Ÿä½œä¸ºoptimization_configä¼ é€’
    }
    
    logger.info("âœ… L1+L2å±‚èµ„æºåˆå§‹åŒ–å®Œæˆ")
    return config


def initialize_shared_resources_l3(tables: List[Dict], task_type: str, dataset_type: str) -> Dict:
    """åˆå§‹åŒ–å®Œæ•´ä¸‰å±‚å…±äº«èµ„æºï¼ˆåŒ…å«ä»»åŠ¡ç‰¹å®šçš„ä¼˜åŒ–é…ç½®ï¼‰"""
    logger.info("ğŸš€ åˆå§‹åŒ–L1+L2+L3å±‚å…±äº«èµ„æº...")
    
    # å¯¹äºOpenDataï¼Œç¡®ä¿è¡¨æœ‰nameå­—æ®µï¼ˆå…¼å®¹æ€§ï¼‰
    if dataset_type == 'opendata':
        for t in tables:
            if 'name' not in t and 'table_name' in t:
                t['name'] = t['table_name']
    
    # åˆå§‹åŒ–L1+L2èµ„æºï¼ˆä¼ é€’task_typeï¼‰
    l2_config = initialize_shared_resources_l2(tables, dataset_type, task_type)
    
    # ä»é…ç½®æ–‡ä»¶åŠ è½½ä»»åŠ¡ç‰¹å®šçš„é…ç½®ï¼ˆä¼ é€’dataset_typeï¼‰
    task_config = load_task_config(task_type, dataset_type)
    
    # åˆ›å»ºä¼˜åŒ–é…ç½®å­—å…¸
    optimization_config = {
        'llm_confidence_threshold': task_config['llm_confidence_threshold'],
        'aggregator_max_results': task_config['aggregator_max_results'],
        'llm_concurrency': task_config.get('llm_concurrency', 3),
        'metadata_threshold': task_config.get('metadata_threshold', 0.30),
        'vector_threshold': task_config.get('vector_threshold', 0.30),
        'min_column_overlap': task_config.get('min_column_overlap', 2),
        'vector_top_k': task_config.get('vector_top_k', 100),
        'enable_llm': task_config.get('enable_llm', True),
        # å±‚ç»„åˆç­–ç•¥ï¼ˆå…³é”®ï¼ï¼‰
        'layer_combination': task_config.get('layer_combination', 'intersection'),
        # UNIONç‰¹å®šé…ç½®
        'include_query_variants': task_config.get('include_query_variants', False),
        'allow_prefix_match': task_config.get('allow_prefix_match', False),
        'semantic_matching': task_config.get('semantic_matching', False),
        'value_similarity_weight': task_config.get('value_similarity_weight', 0.5)
    }
    
    # åˆå§‹åŒ–å·¥ä½œæµï¼ˆè·å–ä¼˜åŒ–é…ç½®ï¼‰
    from src.core.langgraph_workflow import DataLakeDiscoveryWorkflow
    workflow = DataLakeDiscoveryWorkflow()
    
    # å¦‚æœéœ€è¦åŸå§‹OptimizerAgentçš„å…¶ä»–åŠŸèƒ½ï¼Œä»ç„¶è°ƒç”¨å®ƒ
    # ä½†ä½¿ç”¨ä»»åŠ¡ç‰¹å®šçš„é…ç½®è¦†ç›–å…¶é»˜è®¤è®¾ç½®
    from src.agents.optimizer_agent import OptimizerAgent
    from types import SimpleNamespace
    optimizer = OptimizerAgent()
    
    # åˆ›å»ºæ­£ç¡®çš„stateæ ¼å¼ï¼ŒOptimizerAgentæœŸæœ›query_taskå¯¹è±¡
    query_task = SimpleNamespace(task_type=task_type)
    state = {
        'query_task': query_task,
        'all_tables': tables
    }
    
    # è·å–åŸå§‹é…ç½®å¹¶ä¸ä»»åŠ¡ç‰¹å®šé…ç½®åˆå¹¶
    result = optimizer.process(state)
    original_config = result.get('optimization_config', {})
    
    # å¦‚æœoriginal_configä¸æ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºå­—å…¸
    if hasattr(original_config, '__dict__'):
        original_config = original_config.__dict__
    elif not isinstance(original_config, dict):
        original_config = {}
    
    # åˆå¹¶é…ç½®ï¼Œä»»åŠ¡ç‰¹å®šé…ç½®ä¼˜å…ˆ
    merged_config = {**original_config, **optimization_config}
    
    # è·å–æ‰¹å¤„ç†æ‰§è¡Œç­–ç•¥ï¼ˆåªè°ƒç”¨ä¸€æ¬¡PlannerAgentï¼‰
    from src.agents.planner_agent import PlannerAgent
    planner = PlannerAgent()
    execution_strategy = planner.process({
        'task_type': task_type,
        'table_structure': 'unknown',
        'data_size': 'medium',
        'performance_requirement': 'balanced'
    })
    
    config = {
        **l2_config,
        'layer': 'L1+L2+L3',
        'optimization_config': merged_config,
        'execution_strategy': execution_strategy,
        'task_type': task_type,
        'workflow_initialized': True
    }
    
    config_source = f"config_{dataset_type}_{task_type}.yml" if Path(f'config_{dataset_type}_{task_type}.yml').exists() else \
                    f"config_{task_type}_optimized.yml" if Path(f'config_{task_type}_optimized.yml').exists() else \
                    "config_optimized.yml"
    
    logger.info(f"âœ… L1+L2+L3å±‚èµ„æºåˆå§‹åŒ–å®Œæˆ - {task_type.upper()}ä»»åŠ¡ä¼˜åŒ–")
    logger.info(f"  - é…ç½®é˜ˆå€¼: {optimization_config['llm_confidence_threshold']:.3f}")
    logger.info(f"  - å±‚ç»„åˆç­–ç•¥: {optimization_config['layer_combination']}")
    logger.info(f"  - æœ€å¤§å€™é€‰: {optimization_config['aggregator_max_results']}")
    logger.info(f"  - é…ç½®æ¥æº: {config_source}")
    
    return config


def process_query_l1(args: Tuple) -> Dict:
    """å¤„ç†å•ä¸ªæŸ¥è¯¢ - L1å±‚"""
    query, tables, shared_config, cache_file_path = args
    query_table_name = query.get('query_table', '')
    
    # åˆå§‹åŒ–æˆ–è·å–ç¼“å­˜ç®¡ç†å™¨ï¼ˆå­è¿›ç¨‹éœ€è¦ï¼‰
    global cache_manager
    if cache_manager is None and cache_file_path:
        # cache_file_pathç°åœ¨æ˜¯ç¼“å­˜ç›®å½•è·¯å¾„
        cache_dir = cache_file_path
        cache_manager = CacheManager(cache_dir)
    
    # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨
    if cache_manager:
        cached = cache_manager.get('l1', query)
        if cached is not None:
            return cached
    
    # ä½¿ç”¨é¢„æ„å»ºçš„SMDç´¢å¼•ï¼ˆé€šè¿‡pickleåºåˆ—åŒ–ï¼‰
    if 'smd_index' in shared_config:
        # ååºåˆ—åŒ–SMDç´¢å¼•
        import io
        from src.tools.smd_enhanced_metadata_filter import SMDEnhancedMetadataFilter
        metadata_filter = pickle.loads(shared_config['smd_index'])
    else:
        # é™çº§ï¼šæ„å»ºæ–°ç´¢å¼•ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰
        from src.tools.smd_enhanced_metadata_filter import SMDEnhancedMetadataFilter
        metadata_filter = SMDEnhancedMetadataFilter()
        metadata_filter.build_index(tables)
    
    # æŸ¥æ‰¾æŸ¥è¯¢è¡¨ - å…¼å®¹ä¸åŒæ•°æ®é›†çš„å­—æ®µå
    query_table = None
    for t in tables:
        # å…¼å®¹ 'name' (NLCTables) å’Œ 'table_name' (OpenData/WebTable)
        table_name = t.get('name') or t.get('table_name')
        if table_name == query_table_name:
            query_table = t
            break
    
    if not query_table:
        logger.warning(f"Query table {query_table_name} not found in tables")
        result = {'query_table': query_table_name, 'predictions': []}
    else:
        # L1: å…ƒæ•°æ®è¿‡æ»¤ - ä½¿ç”¨é¢„æ„å»ºçš„ç´¢å¼•
        # NLCTableséœ€è¦æ›´ä½çš„é˜ˆå€¼å’Œæ›´å¤šå€™é€‰ä»¥æé«˜å¬å›ç‡
        # è®©é˜ˆå€¼è‡ªç„¶æ§åˆ¶å€™é€‰æ•°é‡ï¼Œä¸è®¾ç½®max_candidatesé™åˆ¶
        logger.debug(f"Filtering candidates for {query_table_name}")
        candidates = metadata_filter.filter_candidates(
            query_table,
            None,  # all_tables - Noneè¡¨ç¤ºä½¿ç”¨é¢„æ„å»ºçš„ç´¢å¼•
            threshold=0.05,  # NLCTableséœ€è¦æ›´ä½çš„é˜ˆå€¼ä»¥æé«˜å¬å›ç‡
            max_candidates=1000  # è®¾ç½®ä¸€ä¸ªå¾ˆé«˜çš„ä¸Šé™ï¼Œå®é™…ç”±é˜ˆå€¼æ§åˆ¶
        )
        
        logger.debug(f"L1 found {len(candidates)} candidates")
        # å€™é€‰æ ¼å¼æ˜¯[(table_name, score), ...]ï¼Œæå–è¡¨å
        predictions = [
            table_name for table_name, score in candidates 
            if table_name != query_table_name
        ][:MAX_PREDICTIONS]
        
        logger.debug(f"L1 final predictions: {len(predictions)}")
        result = {'query_table': query_table_name, 'predictions': predictions}
    
    # ä¿å­˜åˆ°å…¨å±€ç¼“å­˜
    if cache_manager:
        cache_manager.set('l1', query, result)
    
    return result


def process_query_l2(args: Tuple) -> Dict:
    """å¤„ç†å•ä¸ªæŸ¥è¯¢ - L1+L2å±‚ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ”¯æŒUNION/INTERSECTIONç»„åˆç­–ç•¥ï¼‰"""
    query, tables, shared_config, cache_file_path = args
    query_table_name = query.get('query_table', '')
    task_type = query.get('task_type', 'join')  # è·å–ä»»åŠ¡ç±»å‹
    dataset_type = query.get('dataset_type', '')  # è·å–æ•°æ®é›†ç±»å‹
    
    # åˆå§‹åŒ–æˆ–è·å–ç¼“å­˜ç®¡ç†å™¨ï¼ˆå­è¿›ç¨‹éœ€è¦ï¼‰
    global cache_manager
    if cache_manager is None and cache_file_path:
        # cache_file_pathç°åœ¨æ˜¯ç¼“å­˜ç›®å½•è·¯å¾„
        cache_dir = cache_file_path
        cache_manager = CacheManager(cache_dir)
    
    # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨
    if cache_manager:
        cached = cache_manager.get('l1_l2', query, {'task_type': task_type})
        if cached is not None:
            return cached
    
    # è·å–é…ç½®ï¼ˆåŒ…æ‹¬å±‚ç»„åˆç­–ç•¥ï¼‰
    task_config = shared_config.get('optimization_config', {})
    layer_combination = task_config.get('layer_combination', 'intersection')
    
    # è¿è¡ŒL1+L2å±‚
    from src.tools.smd_enhanced_metadata_filter import SMDEnhancedMetadataFilter
    from src.tools.vector_search_tool import VectorSearchTool
    from src.tools.value_similarity_tool import ValueSimilarityTool
    
    metadata_filter = SMDEnhancedMetadataFilter()
    vector_search = VectorSearchTool()
    value_similarity = ValueSimilarityTool()
    
    # æŸ¥æ‰¾æŸ¥è¯¢è¡¨ - å…¼å®¹ä¸åŒæ•°æ®é›†çš„å­—æ®µå
    query_table = None
    for t in tables:
        # å…¼å®¹ 'name' (NLCTables) å’Œ 'table_name' (OpenData/WebTable)
        table_name = t.get('name') or t.get('table_name')
        if table_name == query_table_name:
            query_table = t
            break
    
    if not query_table:
        result = {'query_table': query_table_name, 'predictions': []}
    else:
        # L1: å…ƒæ•°æ®è¿‡æ»¤ï¼ˆæ‰©å¤§å€™é€‰é›†ï¼‰
        # å¯¹äºOpenDataï¼Œç¡®ä¿è¡¨æœ‰nameå­—æ®µå†æ„å»ºç´¢å¼•
        if any('table_name' in t and 'name' not in t for t in tables):
            for t in tables:
                if 'name' not in t and 'table_name' in t:
                    t['name'] = t['table_name']
        metadata_filter.build_index(tables)
        
        # ä½¿ç”¨é…ç½®ä¸­çš„é˜ˆå€¼ï¼ˆWebTableä¼šæ›´ä½ï¼‰
        metadata_threshold = task_config.get('metadata_threshold', 0.05)
        l1_candidates = metadata_filter.filter_candidates(
            query_table,
            None,  # all_tables - Noneè¡¨ç¤ºä½¿ç”¨é¢„æ„å»ºçš„ç´¢å¼•
            threshold=metadata_threshold,
            max_candidates=1000  # è®¾ç½®é«˜ä¸Šé™ï¼Œè®©é˜ˆå€¼è‡ªç„¶æ§åˆ¶
        )
        
        # L2: å‘é‡æœç´¢
        try:
            # æ ¹æ®å±‚ç»„åˆç­–ç•¥å†³å®šæœç´¢èŒƒå›´
            if layer_combination == 'union':
                # UNIONç­–ç•¥ï¼šåœ¨æ‰€æœ‰è¡¨ä¸­æœç´¢ï¼Œä¸é™äºL1å€™é€‰
                logger.debug(f"ä½¿ç”¨UNIONç­–ç•¥ï¼šL2æœç´¢æ‰€æœ‰{len(tables)}ä¸ªè¡¨")
                search_tables = tables
            else:
                # INTERSECTIONç­–ç•¥ï¼šåªåœ¨L1å€™é€‰ä¸­æœç´¢ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                candidate_names = [name for name, score in l1_candidates]
                candidate_tables = []
                for t in tables:
                    table_name = t.get('name') or t.get('table_name')
                    if table_name in candidate_names:
                        candidate_tables.append(t)
                search_tables = candidate_tables if candidate_tables else tables
                logger.debug(f"ä½¿ç”¨INTERSECTIONç­–ç•¥ï¼šL2æœç´¢{len(search_tables)}ä¸ªL1å€™é€‰è¡¨")
            
            # ä½¿ç”¨å‘é‡æœç´¢
            vector_threshold = task_config.get('vector_threshold', 0.1)
            vector_top_k = task_config.get('vector_top_k', 200)
            l2_results = vector_search.search(
                query_table, 
                search_tables,
                top_k=vector_top_k
            )
            
            # æ·»åŠ ä»»åŠ¡ç‰¹å®šçš„å€¼ç›¸ä¼¼æ€§é‡æ’åºï¼ˆL2å¢å¼ºï¼‰
            enhanced_results = []
            for table_name, vec_score in l2_results:
                # è¿‡æ»¤ä½ç›¸ä¼¼åº¦çš„å€™é€‰
                if vec_score < vector_threshold:
                    continue
                if table_name != query_table_name:
                    # æ‰¾åˆ°å€™é€‰è¡¨å¯¹è±¡
                    cand_table = None
                    for t in tables:
                        t_name = t.get('name') or t.get('table_name')
                        if t_name == table_name:
                            cand_table = t
                            break
                    
                    if cand_table:
                        # ä»é…ç½®ä¸­è·å–æƒé‡
                        value_sim_weight = task_config.get('value_similarity_weight', 0.5)
                        
                        # ä»»åŠ¡ç‰¹å®šçš„å€¼ç›¸ä¼¼æ€§è®¡ç®—
                        if task_type == 'union':
                            # UNIONä»»åŠ¡ï¼šæ›´å…³æ³¨ç»“æ„å…¼å®¹æ€§å’Œæ•°æ®åˆ†å¸ƒç›¸ä¼¼æ€§
                            val_sim = value_similarity._calculate_union_value_similarity(
                                query_table, cand_table
                            )
                            # ä½¿ç”¨é…ç½®çš„æƒé‡ï¼ˆUNIONé»˜è®¤æ›´é‡è§†å€¼ç›¸ä¼¼æ€§ï¼‰
                            if task_config.get('semantic_matching', False):
                                combined_score = (1 - value_sim_weight) * vec_score + value_sim_weight * val_sim
                            else:
                                combined_score = 0.4 * vec_score + 0.6 * val_sim
                            
                            # UNIONé¢å¤–æ£€æŸ¥ï¼šåˆ—æ•°å·®å¼‚ä¸èƒ½å¤ªå¤§
                            query_col_count = len(query_table.get('columns', []))
                            cand_col_count = len(cand_table.get('columns', []))
                            col_diff_ratio = abs(query_col_count - cand_col_count) / max(query_col_count, 1)
                            if col_diff_ratio > 0.5:  # åˆ—æ•°å·®å¼‚è¶…è¿‡50%ï¼Œé™ä½åˆ†æ•°
                                combined_score *= 0.7
                        else:
                            # JOINä»»åŠ¡ï¼šæ›´å…³æ³¨å€¼é‡å å’Œå…³è”æ€§
                            val_sim = value_similarity._calculate_join_value_similarity(
                                query_table, cand_table
                            )
                            # ä½¿ç”¨é…ç½®çš„æƒé‡ï¼ˆJOINé»˜è®¤æ›´é‡è§†å‘é‡ç›¸ä¼¼æ€§ï¼‰
                            combined_score = 0.7 * vec_score + 0.3 * val_sim
                        
                        enhanced_results.append((table_name, combined_score))
            
            # åˆå¹¶L1å’ŒL2ç»“æœ
            final_scores = {}
            
            if layer_combination == 'union':
                # UNIONç­–ç•¥ï¼šåˆå¹¶æ‰€æœ‰ç»“æœï¼Œä½¿ç”¨æœ€é«˜åˆ†æ•°
                # å…ˆæ·»åŠ L2çš„å¢å¼ºç»“æœ
                for name, score in enhanced_results:
                    final_scores[name] = score
                
                # æ·»åŠ L1ç‹¬æœ‰çš„ç»“æœï¼ˆL2æ²¡æ‰¾åˆ°çš„ï¼‰
                for name, l1_score in l1_candidates:
                    if name != query_table_name and name not in final_scores:
                        # L1ç‹¬æœ‰çš„ç»“æœä½¿ç”¨åŸå§‹åˆ†æ•°çš„0.6å€
                        final_scores[name] = l1_score * 0.6
            else:
                # INTERSECTIONç­–ç•¥ï¼šåªä¿ç•™ä¸¤è€…éƒ½æœ‰çš„ï¼ˆä½†åˆ†æ•°å–æœ€é«˜ï¼‰
                l1_names = {name for name, _ in l1_candidates}
                for name, score in enhanced_results:
                    if name in l1_names:
                        final_scores[name] = score
                
                # å¦‚æœintersectionç»“æœå¤ªå°‘ï¼Œè¡¥å……ä¸€äº›é«˜åˆ†çš„L1ç»“æœ
                if len(final_scores) < 10:
                    for name, l1_score in l1_candidates[:20]:
                        if name != query_table_name and name not in final_scores:
                            final_scores[name] = l1_score * 0.5
            
            # æ’åºå¹¶æå–é¢„æµ‹
            sorted_results = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)
            predictions = [name for name, score in sorted_results][:MAX_PREDICTIONS]
            
            logger.debug(f"L1+L2ç»„åˆç»“æœï¼šç­–ç•¥={layer_combination}, L1={len(l1_candidates)}ä¸ª, L2={len(enhanced_results)}ä¸ª, æœ€ç»ˆ={len(predictions)}ä¸ª")
            
        except Exception as e:
            logger.warning(f"L2å¤„ç†å¤±è´¥ {query_table_name}: {e}, å›é€€åˆ°L1ç»“æœ")
            # å›é€€åˆ°L1ç»“æœ
            predictions = [
                table_name for table_name, score in l1_candidates
                if table_name != query_table_name
            ][:MAX_PREDICTIONS]
        
        result = {'query_table': query_table_name, 'predictions': predictions}
    
    # ä¿å­˜åˆ°å…¨å±€ç¼“å­˜
    if cache_manager:
        cache_manager.set('l1_l2', query, result, {'task_type': task_type})
    
    return result


def process_query_l3(args: Tuple) -> Dict:
    """å¤„ç†å•ä¸ªæŸ¥è¯¢ - å®Œæ•´ä¸‰å±‚ï¼ˆä¼˜åŒ–ç‰ˆï¼šä»»åŠ¡ç‰¹å®šä¼˜åŒ–å’Œboost factorsï¼‰"""
    query, tables, shared_config, cache_file_path = args
    query_table_name = query.get('query_table', '')
    task_type = query.get('task_type', shared_config.get('task_type', 'join'))
    
    # è·å–åŠ¨æ€ä¼˜åŒ–å™¨å®ä¾‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    dynamic_optimizer = shared_config.get('dynamic_optimizer', None)
    
    # åˆå§‹åŒ–æˆ–è·å–ç¼“å­˜ç®¡ç†å™¨ï¼ˆå­è¿›ç¨‹éœ€è¦ï¼‰
    global cache_manager
    if cache_manager is None and cache_file_path:
        # cache_file_pathç°åœ¨æ˜¯ç¼“å­˜ç›®å½•è·¯å¾„
        cache_dir = cache_file_path
        cache_manager = CacheManager(cache_dir)
    
    # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨
    if cache_manager:
        cached = cache_manager.get('l1_l2_l3', query, {'task_type': task_type})
        if cached is not None:
            return cached
    
    # å…ˆè¿è¡ŒL2å±‚è·å–åŸºç¡€ç»“æœ
    l2_cache_file = cache_file_path.replace('L3', 'L2')
    l2_result = process_query_l2((query, tables, shared_config, l2_cache_file))
    l2_predictions = l2_result.get('predictions', [])
    
    logger.info(f"L3å±‚æ¥æ”¶åˆ°L2é¢„æµ‹: {len(l2_predictions)} ä¸ªå€™é€‰")
    
    # å¦‚æœL2é¢„æµ‹å¤ªå°‘ï¼Œç›´æ¥è¿”å›L2ç»“æœ
    if len(l2_predictions) < 2:
        logger.warning(f"L2é¢„æµ‹å¤ªå°‘ï¼ˆ{len(l2_predictions)}ä¸ªï¼‰ï¼Œè·³è¿‡L3å±‚LLMéªŒè¯")
        return {'query_table': query_table_name, 'predictions': l2_predictions}
    
    # L3å±‚ï¼šç›´æ¥ä½¿ç”¨LLMéªŒè¯ï¼ˆç¡®ä¿UNIONä»»åŠ¡æ­£ç¡®å¤„ç†ï¼‰
    try:
        # æ–¹æ¡ˆ1ï¼šç›´æ¥ä½¿ç”¨LLMMatcherToolè¿›è¡ŒéªŒè¯
        from src.tools.llm_matcher import LLMMatcherTool
        import asyncio
        
        # æŸ¥æ‰¾æŸ¥è¯¢è¡¨ - å…¼å®¹ä¸åŒæ•°æ®é›†çš„å­—æ®µå
        query_table = None
        for t in tables:
            # å…¼å®¹ 'name' (NLCTables) å’Œ 'table_name' (OpenData/WebTable)
            table_name = t.get('name') or t.get('table_name')
            if table_name == query_table_name:
                query_table = t
                break
        
        if not query_table:
            logger.warning(f"æŸ¥è¯¢è¡¨ {query_table_name} æœªæ‰¾åˆ°ï¼Œä½¿ç”¨L2ç»“æœ")
            final_predictions = l2_predictions
        else:
            # ä»é…ç½®ä¸­è·å–L3å±‚å‚æ•°
            optimizer_config = shared_config.get('optimization_config', {})
            
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ä»»åŠ¡ç‰¹å®šå‚æ•°
            max_candidates = optimizer_config.get('aggregator_max_results', 300)
            llm_concurrency = optimizer_config.get('llm_concurrency', 3)
            confidence_threshold = optimizer_config.get('llm_confidence_threshold', 0.20)
            
            logger.info(f"L3å±‚ä½¿ç”¨{task_type.upper()}ä»»åŠ¡é…ç½®: max_candidates={max_candidates}, "
                       f"concurrency={llm_concurrency}, confidence={confidence_threshold:.2f}")
            
            # åˆå§‹åŒ–LLM matcher
            llm_matcher = LLMMatcherTool()
            
            # L3æ”¹è¿›ï¼šé™åˆ¶LLMéªŒè¯æ•°é‡ï¼Œé¿å…è¢«ä½è´¨é‡å€™é€‰æ·¹æ²¡
            # åªéªŒè¯TOPå€™é€‰ï¼Œç¡®ä¿LLMçœ‹åˆ°çš„éƒ½æ˜¯é«˜è´¨é‡å€™é€‰
            # ä»é…ç½®ä¸­è·å–æœ€å¤§éªŒè¯æ•°é‡
            max_verify_config = optimizer_config.get('max_llm_verify', 25)
            max_verify = min(len(l2_predictions), max_verify_config)
            logger.info(f"L3å±‚å‡†å¤‡éªŒè¯ {max_verify} ä¸ªL2å€™é€‰ï¼ˆé…ç½®æœ€å¤§å€¼: {max_verify_config}ï¼‰")
            
            candidate_tables = []
            for pred_name in l2_predictions[:max_verify]:
                for t in tables:
                    # å…¼å®¹ä¸åŒå­—æ®µå
                    t_name = t.get('name') or t.get('table_name')
                    if t_name == pred_name:
                        candidate_tables.append(t)
                        break
            
            logger.info(f"L3å±‚æ‰¾åˆ° {len(candidate_tables)} ä¸ªå€™é€‰è¡¨è¿›è¡ŒLLMéªŒè¯")
            
            if candidate_tables and len(candidate_tables) > 0:
                # ä½¿ç”¨batch_verifyè¿›è¡Œå¹¶è¡ŒLLMéªŒè¯
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                # å…³é”®ï¼šç¡®ä¿task_typeæ­£ç¡®ä¼ é€’ï¼Œä½¿ç”¨OptimizerAgentçš„å‚æ•°
                logger.info(f"L3å±‚å¼€å§‹LLMæ‰¹é‡éªŒè¯: {len(candidate_tables)} ä¸ªè¡¨, å¹¶å‘æ•°={llm_concurrency}")
                
                llm_results = loop.run_until_complete(
                    llm_matcher.batch_verify(
                        query_table=query_table,
                        candidate_tables=candidate_tables,
                        task_type=task_type,  # æ˜ç¡®ä¼ é€’task_type
                        max_concurrent=llm_concurrency,  # ä½¿ç”¨OptimizerAgentä¼˜åŒ–çš„å¹¶å‘æ•°
                        existing_scores=[0.7] * len(candidate_tables)  # å‡è®¾L2ç»™å‡ºçš„éƒ½æ˜¯é«˜åˆ†å€™é€‰
                    )
                )
                loop.close()
                
                logger.info(f"L3å±‚LLMéªŒè¯å®Œæˆ: è¿”å› {len(llm_results)} ä¸ªç»“æœ")
                
                # L3æ”¹è¿›ï¼šä½¿ç”¨é‡æ’åºè€Œéè¿‡æ»¤
                # æ”¶é›†æ‰€æœ‰å€™é€‰è¡¨çš„ç›¸å…³æ€§åˆ†æ•°
                l3_scored = []
                for i, result in enumerate(llm_results):
                    # ä¼˜å…ˆä½¿ç”¨relevance_scoreï¼ˆæ–°çš„é‡æ’åºå­—æ®µï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨confidence
                    relevance_score = result.get('relevance_score', result.get('confidence', 0))
                    # å…¼å®¹ä¸åŒå­—æ®µå
                    candidate_name = candidate_tables[i].get('name') or candidate_tables[i].get('table_name')
                    
                    # åº”ç”¨ä»»åŠ¡ç‰¹å®šçš„boost factorï¼ˆå¦‚æœæœ‰ä¼˜åŒ–å™¨ï¼‰
                    if dynamic_optimizer:
                        boosted_score = dynamic_optimizer.apply_boost_factor(
                            task_type, relevance_score, query_table_name, candidate_name
                        )
                    else:
                        boosted_score = relevance_score
                    
                    # é‡æ’åºï¼šæ”¶é›†æ‰€æœ‰å€™é€‰ï¼Œä¸è¿‡æ»¤
                    l3_scored.append((candidate_name, boosted_score))
                
                # æŒ‰ç›¸å…³æ€§åˆ†æ•°é™åºæ’åºï¼ˆé‡æ’åºçš„æ ¸å¿ƒï¼‰
                l3_scored.sort(key=lambda x: x[1], reverse=True)
                
                # åˆå¹¶L3éªŒè¯çš„ç»“æœå’Œå‰©ä½™çš„L2ç»“æœ
                l3_verified_names = {name for name, _ in l3_scored}
                remaining_l2 = [name for name in l2_predictions if name not in l3_verified_names]
                
                # æœ€ç»ˆé¢„æµ‹ï¼šL3é‡æ’åºçš„ç»“æœ + å‰©ä½™çš„L2ç»“æœï¼ˆç¡®ä¿ä½¿ç”¨æ‰€æœ‰L2é¢„æµ‹ï¼‰
                l3_predictions = [name for name, score in l3_scored]
                
                # ç¡®ä¿åŒ…å«æ‰€æœ‰L2çš„é¢„æµ‹ï¼Œä¸åªé™äºMAX_PREDICTIONS
                for name in remaining_l2:
                    if len(l3_predictions) < MAX_PREDICTIONS:
                        l3_predictions.append(name)
                
                logger.info(f"L3å±‚é‡æ’åº: å¯¹ {len(l3_scored)} ä¸ªå€™é€‰è¿›è¡Œäº†LLMè¯„åˆ†é‡æ’åº")
                logger.info(f"L3å±‚æœ€ç»ˆé¢„æµ‹æ•°: {len(l3_predictions)} (L3éªŒè¯: {len(l3_scored)}, L2è¡¥å……: {len(l3_predictions) - len(l3_scored)})")
                
                if l3_scored:
                    top_scores = [(name, score) for name, score in l3_scored[:5]]
                    logger.info(f"L3å±‚Top5å¾—åˆ†: {top_scores}")
                
                final_predictions = l3_predictions[:MAX_PREDICTIONS]  # ç¡®ä¿æœ€ç»ˆè¾“å‡ºä¸è¶…è¿‡MAX_PREDICTIONS
            else:
                logger.warning(f"æ²¡æœ‰æ‰¾åˆ°L2å€™é€‰è¡¨çš„è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨L2ç»“æœ")
                final_predictions = l2_predictions
                
    except ImportError as e:
        logger.error(f"æ— æ³•å¯¼å…¥LLMMatcherTool: {e}")
        # æ–¹æ¡ˆ2ï¼šå¦‚æœç›´æ¥LLMè°ƒç”¨å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨workflow
        try:
            from src.core.langgraph_workflow import DataLakeDiscoveryWorkflow
            
            workflow = DataLakeDiscoveryWorkflow()
            
            # ç¡®ä¿ä¸è·³è¿‡LLM
            import os
            old_skip_llm = os.environ.get('SKIP_LLM', 'false')
            os.environ['SKIP_LLM'] = 'false'
            
            result = workflow.run(
                query=f"find {task_type}able tables for {query_table_name}",
                tables=tables,
                task_type=task_type,
                query_table_name=query_table_name
            )
            
            # æ¢å¤åŸè®¾ç½®
            os.environ['SKIP_LLM'] = old_skip_llm
            
            if result and result.get('success') and result.get('results'):
                l3_predictions = [
                    r['table_name'] for r in result.get('results', [])[:MAX_PREDICTIONS]
                    if r['table_name'] != query_table_name
                ]
                final_predictions = l3_predictions if l3_predictions else l2_predictions
            else:
                logger.warning(f"L3 å·¥ä½œæµè¿”å›ç©ºç»“æœ {query_table_name}, ä½¿ç”¨L2ç»“æœ")
                final_predictions = l2_predictions
                
        except Exception as e2:
            logger.warning(f"L3 å·¥ä½œæµä¹Ÿå¤±è´¥ {query_table_name}: {e2}, å›é€€åˆ°L2ç»“æœ")
            final_predictions = l2_predictions
            
    except Exception as e:
        logger.warning(f"L3 LLMå¤„ç†å¤±è´¥ {query_table_name}: {e}, å›é€€åˆ°L2ç»“æœ")
        final_predictions = l2_predictions
    
    query_result = {'query_table': query_table_name, 'predictions': final_predictions}
    
    # ä¿å­˜åˆ°å…¨å±€ç¼“å­˜
    if cache_manager:
        cache_manager.set('l1_l2_l3', query, query_result, {'task_type': task_type})
    
    return query_result


def run_layer_experiment(layer: str, tables: List[Dict], queries: List[Dict], 
                         task_type: str, dataset_type: str, max_workers: int = 4) -> Tuple[Dict, float]:
    """è¿è¡Œç‰¹å®šå±‚çš„å®éªŒï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ”¬ Running {layer} Experiment")
    logger.info(f"{'='*60}")
    
    # åˆå§‹åŒ–å…±äº«èµ„æºï¼ˆä¼ é€’task_typeä»¥ä½¿ç”¨ä»»åŠ¡ç‰¹å®šé…ç½®ï¼‰
    if layer == 'L1':
        shared_config = initialize_shared_resources_l1(tables, dataset_type, task_type)
        process_func = process_query_l1
    elif layer == 'L1+L2':
        shared_config = initialize_shared_resources_l2(tables, dataset_type, task_type)
        process_func = process_query_l2
    else:  # L1+L2+L3
        # ç¡®ä¿LLMä¸è¢«è·³è¿‡ï¼Œç‰¹åˆ«é‡è¦ï¼
        os.environ['SKIP_LLM'] = 'false'
        os.environ['FORCE_LLM_VERIFICATION'] = 'true'
        # ä»é…ç½®æ–‡ä»¶åŠ è½½ä»»åŠ¡ç‰¹å®šé…ç½®ï¼ˆä¼ é€’dataset_typeï¼‰
        task_config = load_task_config(task_type, dataset_type)
        if task_config.get('semantic_matching', False):
            os.environ['UNION_OPTIMIZATION'] = 'true'
        shared_config = initialize_shared_resources_l3(tables, task_type, dataset_type)
        process_func = process_query_l3
    
    # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨çš„ç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if cache_manager:
        cache_dir = cache_manager.cache_dir
    else:
        # é™çº§åˆ°é»˜è®¤ç¼“å­˜ç›®å½•
        cache_dir = Path(f"cache/ablation_{dataset_type}_{layer.replace('+', '_')}")
        cache_dir.mkdir(parents=True, exist_ok=True)
    
    # å‡†å¤‡è¿›ç¨‹æ± å‚æ•°ï¼ˆæ¯ä¸ªæŸ¥è¯¢ä¼ é€’ç¼“å­˜ç›®å½•è·¯å¾„å’Œdataset_typeï¼‰
    query_args = []
    for query in queries:
        # åœ¨queryä¸­æ·»åŠ dataset_typeä»¥ä¾›processå‡½æ•°ä½¿ç”¨
        query_with_dataset = {**query, 'dataset_type': dataset_type}
        query_args.append((query_with_dataset, tables, shared_config, str(cache_dir)))
    
    # ä½¿ç”¨è¿›ç¨‹æ± å¤„ç†
    predictions = {}
    start_time = time.time()
    
    logger.info(f"ğŸ“Š å¤„ç† {len(queries)} ä¸ªæŸ¥è¯¢ (è¿›ç¨‹æ•°={max_workers})...")
    
    if layer == 'L1+L2+L3' and shared_config.get('optimization_config'):
        logger.info(f"  âš¡ æ‰¹å¤„ç†ä¼˜åŒ–: OptimizerAgentå’ŒPlannerAgentåªè°ƒç”¨1æ¬¡")
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        future_to_query = {
            executor.submit(process_func, args): args[0]
            for args in query_args
        }
        
        completed = 0
        for future in as_completed(future_to_query):
            query = future_to_query[future]
            completed += 1
            
            try:
                result = future.result(timeout=60)
                predictions[result['query_table']] = result['predictions']
                
                if completed % 5 == 0:
                    logger.info(f"  è¿›åº¦: {completed}/{len(queries)}")
                    
            except Exception as e:
                logger.error(f"æŸ¥è¯¢å¤±è´¥: {query.get('query_table', '')}: {e}")
                predictions[query.get('query_table', '')] = []
    
    elapsed_time = time.time() - start_time
    logger.info(f"âœ… {layer} å®Œæˆ - æ€»æ—¶é—´: {elapsed_time:.2f}ç§’")
    
    return predictions, elapsed_time


def calculate_metrics(predictions: Dict[str, List[str]], 
                     ground_truth: Dict[str, List[str]]) -> Dict[str, float]:
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    hit_at_1 = 0
    hit_at_3 = 0
    hit_at_5 = 0
    
    total_precision = 0
    total_recall = 0
    total_f1 = 0
    valid_queries = 0
    
    for query_table, pred_tables in predictions.items():
        if query_table not in ground_truth:
            continue
        
        valid_queries += 1
        true_tables = set(ground_truth[query_table])
        
        # Hit@K metrics
        for k in [1, 3, 5]:
            top_k_predictions = set(pred_tables[:k])
            if top_k_predictions & true_tables:
                if k == 1:
                    hit_at_1 += 1
                elif k == 3:
                    hit_at_3 += 1
                elif k == 5:
                    hit_at_5 += 1
        
        # Precision, Recall, F1 (Use all predictions, not limited)
        if pred_tables:
            predicted_set = set(pred_tables)  # Use all predictions for metrics calculation
            tp = len(predicted_set & true_tables)
            fp = len(predicted_set - true_tables)
            fn = len(true_tables - predicted_set)
            
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            
            total_precision += precision
            total_recall += recall
            total_f1 += f1
    
    if valid_queries > 0:
        return {
            'hit@1': hit_at_1 / valid_queries,
            'hit@3': hit_at_3 / valid_queries,
            'hit@5': hit_at_5 / valid_queries,
            'precision': total_precision / valid_queries,
            'recall': total_recall / valid_queries,
            'f1_score': total_f1 / valid_queries,
            'valid_queries': valid_queries
        }
    else:
        return {
            'hit@1': 0.0, 'hit@3': 0.0, 'hit@5': 0.0,
            'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0,
            'valid_queries': 0
        }


def create_challenging_queries(tables: List[Dict], queries: List[Dict], ground_truth: List[Dict], max_queries: int = None) -> Tuple[List[Dict], List[Dict]]:
    """åˆ›å»ºæ›´å…·æŒ‘æˆ˜æ€§çš„æŸ¥è¯¢ï¼Œé™ä½L1å‡†ç¡®ç‡
    
    Args:
        tables: æ‰€æœ‰è¡¨çš„åˆ—è¡¨
        queries: åŸå§‹æŸ¥è¯¢åˆ—è¡¨
        ground_truth: çœŸå®æ ‡ç­¾
        max_queries: æœ€å¤§æŸ¥è¯¢æ•°é™åˆ¶
    """
    # é€‰æ‹©å…·æœ‰ç›¸ä¼¼ç»“æ„ä½†è¯­ä¹‰ä¸åŒçš„è¡¨ä½œä¸ºæŒ‘æˆ˜æ€§æŸ¥è¯¢
    challenging_queries = []
    challenging_gt = []
    
    # æŒ‰åˆ—æ•°åˆ†ç»„è¡¨
    tables_by_col_count = {}
    for table in tables:
        col_count = len(table.get('columns', []))
        if col_count not in tables_by_col_count:
            tables_by_col_count[col_count] = []
        tables_by_col_count[col_count].append(table.get('name'))
    
    # ç¡®å®šè¦å¤„ç†çš„æŸ¥è¯¢æ•°
    if max_queries is None:
        # å¦‚æœmax_queriesæ˜¯Noneï¼ˆä½¿ç”¨allï¼‰ï¼Œè¿”å›æ‰€æœ‰åŸå§‹æŸ¥è¯¢ï¼Œä¸åˆ›å»ºæŒ‘æˆ˜æ€§æŸ¥è¯¢
        # è¿™æ ·å¯ä»¥ç¡®ä¿ä½¿ç”¨æ•°æ®é›†çš„æ‰€æœ‰æŸ¥è¯¢
        logger.info(f"ğŸ“Š ä½¿ç”¨æ‰€æœ‰åŸå§‹æŸ¥è¯¢ï¼ˆ{len(queries)}ä¸ªï¼‰ï¼Œä¸åˆ›å»ºæŒ‘æˆ˜æ€§æŸ¥è¯¢")
        return queries, ground_truth
    else:
        # å¦‚æœæŒ‡å®šäº†å…·ä½“æ•°é‡ï¼Œåˆ™æŒ‰åŸé€»è¾‘åˆ†é…ä¸€åŠåŸå§‹ã€ä¸€åŠæŒ‘æˆ˜æ€§
        num_queries = min(len(queries), max_queries)
        num_original = num_queries // 2
        num_challenging = num_queries - num_original
    
    # ä¸ºæ¯ä¸ªåŸå§‹æŸ¥è¯¢åˆ›å»ºä¸€ä¸ªæŒ‘æˆ˜æ€§ç‰ˆæœ¬
    for i, query in enumerate(queries[:num_original]):
        query_table_name = query.get('query_table', '')
        
        # æ‰¾åˆ°æŸ¥è¯¢è¡¨çš„åˆ—æ•°
        query_table = None
        for t in tables:
            if t.get('name') == query_table_name:
                query_table = t
                break
        
        if query_table:
            col_count = len(query_table.get('columns', []))
            
            # åœ¨åŒåˆ—æ•°çš„è¡¨ä¸­é€‰æ‹©ç»“æ„ç›¸ä¼¼ä½†è¯­ä¹‰ä¸åŒçš„è¡¨ä½œä¸ºæŸ¥è¯¢
            similar_tables = tables_by_col_count.get(col_count, [])
            if len(similar_tables) > 1:
                for similar_table_name in similar_tables:
                    if similar_table_name != query_table_name:
                        # åˆ›å»ºæŒ‘æˆ˜æ€§æŸ¥è¯¢
                        challenging_query = {
                            'query_table': similar_table_name,
                            'task_type': query.get('task_type', 'join')
                        }
                        challenging_queries.append(challenging_query)
                        
                        # æŸ¥æ‰¾ground truthï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        gt_matches = []
                        for gt_item in ground_truth:
                            if gt_item.get('query_table') == similar_table_name:
                                gt_matches.append(gt_item)
                        
                        challenging_gt.extend(gt_matches)
                        break
    
    # æ··åˆåŸå§‹æŸ¥è¯¢å’ŒæŒ‘æˆ˜æ€§æŸ¥è¯¢
    mixed_queries = queries[:num_original] + challenging_queries[:num_challenging]
    
    # å¯¹åº”çš„ground truth
    original_gt = []
    for query in queries[:num_original]:
        query_table_name = query.get('query_table', '')
        for gt_item in ground_truth:
            if gt_item.get('query_table') == query_table_name:
                original_gt.append(gt_item)
    
    mixed_gt = original_gt + challenging_gt
    
    logger.info(f"ğŸ“ˆ Created {len(challenging_queries)} challenging queries")
    logger.info(f"ğŸ“ˆ Total mixed queries: {len(mixed_queries)}")
    
    return mixed_queries, mixed_gt


def run_ablation_experiment_optimized(task_type: str, dataset_type: str = 'subset', max_queries: int = None, max_workers: int = 4, use_challenging: bool = True):
    """è¿è¡Œä¼˜åŒ–çš„æ¶ˆèå®éªŒ
    
    Args:
        task_type: ä»»åŠ¡ç±»å‹ ('join' æˆ– 'union')
        dataset_type: æ•°æ®é›†ç±»å‹ ('subset' æˆ– 'complete')
        max_queries: æœ€å¤§æŸ¥è¯¢æ•° (Noneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰æŸ¥è¯¢)
        max_workers: å¹¶è¡Œè¿›ç¨‹æ•°
        use_challenging: æ˜¯å¦ä½¿ç”¨æŒ‘æˆ˜æ€§æŸ¥è¯¢
    """
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸš€ Running OPTIMIZED Ablation Experiment for {task_type.upper()} Task")
    logger.info(f"ğŸ“‚ Dataset Type: {dataset_type.upper()}")
    queries_desc = "ALL" if max_queries is None else str(max_queries)
    logger.info(f"ğŸ“Š Max Queries: {queries_desc}")
    if use_challenging:
        logger.info(f"ğŸ¯ Using challenging mixed queries to test layer improvements")
    logger.info(f"{'='*80}")
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    init_cache_manager(dataset_type, task_type, str(max_queries) if max_queries else 'all')
    
    # åŠ è½½æ•°æ®
    tables, queries, ground_truth = load_dataset(task_type, dataset_type)
    logger.info(f"ğŸ“Š Dataset: {len(tables)} tables, {len(queries)} queries")
    
    # åˆ›å»ºæŒ‘æˆ˜æ€§æŸ¥è¯¢æˆ–ä½¿ç”¨åŸå§‹æŸ¥è¯¢
    if use_challenging and max_queries is not None:
        # åªæœ‰åœ¨æŒ‡å®šäº†å…·ä½“æ•°é‡æ—¶æ‰åˆ›å»ºæŒ‘æˆ˜æ€§æŸ¥è¯¢
        queries, ground_truth = create_challenging_queries(tables, queries, ground_truth, max_queries)
        # ä¸éœ€è¦å†æ¬¡æˆªæ–­ï¼Œcreate_challenging_querieså·²ç»å¤„ç†äº†max_queries
    else:
        # å¦‚æœmax_queriesæ˜¯Noneï¼Œä½¿ç”¨æ‰€æœ‰æŸ¥è¯¢ï¼›å¦åˆ™æˆªæ–­
        if max_queries is not None:
            queries = queries[:max_queries]
            logger.info(f"ğŸ“Š ä½¿ç”¨å‰{max_queries}ä¸ªæŸ¥è¯¢")
        else:
            logger.info(f"ğŸ“Š ä½¿ç”¨æ•°æ®é›†çš„æ‰€æœ‰{len(queries)}ä¸ªæŸ¥è¯¢")
        # else: ä½¿ç”¨æ‰€æœ‰æŸ¥è¯¢
    
    # ç¡®ä¿æ¯ä¸ªæŸ¥è¯¢éƒ½æœ‰æ­£ç¡®çš„ä»»åŠ¡ç±»å‹
    for query in queries:
        if 'task_type' not in query:
            query['task_type'] = task_type
    
    logger.info(f"ğŸ“‹ Using {len(queries)} queries for {task_type.upper()} task experiment")
    
    # è½¬æ¢ground truthæ ¼å¼
    gt_dict = convert_ground_truth_format(ground_truth)
    
    # å­˜å‚¨ç»“æœ
    results = {}
    
    # è¿è¡Œä¸‰å±‚å®éªŒ
    for layer in ['L1', 'L1+L2', 'L1+L2+L3']:
        predictions, elapsed_time = run_layer_experiment(
            layer, tables, queries, task_type, dataset_type, max_workers
        )
        
        metrics = calculate_metrics(predictions, gt_dict)
        
        results[layer.replace('+', '_')] = {
            'metrics': metrics,
            'time': elapsed_time,
            'avg_time': elapsed_time / len(queries) if queries else 0
        }
        
        logger.info(f"ğŸ“ˆ {layer} - F1: {metrics['f1_score']:.3f}, "
                   f"Hit@1: {metrics['hit@1']:.3f}, "
                   f"Avg Time: {elapsed_time/len(queries):.2f}s/query")
    
    return results


def print_comparison_table(all_results: Dict[str, Dict]):
    """æ‰“å°å¯¹æ¯”è¡¨æ ¼"""
    print("\n" + "="*100)
    print("ğŸš€ OPTIMIZED THREE-LAYER ABLATION EXPERIMENT RESULTS")
    print("="*100)
    
    for task_type, results in all_results.items():
        print(f"\n{task_type.upper()} Task Results:")
        print("-"*80)
        print(f"{'Layer Config':<15} {'Hit@1':<10} {'Hit@3':<10} {'Hit@5':<10} "
              f"{'Precision':<12} {'Recall':<10} {'F1-Score':<10} {'Time(s)':<10}")
        print("-"*80)
        
        for config in ['L1', 'L1_L2', 'L1_L2_L3']:
            if config in results:
                m = results[config]['metrics']
                t = results[config]['avg_time']
                config_display = config.replace('_', '+')
                print(f"{config_display:<15} {m['hit@1']:<10.3f} {m['hit@3']:<10.3f} "
                      f"{m['hit@5']:<10.3f} {m['precision']:<12.3f} "
                      f"{m['recall']:<10.3f} {m['f1_score']:<10.3f} {t:<10.2f}")
    
    print("\n" + "="*100)
    print("ğŸ“Š LAYER CONTRIBUTION ANALYSIS")
    print("="*100)
    
    for task_type, results in all_results.items():
        print(f"\n{task_type.upper()} Task - Incremental Improvements:")
        
        if 'L1' in results and 'L1_L2' in results:
            f1_l1 = results['L1']['metrics']['f1_score']
            f1_l12 = results['L1_L2']['metrics']['f1_score']
            improvement = (f1_l12 - f1_l1) * 100
            time_increase = results['L1_L2']['avg_time'] - results['L1']['avg_time']
            print(f"  L2 Contribution: {improvement:+.1f}% F1 improvement, {time_increase:+.2f}s time cost")
        
        if 'L1_L2' in results and 'L1_L2_L3' in results:
            f1_l12 = results['L1_L2']['metrics']['f1_score']
            f1_full = results['L1_L2_L3']['metrics']['f1_score']
            improvement = (f1_full - f1_l12) * 100
            time_increase = results['L1_L2_L3']['avg_time'] - results['L1_L2']['avg_time']
            print(f"  L3 Contribution: {improvement:+.1f}% F1 improvement, {time_increase:+.2f}s time cost")
        
        if 'L1' in results and 'L1_L2_L3' in results:
            f1_l1 = results['L1']['metrics']['f1_score']
            f1_full = results['L1_L2_L3']['metrics']['f1_score']
            total_improvement = (f1_full - f1_l1) * 100
            speedup = results['L1']['avg_time'] / results['L1_L2_L3']['avg_time'] if results['L1_L2_L3']['avg_time'] > 0 else 0
            print(f"  Total Improvement: {total_improvement:+.1f}% F1 improvement")
            
            # è®¡ç®—æˆæœ¬æ•ˆç›Šæ¯”
            if results['L1_L2_L3']['avg_time'] > results['L1']['avg_time']:
                cost_benefit = total_improvement / (results['L1_L2_L3']['avg_time'] / results['L1']['avg_time'])
                print(f"  Cost-Benefit Ratio: {cost_benefit:.2f}% improvement per time unit")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–ç‰ˆä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒ')
    parser.add_argument('--task', choices=['join', 'union', 'both'], default='both',
                       help='ä»»åŠ¡ç±»å‹ (bothä¼šåŒæ—¶è¿è¡Œjoinå’Œunion)')
    parser.add_argument('--dataset', type=str, default='webtable',
                       help='æ•°æ®é›†åç§°: webtable, opendata, æˆ–è‡ªå®šä¹‰è·¯å¾„')
    parser.add_argument('--dataset-type', choices=['subset', 'complete', 'true_subset'], default='subset',
                       help='æ•°æ®é›†ç±»å‹: subset(å­é›†), complete(å®Œæ•´), true_subset(WebTableçš„çœŸå­é›†)')
    parser.add_argument('--max-queries', type=str, default='10',
                       help='æœ€å¤§æŸ¥è¯¢æ•° (æ•°å­—æˆ–"all"è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨)')
    parser.add_argument('--workers', type=int, default=4,
                       help='å¹¶è¡Œè¿›ç¨‹æ•°')
    parser.add_argument('--challenging', action='store_true', default=True,
                       help='ä½¿ç”¨æŒ‘æˆ˜æ€§æ··åˆæŸ¥è¯¢ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--simple', action='store_true',
                       help='ä½¿ç”¨ç®€å•åŸå§‹æŸ¥è¯¢ï¼ˆç¦ç”¨æŒ‘æˆ˜æ€§æŸ¥è¯¢ï¼‰')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()
    
    # å¤„ç†max_querieså‚æ•°
    if args.max_queries.lower() in ['all', '-1', 'none']:
        max_queries = None  # Noneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰æŸ¥è¯¢
        print(f"ğŸ“Š ä½¿ç”¨æ•´ä¸ªæ•°æ®é›†çš„æ‰€æœ‰æŸ¥è¯¢")
    else:
        try:
            max_queries = int(args.max_queries)
            print(f"ğŸ“Š é™åˆ¶æœ€å¤§æŸ¥è¯¢æ•°ä¸º: {max_queries}")
        except ValueError:
            print(f"âš ï¸ æ— æ•ˆçš„max-querieså€¼: {args.max_queries}ï¼Œä½¿ç”¨é»˜è®¤å€¼10")
            max_queries = 10
    
    # å†³å®šæ˜¯å¦ä½¿ç”¨æŒ‘æˆ˜æ€§æŸ¥è¯¢
    use_challenging = args.challenging and not args.simple
    
    # è¿è¡Œå®éªŒ
    tasks = ['join', 'union'] if args.task == 'both' else [args.task]
    all_results = {}
    
    # æ„å»ºæ•°æ®é›†è·¯å¾„
    for task in tasks:
        # å¤„ç†æ•°æ®é›†è·¯å¾„
        if '/' in args.dataset and not args.dataset.startswith('examples/'):
            # è‡ªå®šä¹‰å®Œæ•´è·¯å¾„ï¼ˆéexampleså¼€å¤´ï¼‰
            task_dataset = args.dataset
        elif args.dataset.startswith('examples/') and args.task != 'both':
            # ç›´æ¥ä½¿ç”¨æä¾›çš„è·¯å¾„ï¼ˆå•ä»»åŠ¡æ¨¡å¼ï¼‰
            task_dataset = args.dataset
        elif args.dataset in ['webtable', 'opendata']:
            # ä½¿ç”¨æ ‡å‡†æ•°æ®é›†
            task_dataset = f"examples/{args.dataset}/{task}_{args.dataset_type}"
        elif args.dataset == 'true_subset':
            # WebTableçš„çœŸå­é›†ï¼ˆå‘åå…¼å®¹ï¼‰
            task_dataset = f"examples/separated_datasets/{task}_true_subset"
        elif 'nlctables' in args.dataset.lower():
            # NLCTablesæ•°æ®é›† - ç›´æ¥ä¼ é€’ç»™load_dataset
            if args.dataset_type == 'complete':
                task_dataset = 'nlctables_complete'
            else:
                task_dataset = 'nlctables_subset'
        else:
            # å…¶ä»–é¢„å®šä¹‰ç±»å‹ï¼ˆå‘åå…¼å®¹ï¼‰
            if args.dataset_type == 'complete':
                task_dataset = f"examples/separated_datasets/{task}"
            else:
                task_dataset = f"examples/separated_datasets/{task}_{args.dataset_type}"
            
        results = run_ablation_experiment_optimized(task, task_dataset, max_queries, args.workers, use_challenging)
        all_results[task] = results
    
    # æ‰“å°ç»“æœè¡¨æ ¼
    print_comparison_table(all_results)
    
    # ä¿å­˜ç»“æœ
    if args.output:
        output_path = Path(args.output)
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        dataset_suffix = args.dataset if args.dataset != 'subset' else 'subset'
        output_path = Path(f"experiment_results/ablation_optimized_{dataset_suffix}_{timestamp}.json")
    
    output_path.parent.mkdir(exist_ok=True)
    with open(output_path, 'w') as f:
        json.dump(all_results, f, indent=2)
    
    logger.info(f"\nâœ… Results saved to: {output_path}")
    
    # è¾“å‡ºç¼“å­˜ç»Ÿè®¡
    if cache_manager:
        cache_stats = cache_manager.get_stats()
        print("\n" + "="*100)
        print("ğŸ“Š CACHE STATISTICS")
        print("="*100)
        print(f"  Cache Hits: {cache_stats['hits']}")
        print(f"  Cache Misses: {cache_stats['misses']}")
        print(f"  Cache Saves: {cache_stats['saves']}")
        print(f"  Hit Rate: {cache_stats['hit_rate']}")
        print(f"  Memory Items: {cache_stats['memory_items']}")
    
    # ä¼˜åŒ–æ€»ç»“
    print("\n" + "="*100)
    print("âš¡ OPTIMIZATION SUMMARY")
    print("="*100)
    print("Layer Optimizations Applied:")
    print("  ğŸ” L1 (Metadata): SMD Enhanced filter with reduced table name weight (5%)")
    print("  âš¡ L2 (Vector): Task-specific value similarity (UNION: 50%+50%, JOIN: 70%+30%)")
    print("  ğŸ§  L3 (LLM): Simplified robust verification with enhanced fallback")
    print("\nSystem Optimizations:")
    print("  1. Batch-level resource sharing (OptimizerAgent & PlannerAgent)")
    print("  2. Process pool parallelization")
    print("  3. Persistent caching system")
    print("  4. Pre-computed vector indices")
    print("  5. Challenging mixed queries for better layer evaluation")
    print("="*100)


if __name__ == "__main__":
    # ä¿®å¤å¤šè¿›ç¨‹å¯åŠ¨é—®é¢˜
    mp.freeze_support()
    main()