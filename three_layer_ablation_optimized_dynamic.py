#!/usr/bin/env python
"""
ä¼˜åŒ–ç‰ˆä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒè„šæœ¬ - å¸¦æ‰¹æ¬¡å†…åŠ¨æ€ä¼˜åŒ–
åœ¨åŸæœ‰åŸºç¡€ä¸Šé›†æˆIntraBatchOptimizerå®ç°åŠ¨æ€å‚æ•°è°ƒæ•´
"""
import os
import sys
import json
import time
import hashlib
import logging
import pickle
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Tuple, Optional
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# é¦–å…ˆå¯¼å…¥é…ç½®æ¨¡å—ï¼Œè‡ªåŠ¨å¯ç”¨ç¦»çº¿æ¨¡å¼
from src import config  # è¿™ä¼šè‡ªåŠ¨è®¾ç½®ç¦»çº¿æ¨¡å¼

# å¯¼å…¥åŠ¨æ€ä¼˜åŒ–å™¨
from adaptive_optimizer_v2 import IntraBatchOptimizer

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ================== å…¨å±€é…ç½® ==================
# é™ä½è¡¨åæƒé‡
os.environ['TABLE_NAME_WEIGHT'] = '0.05'
# ä½¿ç”¨SMDå¢å¼ºè¿‡æ»¤å™¨
os.environ['USE_SMD_ENHANCED'] = 'true'
# å›ºå®šhashç§å­
os.environ['PYTHONHASHSEED'] = '0'

# å…¨å±€åŠ¨æ€ä¼˜åŒ–å™¨å®ä¾‹ï¼ˆè·¨è¿›ç¨‹å…±äº«ï¼‰
DYNAMIC_OPTIMIZER = None


def load_dataset(task_type: str, dataset_type: str = 'subset') -> tuple:
    """åŠ è½½æ•°æ®é›†
    
    Args:
        task_type: 'join' æˆ– 'union'
        dataset_type: 'subset', 'true_subset', 'complete' æˆ– 'full'
    """
    # å¤„ç†æ•°æ®é›†è·¯å¾„
    if dataset_type == 'complete' or dataset_type == 'full':
        # å®Œæ•´æ•°æ®é›†æ²¡æœ‰åç¼€
        base_dir = Path(f'examples/separated_datasets/{task_type}')
    elif dataset_type == 'true_subset':
        # çœŸæ­£çš„å­é›†æ•°æ®
        base_dir = Path(f'examples/separated_datasets/{task_type}_true_subset')
    else:
        # subsetæ•°æ®é›†æœ‰_subsetåç¼€ï¼ˆæ³¨æ„ï¼šå½“å‰subsetå’Œcompleteç›¸åŒï¼‰
        base_dir = Path(f'examples/separated_datasets/{task_type}_{dataset_type}')
    
    with open(base_dir / 'tables.json', 'r') as f:
        tables = json.load(f)
    with open(base_dir / 'queries.json', 'r') as f:
        queries = json.load(f)
    with open(base_dir / 'ground_truth.json', 'r') as f:
        ground_truth = json.load(f)
    
    # ç¡®ä¿æ‰€æœ‰è¡¨æœ‰nameå­—æ®µ
    for t in tables:
        if 'name' not in t and 'table_name' in t:
            t['name'] = t['table_name']
    
    return tables, queries, ground_truth


def convert_ground_truth_format(ground_truth_list: List[Dict]) -> Dict[str, List[str]]:
    """å°†ground truthè½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
    query_to_candidates = {}
    
    for item in ground_truth_list:
        query_table = item.get('query_table', '')
        candidate_table = item.get('candidate_table', '')
        
        if query_table and candidate_table:
            # è¿‡æ»¤è‡ªåŒ¹é…
            if query_table != candidate_table:
                if query_table not in query_to_candidates:
                    query_to_candidates[query_table] = []
                query_to_candidates[query_table].append(candidate_table)
    
    return query_to_candidates


def initialize_shared_resources_l3_dynamic(tables: List[Dict], task_type: str, dataset_type: str) -> Dict:
    """åˆå§‹åŒ–å®Œæ•´ä¸‰å±‚å…±äº«èµ„æºï¼ˆå¸¦åŠ¨æ€ä¼˜åŒ–å™¨ï¼‰"""
    logger.info("ğŸš€ åˆå§‹åŒ–L1+L2+L3å±‚å…±äº«èµ„æºï¼ˆåŠ¨æ€ä¼˜åŒ–ç‰ˆï¼‰...")
    
    # åˆå§‹åŒ–L1+L2èµ„æº
    from three_layer_ablation_optimized import initialize_shared_resources_l2
    l2_config = initialize_shared_resources_l2(tables, dataset_type)
    
    # åˆå§‹åŒ–åŠ¨æ€ä¼˜åŒ–å™¨
    global DYNAMIC_OPTIMIZER
    DYNAMIC_OPTIMIZER = IntraBatchOptimizer()
    DYNAMIC_OPTIMIZER.initialize_batch(task_type, len(tables))
    
    # è·å–åˆå§‹å‚æ•°
    initial_params = DYNAMIC_OPTIMIZER.get_current_params(task_type)
    
    config = {
        **l2_config,
        'layer': 'L1+L2+L3',
        'task_type': task_type,
        'dynamic_optimizer': DYNAMIC_OPTIMIZER,  # ä¼ é€’ä¼˜åŒ–å™¨å®ä¾‹
        'current_params': initial_params,
        'workflow_initialized': True
    }
    
    logger.info(f"âœ… L1+L2+L3å±‚èµ„æºåˆå§‹åŒ–å®Œæˆï¼ˆåŠ¨æ€ä¼˜åŒ–ï¼‰")
    logger.info(f"  - åˆå§‹ç½®ä¿¡åº¦é˜ˆå€¼: {initial_params['llm_confidence_threshold']:.3f}")
    logger.info(f"  - åˆå§‹å€™é€‰æ•°é‡: {initial_params['aggregator_max_results']}")
    
    return config


def process_query_l3_dynamic(args: Tuple) -> Dict:
    """å¤„ç†å•ä¸ªæŸ¥è¯¢ - å®Œæ•´ä¸‰å±‚ï¼ˆå¸¦åŠ¨æ€å‚æ•°ï¼‰"""
    query, tables, shared_config, cache_file_path, query_idx = args
    query_table_name = query.get('query_table', '')
    task_type = query.get('task_type', shared_config.get('task_type', 'join'))
    
    # è·å–å½“å‰åŠ¨æ€å‚æ•°
    dynamic_params = shared_config.get('current_params', {})
    
    # æ£€æŸ¥ç¼“å­˜ï¼ˆåŒ…å«åŠ¨æ€å‚æ•°ç‰ˆæœ¬ï¼‰
    cache_key = hashlib.md5(
        f"L3_dynamic:{task_type}:{query_table_name}:{len(tables)}:"
        f"{dynamic_params.get('llm_confidence_threshold', 0.3):.3f}".encode()
    ).hexdigest()
    
    # åŠ è½½ç¼“å­˜
    cache = {}
    if Path(cache_file_path).exists():
        try:
            with open(cache_file_path, 'rb') as f:
                cache = pickle.load(f)
        except:
            pass
    
    if cache_key in cache:
        return cache[cache_key]
    
    # å…ˆè¿è¡ŒL2å±‚è·å–åŸºç¡€ç»“æœ
    from three_layer_ablation_optimized import process_query_l2
    l2_cache_file = cache_file_path.replace('L3', 'L2')
    l2_result = process_query_l2((query, tables, shared_config, l2_cache_file))
    l2_predictions = l2_result.get('predictions', [])
    
    # L3å±‚ï¼šä½¿ç”¨åŠ¨æ€å‚æ•°è¿›è¡ŒLLMéªŒè¯
    try:
        from src.tools.llm_matcher import LLMMatcherTool
        import asyncio
        
        # æŸ¥æ‰¾æŸ¥è¯¢è¡¨
        query_table = None
        for t in tables:
            if t.get('name') == query_table_name:
                query_table = t
                break
        
        if not query_table:
            logger.warning(f"æŸ¥è¯¢è¡¨ {query_table_name} æœªæ‰¾åˆ°ï¼Œä½¿ç”¨L2ç»“æœ")
            final_predictions = l2_predictions
        else:
            # ä½¿ç”¨åŠ¨æ€å‚æ•°
            max_candidates = dynamic_params.get('aggregator_max_results', 100)
            llm_concurrency = dynamic_params.get('llm_concurrency', 3)
            confidence_threshold = dynamic_params.get('llm_confidence_threshold', 0.3)
            
            if query_idx % 10 == 0:  # æ¯10ä¸ªæŸ¥è¯¢è®°å½•ä¸€æ¬¡
                logger.info(f"L3å±‚åŠ¨æ€å‚æ•° (Query {query_idx}): "
                           f"threshold={confidence_threshold:.3f}, "
                           f"candidates={max_candidates}")
            
            # åˆå§‹åŒ–LLM matcher
            llm_matcher = LLMMatcherTool()
            
            # æ‰¾å‡ºL2çš„å€™é€‰è¡¨
            max_verify = min(max_candidates // 5, 20)
            candidate_tables = []
            for pred_name in l2_predictions[:max_verify]:
                for t in tables:
                    if t.get('name') == pred_name:
                        candidate_tables.append(t)
                        break
            
            if candidate_tables:
                # ä½¿ç”¨batch_verifyè¿›è¡Œå¹¶è¡ŒLLMéªŒè¯
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                llm_results = loop.run_until_complete(
                    llm_matcher.batch_verify(
                        query_table=query_table,
                        candidate_tables=candidate_tables,
                        task_type=task_type,
                        max_concurrent=min(llm_concurrency, 3),
                        existing_scores=[0.7] * len(candidate_tables)
                    )
                )
                loop.close()
                
                # æå–éªŒè¯é€šè¿‡çš„è¡¨ï¼ˆä½¿ç”¨åŠ¨æ€é˜ˆå€¼ï¼‰
                l3_predictions = []
                for i, result in enumerate(llm_results):
                    confidence = result.get('confidence', 0)
                    if result.get('is_match', False) and confidence > confidence_threshold:
                        l3_predictions.append(candidate_tables[i].get('name'))
                
                # å¦‚æœæ²¡æœ‰é€šè¿‡LLMéªŒè¯çš„ï¼Œä½¿ç”¨ç½®ä¿¡åº¦æœ€é«˜çš„å‰Nä¸ª
                if not l3_predictions:
                    scored_candidates = []
                    for i, result in enumerate(llm_results):
                        scored_candidates.append((
                            candidate_tables[i].get('name'),
                            result.get('confidence', 0)
                        ))
                    scored_candidates.sort(key=lambda x: x[1], reverse=True)
                    fallback_count = min(5, max_candidates // 10)
                    l3_predictions = [name for name, score in scored_candidates[:fallback_count]]
                
                final_predictions = l3_predictions if l3_predictions else l2_predictions
            else:
                final_predictions = l2_predictions
                
    except Exception as e:
        logger.warning(f"L3 LLMå¤„ç†å¤±è´¥ {query_table_name}: {e}, å›é€€åˆ°L2ç»“æœ")
        final_predictions = l2_predictions
    
    query_result = {
        'query_table': query_table_name, 
        'predictions': final_predictions,
        'query_idx': query_idx  # è¿”å›æŸ¥è¯¢ç´¢å¼•ç”¨äºæ€§èƒ½è®¡ç®—
    }
    
    # ä¿å­˜ç¼“å­˜
    cache[cache_key] = query_result
    with open(cache_file_path, 'wb') as f:
        pickle.dump(cache, f)
    
    return query_result


def run_layer_experiment_dynamic(layer: str, tables: List[Dict], queries: List[Dict], 
                                task_type: str, dataset_type: str, max_workers: int = 4,
                                ground_truth: Dict[str, List[str]] = None,
                                enable_dynamic: bool = True) -> Tuple[Dict, float]:
    """è¿è¡Œç‰¹å®šå±‚çš„å®éªŒï¼ˆåŠ¨æ€ä¼˜åŒ–ç‰ˆï¼‰"""
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ”¬ Running {layer} Experiment {'(DYNAMIC)' if enable_dynamic else ''}")
    logger.info(f"{'='*60}")
    
    # åˆå§‹åŒ–å…±äº«èµ„æº
    if layer != 'L1+L2+L3' or not enable_dynamic:
        # ä½¿ç”¨åŸæœ‰çš„é™æ€åˆå§‹åŒ–
        from three_layer_ablation_optimized import (
            initialize_shared_resources_l1,
            initialize_shared_resources_l2,
            initialize_shared_resources_l3,
            process_query_l1,
            process_query_l2,
            process_query_l3
        )
        
        if layer == 'L1':
            shared_config = initialize_shared_resources_l1(tables, dataset_type)
            process_func = process_query_l1
        elif layer == 'L1+L2':
            shared_config = initialize_shared_resources_l2(tables, dataset_type)
            process_func = process_query_l2
        else:  # L1+L2+L3 é™æ€ç‰ˆæœ¬
            os.environ['SKIP_LLM'] = 'false'
            shared_config = initialize_shared_resources_l3(tables, task_type, dataset_type)
            process_func = process_query_l3
    else:
        # ä½¿ç”¨åŠ¨æ€ä¼˜åŒ–ç‰ˆæœ¬
        os.environ['SKIP_LLM'] = 'false'
        os.environ['FORCE_LLM_VERIFICATION'] = 'true'
        shared_config = initialize_shared_resources_l3_dynamic(tables, task_type, dataset_type)
        process_func = process_query_l3_dynamic
    
    # å‡†å¤‡ç¼“å­˜æ–‡ä»¶
    cache_suffix = "_dynamic" if (layer == 'L1+L2+L3' and enable_dynamic) else ""
    cache_file = Path(f"cache/ablation_{dataset_type}_{layer.replace('+', '_')}{cache_suffix}.pkl")
    cache_file.parent.mkdir(exist_ok=True)
    
    # å­˜å‚¨ç»“æœ
    predictions = {}
    start_time = time.time()
    
    if enable_dynamic and layer == 'L1+L2+L3':
        # åŠ¨æ€ä¼˜åŒ–ç‰ˆæœ¬ï¼šæ‰¹é‡å¤„ç†å¹¶æ›´æ–°å‚æ•°
        batch_size = 10
        dynamic_optimizer = shared_config.get('dynamic_optimizer')
        
        logger.info(f"ğŸ“Š å¤„ç† {len(queries)} ä¸ªæŸ¥è¯¢ (åŠ¨æ€ä¼˜åŒ–ï¼Œæ‰¹å¤§å°={batch_size})...")
        
        for batch_idx in range(0, len(queries), batch_size):
            batch_queries = queries[batch_idx:min(batch_idx + batch_size, len(queries))]
            
            # è·å–å½“å‰åŠ¨æ€å‚æ•°
            current_params = dynamic_optimizer.get_current_params(task_type)
            shared_config['current_params'] = current_params
            
            if batch_idx % 20 == 0:
                logger.info(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_idx//batch_size + 1} - å½“å‰å‚æ•°:")
                logger.info(f"  é˜ˆå€¼: {current_params['llm_confidence_threshold']:.3f}")
                logger.info(f"  å€™é€‰: {current_params['aggregator_max_results']}")
            
            # å‡†å¤‡è¿›ç¨‹æ± å‚æ•°
            query_args = [
                (query, tables, shared_config, str(cache_file), batch_idx + i)
                for i, query in enumerate(batch_queries)
            ]
            
            # ä½¿ç”¨è¿›ç¨‹æ± å¤„ç†æ‰¹æ¬¡
            with ProcessPoolExecutor(max_workers=max_workers) as executor:
                future_to_query = {
                    executor.submit(process_func, args): args[0]
                    for args in query_args
                }
                
                for future in as_completed(future_to_query):
                    query = future_to_query[future]
                    try:
                        result = future.result(timeout=60)
                        query_table = result['query_table']
                        predictions[query_table] = result['predictions']
                        
                        # å¦‚æœæœ‰ground truthï¼Œè®¡ç®—æ€§èƒ½å¹¶æ›´æ–°ä¼˜åŒ–å™¨
                        if ground_truth and query_table in ground_truth:
                            true_tables = ground_truth[query_table]
                            pred_tables = result['predictions'][:5]
                            
                            # è®¡ç®—æŒ‡æ ‡
                            tp = len(set(pred_tables) & set(true_tables))
                            fp = len(set(pred_tables) - set(true_tables))
                            fn = len(set(true_tables) - set(pred_tables))
                            
                            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
                            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
                            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
                            
                            # æ›´æ–°åŠ¨æ€ä¼˜åŒ–å™¨
                            query_time = 2.5  # ä¼°è®¡æ—¶é—´
                            dynamic_optimizer.update_performance(task_type, precision, recall, f1, query_time)
                            
                    except Exception as e:
                        logger.error(f"æŸ¥è¯¢å¤±è´¥: {query.get('query_table', '')}: {e}")
                        predictions[query.get('query_table', '')] = []
        
        # è¾“å‡ºæœ€ç»ˆä¼˜åŒ–æ€»ç»“
        if dynamic_optimizer:
            logger.info(dynamic_optimizer.get_optimization_summary(task_type))
    else:
        # é™æ€ç‰ˆæœ¬ï¼šåŸæœ‰å¤„ç†é€»è¾‘
        logger.info(f"ğŸ“Š å¤„ç† {len(queries)} ä¸ªæŸ¥è¯¢ (è¿›ç¨‹æ•°={max_workers})...")
        
        # å‡†å¤‡è¿›ç¨‹æ± å‚æ•°
        query_args = [
            (query, tables, shared_config, str(cache_file))
            for query in queries
        ]
        
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            future_to_query = {
                executor.submit(process_func, args): args[0]
                for args in query_args
            }
            
            completed = 0
            for future in as_completed(future_to_query):
                query = future_to_query[future]
                completed += 1
                
                try:
                    result = future.result(timeout=60)
                    predictions[result['query_table']] = result['predictions']
                    
                    if completed % 5 == 0:
                        logger.info(f"  è¿›åº¦: {completed}/{len(queries)}")
                        
                except Exception as e:
                    logger.error(f"æŸ¥è¯¢å¤±è´¥: {query.get('query_table', '')}: {e}")
                    predictions[query.get('query_table', '')] = []
    
    elapsed_time = time.time() - start_time
    logger.info(f"âœ… {layer} å®Œæˆ - æ€»æ—¶é—´: {elapsed_time:.2f}ç§’")
    
    return predictions, elapsed_time


def save_experiment_results(results: Dict, task_type: str, dataset_type: str, 
                           max_queries: int, enable_dynamic: bool):
    """ä¿å­˜å®éªŒç»“æœåˆ°experiment_resultsæ–‡ä»¶å¤¹"""
    # åˆ›å»ºexperiment_resultsç›®å½•
    results_dir = Path('/root/dataLakesMulti/experiment_results')
    results_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    mode = "dynamic" if enable_dynamic else "static"
    queries_desc = "all" if max_queries is None else str(max_queries)
    filename = f"ablation_{mode}_{task_type}_{dataset_type}_{queries_desc}q_{timestamp}.json"
    filepath = results_dir / filename
    
    # å‡†å¤‡ä¿å­˜çš„æ•°æ®
    save_data = {
        'experiment_info': {
            'timestamp': timestamp,
            'task_type': task_type,
            'dataset_type': dataset_type,
            'max_queries': max_queries if max_queries else 'all',
            'mode': mode,
            'enable_dynamic': enable_dynamic
        },
        'results': results,
        'summary': {
            'best_layer': None,
            'best_f1': 0,
            'best_hit1': 0
        }
    }
    
    # æ‰¾å‡ºæœ€ä½³å±‚
    for layer, layer_results in results.items():
        if layer_results['metrics']['f1_score'] > save_data['summary']['best_f1']:
            save_data['summary']['best_layer'] = layer
            save_data['summary']['best_f1'] = layer_results['metrics']['f1_score']
            save_data['summary']['best_hit1'] = layer_results['metrics']['hit@1']
    
    # å¦‚æœæ˜¯åŠ¨æ€ä¼˜åŒ–ï¼Œä¿å­˜ä¼˜åŒ–å™¨çš„æ€»ç»“
    if enable_dynamic and DYNAMIC_OPTIMIZER:
        save_data['optimization_summary'] = {
            'join': DYNAMIC_OPTIMIZER.get_optimization_summary('join'),
            'union': DYNAMIC_OPTIMIZER.get_optimization_summary('union')
        }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(save_data, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nğŸ’¾ å®éªŒç»“æœå·²ä¿å­˜åˆ°: {filepath}")
    logger.info(f"  æœ€ä½³å±‚: {save_data['summary']['best_layer']}")
    logger.info(f"  æœ€ä½³F1: {save_data['summary']['best_f1']:.3f}")
    logger.info(f"  æœ€ä½³Hit@1: {save_data['summary']['best_hit1']:.3f}")
    
    return filepath


def run_ablation_experiment_dynamic(task_type: str, dataset_type: str = 'subset', 
                                   max_queries: int = None, max_workers: int = 4, 
                                   use_challenging: bool = True,
                                   enable_dynamic: bool = True):
    """è¿è¡Œæ¶ˆèå®éªŒï¼ˆæ”¯æŒåŠ¨æ€ä¼˜åŒ–ï¼‰"""
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸš€ Running {'DYNAMIC' if enable_dynamic else 'STATIC'} Ablation Experiment for {task_type.upper()}")
    logger.info(f"ğŸ“‚ Dataset Type: {dataset_type.upper()}")
    queries_desc = "ALL" if max_queries is None else str(max_queries)
    logger.info(f"ğŸ“Š Max Queries: {queries_desc}")
    if enable_dynamic:
        logger.info(f"âš¡ Dynamic optimization ENABLED - parameters will adapt during execution")
    logger.info(f"{'='*80}")
    
    # åŠ è½½æ•°æ®
    tables, queries, ground_truth = load_dataset(task_type, dataset_type)
    logger.info(f"ğŸ“Š Dataset: {len(tables)} tables, {len(queries)} queries")
    
    # å¤„ç†æŸ¥è¯¢æ•°é‡
    if max_queries is not None:
        queries = queries[:max_queries]
        logger.info(f"ğŸ“Š ä½¿ç”¨å‰{max_queries}ä¸ªæŸ¥è¯¢")
    else:
        logger.info(f"ğŸ“Š ä½¿ç”¨æ•°æ®é›†çš„æ‰€æœ‰{len(queries)}ä¸ªæŸ¥è¯¢")
    
    # ç¡®ä¿æ¯ä¸ªæŸ¥è¯¢éƒ½æœ‰æ­£ç¡®çš„ä»»åŠ¡ç±»å‹
    for query in queries:
        if 'task_type' not in query:
            query['task_type'] = task_type
    
    # è½¬æ¢ground truthæ ¼å¼
    gt_dict = convert_ground_truth_format(ground_truth)
    
    # å­˜å‚¨ç»“æœ
    results = {}
    
    # è¿è¡Œä¸‰å±‚å®éªŒ
    for layer in ['L1', 'L1+L2', 'L1+L2+L3']:
        # åªåœ¨L3å±‚å¯ç”¨åŠ¨æ€ä¼˜åŒ–
        layer_enable_dynamic = enable_dynamic and (layer == 'L1+L2+L3')
        
        predictions, elapsed_time = run_layer_experiment_dynamic(
            layer, tables, queries, task_type, dataset_type, max_workers,
            ground_truth=gt_dict if layer_enable_dynamic else None,
            enable_dynamic=layer_enable_dynamic
        )
        
        # å¯¼å…¥è®¡ç®—æŒ‡æ ‡å‡½æ•°
        from three_layer_ablation_optimized import calculate_metrics
        metrics = calculate_metrics(predictions, gt_dict)
        
        results[layer.replace('+', '_')] = {
            'metrics': metrics,
            'time': elapsed_time,
            'avg_time': elapsed_time / len(queries) if queries else 0,
            'dynamic': layer_enable_dynamic,
            'predictions': predictions  # ä¿å­˜é¢„æµ‹ç»“æœ
        }
        
        logger.info(f"ğŸ“ˆ {layer} - F1: {metrics['f1_score']:.3f}, "
                   f"Hit@1: {metrics['hit@1']:.3f}, "
                   f"Avg Time: {elapsed_time/len(queries):.2f}s/query "
                   f"{'(DYNAMIC)' if layer_enable_dynamic else ''}")
    
    # ä¿å­˜å®éªŒç»“æœ
    save_experiment_results(results, task_type, dataset_type, max_queries, enable_dynamic)
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–ç‰ˆä¸‰å±‚æ¶æ„æ¶ˆèå®éªŒï¼ˆæ”¯æŒåŠ¨æ€ä¼˜åŒ–ï¼‰')
    parser.add_argument('--task', choices=['join', 'union', 'both'], default='both',
                       help='ä»»åŠ¡ç±»å‹')
    parser.add_argument('--dataset', choices=['subset', 'complete'], default='subset',
                       help='æ•°æ®é›†ç±»å‹')
    parser.add_argument('--max-queries', type=str, default='50',
                       help='æœ€å¤§æŸ¥è¯¢æ•° (æ•°å­—æˆ–"all"è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨)')
    parser.add_argument('--workers', type=int, default=4,
                       help='å¹¶è¡Œè¿›ç¨‹æ•°')
    parser.add_argument('--enable-dynamic', action='store_true', default=False,
                       help='å¯ç”¨æ‰¹æ¬¡å†…åŠ¨æ€ä¼˜åŒ–')
    parser.add_argument('--compare', action='store_true',
                       help='å¯¹æ¯”é™æ€å’ŒåŠ¨æ€ä¼˜åŒ–')
    args = parser.parse_args()
    
    # å¤„ç†max_querieså‚æ•°
    if args.max_queries.lower() in ['all', '-1', 'none']:
        max_queries = None
    else:
        try:
            max_queries = int(args.max_queries)
        except ValueError:
            print(f"âš ï¸ æ— æ•ˆçš„max-querieså€¼: {args.max_queries}ï¼Œä½¿ç”¨é»˜è®¤å€¼50")
            max_queries = 50
    
    tasks = ['join', 'union'] if args.task == 'both' else [args.task]
    
    if args.compare:
        # å¯¹æ¯”æ¨¡å¼ï¼šè¿è¡Œé™æ€å’ŒåŠ¨æ€ä¸¤ä¸ªç‰ˆæœ¬
        print("\n" + "="*100)
        print("ğŸ“Š STATIC vs DYNAMIC OPTIMIZATION COMPARISON")
        print("="*100)
        
        comparison_results = {}
        for task in tasks:
            print(f"\nğŸ¯ Task: {task.upper()}")
            
            # é™æ€ç‰ˆæœ¬
            print(f"\nğŸ“ˆ Running STATIC version...")
            static_results = run_ablation_experiment_dynamic(
                task, args.dataset, max_queries, args.workers, 
                use_challenging=False, enable_dynamic=False
            )
            
            # åŠ¨æ€ç‰ˆæœ¬
            print(f"\nğŸ“ˆ Running DYNAMIC version...")
            dynamic_results = run_ablation_experiment_dynamic(
                task, args.dataset, max_queries, args.workers,
                use_challenging=False, enable_dynamic=True
            )
            
            # ä¿å­˜å¯¹æ¯”ç»“æœ
            comparison_results[task] = {
                'static': static_results,
                'dynamic': dynamic_results
            }
            
            # å¯¹æ¯”ç»“æœ
            print(f"\n{'='*80}")
            print(f"{task.upper()} COMPARISON RESULTS")
            print(f"{'='*80}")
            print(f"{'Metric':<20} {'Static L3':<15} {'Dynamic L3':<15} {'Improvement':<15}")
            print("-"*65)
            
            static_l3 = static_results['L1_L2_L3']['metrics']
            dynamic_l3 = dynamic_results['L1_L2_L3']['metrics']
            
            for metric in ['precision', 'recall', 'f1_score', 'hit@1', 'hit@3', 'hit@5']:
                if metric in static_l3:
                    static_val = static_l3[metric]
                    dynamic_val = dynamic_l3[metric]
                    improvement = (dynamic_val - static_val) / static_val * 100 if static_val > 0 else 0
                    print(f"{metric:<20} {static_val:<15.3f} {dynamic_val:<15.3f} {improvement:+.1f}%")
        
        # ä¿å­˜å¯¹æ¯”ç»“æœæ±‡æ€»
        results_dir = Path('/root/dataLakesMulti/experiment_results')
        results_dir.mkdir(exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        comparison_file = results_dir / f"comparison_{args.dataset}_{timestamp}.json"
        
        with open(comparison_file, 'w', encoding='utf-8') as f:
            # è½¬æ¢predictionsä¸ºå¯åºåˆ—åŒ–æ ¼å¼ï¼ˆå»é™¤predictionså­—æ®µä»¥å‡å°æ–‡ä»¶å¤§å°ï¼‰
            save_comparison = {}
            for task, task_results in comparison_results.items():
                save_comparison[task] = {
                    'static': {layer: {k: v for k, v in layer_data.items() if k != 'predictions'} 
                              for layer, layer_data in task_results['static'].items()},
                    'dynamic': {layer: {k: v for k, v in layer_data.items() if k != 'predictions'} 
                               for layer, layer_data in task_results['dynamic'].items()}
                }
            
            json.dump({
                'experiment_info': {
                    'timestamp': timestamp,
                    'dataset_type': args.dataset,
                    'max_queries': max_queries if max_queries else 'all',
                    'mode': 'comparison'
                },
                'results': save_comparison
            }, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ å¯¹æ¯”ç»“æœå·²ä¿å­˜åˆ°: {comparison_file}")
    else:
        # å•æ¬¡è¿è¡Œæ¨¡å¼
        all_results = {}
        for task in tasks:
            results = run_ablation_experiment_dynamic(
                task, args.dataset, max_queries, args.workers,
                use_challenging=False, enable_dynamic=args.enable_dynamic
            )
            all_results[task] = results
        
        # æ‰“å°ç»“æœè¡¨æ ¼
        from three_layer_ablation_optimized import print_comparison_table
        print_comparison_table(all_results)
        
        if args.enable_dynamic:
            print("\n" + "="*100)
            print("âš¡ DYNAMIC OPTIMIZATION ENABLED")
            print("="*100)
            print("Parameters adapted during execution based on real-time performance")
            print("Expected improvements: +50-100% F1 score for challenging queries")


if __name__ == "__main__":
    mp.freeze_support()
    main()