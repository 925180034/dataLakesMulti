#!/usr/bin/env python
"""
éªŒè¯æ–°åˆ›å»ºçš„JOINå’ŒUNIONé«˜è´¨é‡æ•°æ®é›†
"""
import json
from pathlib import Path
from collections import Counter

def validate_dataset(dataset_dir: Path, task_type: str):
    """éªŒè¯å•ä¸ªæ•°æ®é›†çš„è´¨é‡"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š éªŒè¯ {task_type.upper()} æ•°æ®é›†")
    print(f"{'='*60}")
    
    # åŠ è½½æ•°æ®
    with open(dataset_dir / 'tables.json', 'r') as f:
        tables = json.load(f)
    with open(dataset_dir / 'queries.json', 'r') as f:
        queries = json.load(f)
    with open(dataset_dir / 'ground_truth.json', 'r') as f:
        ground_truth = json.load(f)
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"\nğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
    print(f"  è¡¨æ•°é‡: {len(tables)}")
    print(f"  æŸ¥è¯¢æ•°é‡: {len(queries)}")
    print(f"  Ground Truthæ¡ç›®: {len(ground_truth)}")
    
    # æ„å»ºground truthæ˜ å°„
    gt_map = {}
    for gt in ground_truth:
        qt = gt['query_table']
        ct = gt['candidate_table']
        if qt not in gt_map:
            gt_map[qt] = set()
        gt_map[qt].add(ct)
    
    # è´¨é‡æ£€æŸ¥
    print(f"\nâœ… è´¨é‡æ£€æŸ¥:")
    
    # 1. è¦†ç›–ç‡
    query_tables = {q['query_table'] for q in queries}
    gt_queries = set(gt_map.keys())
    coverage = len(query_tables & gt_queries) / len(query_tables) if query_tables else 0
    print(f"  Ground Truthè¦†ç›–ç‡: {coverage:.1%} ({len(query_tables & gt_queries)}/{len(query_tables)})")
    
    # 2. è‡ªåŒ¹é…æ£€æŸ¥
    self_matches = 0
    for gt in ground_truth:
        if gt['query_table'] == gt['candidate_table']:
            self_matches += 1
    print(f"  è‡ªåŒ¹é…æ•°é‡: {self_matches} {'âŒ' if self_matches > 0 else 'âœ…'}")
    
    # 3. å€™é€‰è¡¨åˆ†å¸ƒ
    candidate_counts = Counter(len(candidates) for candidates in gt_map.values())
    avg_candidates = sum(len(c) for c in gt_map.values()) / len(gt_map) if gt_map else 0
    
    print(f"\nğŸ“Š å€™é€‰è¡¨åˆ†å¸ƒ:")
    print(f"  å¹³å‡å€™é€‰è¡¨æ•°: {avg_candidates:.2f}")
    print(f"  åˆ†å¸ƒæƒ…å†µ:")
    for count in sorted(candidate_counts.keys())[:10]:
        freq = candidate_counts[count]
        pct = freq / len(gt_map) * 100 if gt_map else 0
        print(f"    {count:2d}ä¸ªå€™é€‰: {freq:3d}ä¸ªæŸ¥è¯¢ ({pct:5.1f}%)")
    
    # 4. è¡¨å­˜åœ¨æ€§æ£€æŸ¥
    table_names = {t['table_name'] for t in tables}
    missing_query_tables = []
    missing_candidate_tables = []
    
    for qt in query_tables:
        if qt not in table_names:
            missing_query_tables.append(qt)
    
    for candidates in gt_map.values():
        for ct in candidates:
            if ct not in table_names:
                missing_candidate_tables.append(ct)
    
    print(f"\nğŸ” è¡¨å­˜åœ¨æ€§æ£€æŸ¥:")
    print(f"  ç¼ºå¤±çš„æŸ¥è¯¢è¡¨: {len(missing_query_tables)} {'âŒ' if missing_query_tables else 'âœ…'}")
    print(f"  ç¼ºå¤±çš„å€™é€‰è¡¨: {len(set(missing_candidate_tables))} {'âŒ' if missing_candidate_tables else 'âœ…'}")
    
    # 5. æœ€é¢‘ç¹çš„å€™é€‰è¡¨
    candidate_freq = Counter()
    for candidates in gt_map.values():
        for c in candidates:
            candidate_freq[c] += 1
    
    print(f"\nğŸ¯ æœ€é¢‘ç¹çš„å€™é€‰è¡¨ (æ£€æŸ¥æ˜¯å¦è¿‡åº¦é›†ä¸­):")
    for table, count in candidate_freq.most_common(5):
        pct = count / len(gt_map) * 100 if gt_map else 0
        print(f"  {table}: {count}æ¬¡ ({pct:.1f}%)")
    
    # æœ€é«˜é¢‘ç‡å€™é€‰è¡¨çš„å æ¯”
    if candidate_freq:
        max_freq = candidate_freq.most_common(1)[0][1]
        max_freq_pct = max_freq / len(gt_map) * 100 if gt_map else 0
        if max_freq_pct > 50:
            print(f"  âš ï¸ è­¦å‘Š: æœ€é¢‘ç¹çš„å€™é€‰è¡¨å‡ºç°åœ¨ {max_freq_pct:.1f}% çš„æŸ¥è¯¢ä¸­")
        else:
            print(f"  âœ… å€™é€‰è¡¨åˆ†å¸ƒç›¸å¯¹å‡è¡¡ (æœ€é«˜ {max_freq_pct:.1f}%)")
    
    return {
        'tables': len(tables),
        'queries': len(queries),
        'ground_truth': len(ground_truth),
        'coverage': coverage,
        'avg_candidates': avg_candidates,
        'self_matches': self_matches,
        'missing_tables': len(missing_query_tables) + len(set(missing_candidate_tables))
    }

def main():
    print("="*80)
    print("ğŸ” éªŒè¯é«˜è´¨é‡æ•°æ®é›†")
    print("="*80)
    
    base_dir = Path('/root/dataLakesMulti/examples/separated_datasets')
    
    # éªŒè¯ä¸¤ä¸ªä»»åŠ¡çš„æ•°æ®é›†
    all_stats = {}
    for task_type in ['join', 'union']:
        task_dir = base_dir / task_type
        if task_dir.exists():
            stats = validate_dataset(task_dir, task_type)
            all_stats[task_type] = stats
        else:
            print(f"\nâŒ æœªæ‰¾åˆ° {task_type} æ•°æ®é›†ç›®å½•: {task_dir}")
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("ğŸ“ˆ æ•°æ®é›†è´¨é‡æ€»ç»“")
    print("="*80)
    
    quality_score = 0
    max_score = 0
    
    for task_type, stats in all_stats.items():
        print(f"\n{task_type.upper()}:")
        
        # è¯„åˆ†
        task_score = 0
        task_max = 5
        
        # è¦†ç›–ç‡ (1åˆ†)
        if stats['coverage'] == 1.0:
            task_score += 1
            print(f"  âœ… 100%è¦†ç›–ç‡")
        else:
            print(f"  âŒ è¦†ç›–ç‡åªæœ‰ {stats['coverage']:.1%}")
        
        # æ— è‡ªåŒ¹é… (1åˆ†)
        if stats['self_matches'] == 0:
            task_score += 1
            print(f"  âœ… æ— è‡ªåŒ¹é…")
        else:
            print(f"  âŒ å­˜åœ¨ {stats['self_matches']} ä¸ªè‡ªåŒ¹é…")
        
        # å¹³å‡å€™é€‰è¡¨æ•° (1åˆ†)
        if stats['avg_candidates'] >= 3:
            task_score += 1
            print(f"  âœ… å¹³å‡ {stats['avg_candidates']:.1f} ä¸ªå€™é€‰è¡¨")
        else:
            print(f"  âš ï¸ å¹³å‡åªæœ‰ {stats['avg_candidates']:.1f} ä¸ªå€™é€‰è¡¨")
        
        # è¡¨å®Œæ•´æ€§ (1åˆ†)
        if stats['missing_tables'] == 0:
            task_score += 1
            print(f"  âœ… æ‰€æœ‰è¡¨éƒ½å­˜åœ¨")
        else:
            print(f"  âŒ ç¼ºå¤± {stats['missing_tables']} ä¸ªè¡¨")
        
        # æ•°æ®é‡ (1åˆ†)
        if stats['queries'] >= 50:
            task_score += 1
            print(f"  âœ… å……è¶³çš„æŸ¥è¯¢æ•° ({stats['queries']})")
        else:
            print(f"  âš ï¸ æŸ¥è¯¢æ•°è¾ƒå°‘ ({stats['queries']})")
        
        print(f"  å¾—åˆ†: {task_score}/{task_max}")
        quality_score += task_score
        max_score += task_max
    
    # æœ€ç»ˆè¯„åˆ†
    print("\n" + "="*80)
    print(f"ğŸ¯ æ€»ä½“è´¨é‡è¯„åˆ†: {quality_score}/{max_score} ({quality_score/max_score*100:.0f}%)")
    print("="*80)
    
    if quality_score / max_score >= 0.8:
        print("\nâœ… æ•°æ®é›†è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥ç”¨äºå®éªŒï¼")
    elif quality_score / max_score >= 0.6:
        print("\nâš ï¸ æ•°æ®é›†è´¨é‡è‰¯å¥½ï¼Œä½†æœ‰æ”¹è¿›ç©ºé—´")
    else:
        print("\nâŒ æ•°æ®é›†è´¨é‡éœ€è¦æ”¹è¿›")
    
    print("\nğŸ“ ä½¿ç”¨å»ºè®®:")
    print("1. è¿è¡ŒJOINå®éªŒ:")
    print("   python run_cached_experiments.py --task join --dataset subset --max-queries 20")
    print("2. è¿è¡ŒUNIONå®éªŒ:")
    print("   python run_cached_experiments.py --task union --dataset subset --max-queries 20")
    print("3. è¿è¡Œä¸¤ä¸ªä»»åŠ¡:")
    print("   python run_cached_experiments.py --task both --dataset subset --max-queries 10")


if __name__ == "__main__":
    main()